<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gam0022.net</title>
    <link>https://gam0022.net/tags/cg/index.xml</link>
    <description>Recent content on gam0022.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>jp</language>
    <copyright>&amp;copy; 2021 gam0022</copyright>
    <atom:link href="/tags/cg/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>[Unity][ShaderGraph]インクシェーダーを作る</title>
      <link>https://gam0022.net/blog/2022/12/25/unity-ink-shader/</link>
      <pubDate>Sun, 25 Dec 2022 23:03:44 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2022/12/25/unity-ink-shader/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;https://qiita.com/advent-calendar/2022/unity&#34;&gt;Unity Advent Calendar 2022&lt;/a&gt;の22日目の記事です。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;スプラトゥーン3面白いですよね。過去作は未プレイでしたが、ゆるく楽しく遊んでいます。&lt;/p&gt;

&lt;p&gt;スプラ3で遊びながら、インクシェーダーの実装方法に興味が出てきたので、UnityのShaderGraphでそれっぽいものを実装してみました。&lt;/p&gt;

&lt;p&gt;ShaderGraphの基本機能だけで構成されており、ノードの量も少なめにしました。&lt;/p&gt;

&lt;p&gt;ShaderGraphの基本操作は解説しませんが、なるべく丁寧に説明をしたつもりなので、ShaderGraphの入門記事として参考にしてください！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;UnityのShaderGraphでインクシェーダーを試作&lt;a href=&#34;https://twitter.com/hashtag/Unity3D?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Unity3D&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/ShaderGraph?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ShaderGraph&lt;/a&gt; &lt;a href=&#34;https://t.co/PHxIkfnkiQ&#34;&gt;pic.twitter.com/PHxIkfnkiQ&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1606141695724204032?ref_src=twsrc%5Etfw&#34;&gt;December 23, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/ShaderPlaygroundURP/tree/main/Assets/ShaderPlaygroundURP/InkShader&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/ShaderPlaygroundURP/&#34;&gt;WebGLデモ&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;WASDと右クリックのドラッグでカメラ操作&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;shadergraph全体&#34;&gt;ShaderGraph全体&lt;/h1&gt;

&lt;p&gt;ShaderGraphの全体です。&lt;/p&gt;

&lt;p&gt;文字が小さくてすみません。&lt;/p&gt;

&lt;p&gt;※2回に分けてスクリーンショットを取ってMSペイントで結合しました。3回以上分割して撮影するのは手間がかかるので諦めました。いい感じにウィンドウのスクロール領域を含めて一発でスクリーンショットを撮る方法があれば教えてください。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/shader-graph-all.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/shader-graph-all.png&#34; alt=&#34;ShaderGraph全体&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;基本方針&#34;&gt;基本方針&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;URPのLitグラフに与えるBaseColorやSmoothnessや法線をいい感じに制御してインクっぽくする

&lt;ul&gt;
&lt;li&gt;カスタムなシェーディングはしない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;インクの高さマップはGradient Noiseからプロシージャル生成

&lt;ul&gt;
&lt;li&gt;インタラクティブなインク制御は未対応&lt;/li&gt;
&lt;li&gt;RenderTextureを生成してペイントするようなアプローチでインタラクティブにできそう（今後の課題）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;チュートリアル&#34;&gt;チュートリアル&lt;/h1&gt;

&lt;p&gt;そこまで規模の大きくないShaderGraphですが、理解しやすいように1ステップごと解説します。&lt;/p&gt;

&lt;h2 id=&#34;ステップ1-pbrテクスチャに対応&#34;&gt;ステップ1. PBRテクスチャに対応&lt;/h2&gt;

&lt;p&gt;まずはPBRテクスチャに対応します。&lt;/p&gt;

&lt;p&gt;PBRテクスチャは以下のサイトからお借りしました。とても良い感じのCC0ライセンスの床のタイル素材を利用させていただきました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://polyhaven.com/a/cobblestone_floor_08&#34;&gt;Cobblestone Floor 08 Texture • Poly Haven&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これがPBRテクスチャをプロパティにして、ShaderGraphの各種PBRパラメーターを渡すだけのShaderGraphです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/1-armtex.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/1-armtex.png&#34; alt=&#34;PBRテクスチャに対応&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;BaseColor&lt;/code&gt; や &lt;code&gt;Normal&lt;/code&gt; はそのままノードを繋げるだけでOKです。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Metallic/Smoothness/Ambient Occlusion&lt;/code&gt; だけ少し工夫がいります。&lt;/p&gt;

&lt;p&gt;Poly Havenのテクスチャは &lt;code&gt;Ambient Occlusion/Roughness/Metallic&lt;/code&gt;（以下、ARMテクスチャ）がRGBに格納されているようなので、RGBの順番をBGRのように並び替える必要があります。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Smoothness = 1 - Roughness&lt;/code&gt; の関係があるので &lt;code&gt;One Minus&lt;/code&gt; ノードで変換します。&lt;/p&gt;

&lt;p&gt;これでPoly Havenから落としてきたARMテクスチャに対応したShaderGraphができました。&lt;/p&gt;

&lt;h2 id=&#34;ステップ2-uvのタイリング&#34;&gt;ステップ2. UVのタイリング&lt;/h2&gt;

&lt;p&gt;ここから最終的なインクシェーダーのShaderGraphをステップごとに解説します。&lt;/p&gt;

&lt;p&gt;まずUVのタイリングですが、単純にUVに定数を乗算しているだけです。今回は下地のテクスチャ用とインク用で独立してタイリングできるようにしました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/2-uv.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/2-uv.png&#34; alt=&#34;UVのタイリング&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ステップ3-インクの高さマップ用のノイズ生成&#34;&gt;ステップ3. インクの高さマップ用のノイズ生成&lt;/h2&gt;

&lt;p&gt;インクの高さマップはGradient Noiseから生成します。時間でアニメーションさせるために2つのGradient Noiseを線形補間で合成しています。&lt;/p&gt;

&lt;p&gt;1つ目のGradient NoiseのUVは固定させておいて、2つ目のGradient NoiseのUVはtimeでスクロールさせています。&lt;/p&gt;

&lt;p&gt;非常にシンプルな処理ですが、意外にもそれなりにインクっぽく見えるのではないでしょうか？&lt;/p&gt;

&lt;p&gt;ShaderGraphのGradient Noiseはシェーダーでプロシージャル生成しているようでGPU負荷があるようでした。軽量化のためにテクスチャのサンプリングに置き換えた方がいいかもしれません。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/3-noise.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/3-noise.png&#34; alt=&#34;インクの高さマップ用のノイズ生成&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ステップ4-凹凸を考慮したインク判定のしきい値&#34;&gt;ステップ4. 凹凸を考慮したインク判定のしきい値&lt;/h2&gt;

&lt;p&gt;ステップ3. でインクの高さマップを生成しました。この高さマップがしきい値以上ならインクの領域と見なすようにします。&lt;/p&gt;

&lt;p&gt;インク判定のしきい値は定数でも良いのですが、高さマップを考慮してブロックの溝など低い部分の方がインクになりやすくします。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/4-threshold.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/4-threshold.png&#34; alt=&#34;インクの高さマップ用のノイズ生成&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;高さマップの影響力はプロパティで制御できるようにしました。&lt;/p&gt;

&lt;p&gt;高さマップの考慮がないと真っ平らなPlaneにインクが乗っているようで、雑コラ感・馴染まない感があります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/height-intensity-off.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/height-intensity-off.png&#34; alt=&#34;高さマップの考慮なし&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;高さマップを考慮すると、ブロックの凹凸を考慮してインクが広がるので、リアリティを少し向上できます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/height-intensity-on.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/height-intensity-on.png&#34; alt=&#34;高さマップの考慮あり&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ステップ5-インクのマスク生成&#34;&gt;ステップ5. インクのマスク生成&lt;/h2&gt;

&lt;p&gt;「ステップ3のインクの高さマップ」から「ステップ4のしきい値」を引き算することで、インクのマスク画像を生成します。&lt;/p&gt;

&lt;p&gt;そのままだとコントラストが薄いので、Powerノードでコントラストを強めに調整します。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/5-1-ink-mask.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/5-1-ink-mask.png&#34; alt=&#34;インクのマスク生成&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;インクのマスクマップをLerpの引数にして、各種PBRパラメーターにインク用の値をブレンドします。
元はARMテクスチャの値をそのままPBRパラメーターとして渡していましたが、間にLerpノードを挟み込んで、インク用の &lt;code&gt;Ambient Occlusion/Roughness/Metallic&lt;/code&gt; をブレンドできるようにしました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/5-2-ink-mask.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/5-2-ink-mask.png&#34; alt=&#34;インク用の設定をブレンド&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BaseMapも同じようにLerpします。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/5-3-ink-mask.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/5-3-ink-mask.png&#34; alt=&#34;インク用の設定をブレンド(BaseMap)&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ステップ6-法線の生成&#34;&gt;ステップ6. 法線の生成&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/6-normal.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-12-26-unity-ink-shader/6-normal.png&#34; alt=&#34;法線の生成&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ステップ3のインクの高さマップから法線を生成します。Normal From Heightノードがあるので利用します。&lt;/p&gt;

&lt;p&gt;ステップ5のインクのマスクでは高さマップの影響で高周波成分が現れてしまうので滑らかな法線ができず、法線生成には不適切です。しきい値を引き算する前のGradient Noiseの値をNormal From Heightノードに繋ぎます。&lt;/p&gt;

&lt;p&gt;今回もPowerノードでコントラストを調整可能にしました。SaturateノードではなくMaximumノードを利用しているのでは、 &lt;code&gt;Clamp(x, 0, INF)&lt;/code&gt; にしたいからです。&lt;/p&gt;

&lt;p&gt;マスク画像の結果は &lt;code&gt;[0-1]&lt;/code&gt; に正規化する必要がありますが、法線生成のHeightマップであれば最大値の制限は不要だと思ったからです。&lt;/p&gt;

&lt;p&gt;以上がインク用のシェーダーの解説でした。&lt;/p&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;ShaderGraphだけでノーコードのインクシェーダーを試作しました。
PBRパラメーターを制御するだけのお手軽な実装ですが、思ったよりも良い見た目になったので満足です。&lt;/p&gt;

&lt;p&gt;今回はインクのマスクにGradient Noiseを利用しましたが、RenderTextureをシェーダー外部から与えればインタラクティブにインクを塗ったりもできると思います。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>normalize.fmにゲスト出演しました</title>
      <link>https://gam0022.net/blog/2022/10/20/normalizefm/</link>
      <pubDate>Thu, 20 Oct 2022 10:44:48 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2022/10/20/normalizefm/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://normalize.fm/&#34;&gt;normalize.fm&lt;/a&gt;の第032回にゲスト出演させていただきました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/normalizeFM?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#normalizeFM&lt;/a&gt; の新エピソード公開しました。&lt;br&gt;今回は &lt;a href=&#34;https://twitter.com/gam0022?ref_src=twsrc%5Etfw&#34;&gt;@gam0022&lt;/a&gt; さんをゲストに、普段の収録と比較するとかなりテックな話題に寄った感じで、深い技術の話をいろいろうかがいました。&lt;br&gt;&lt;br&gt;032. たゆまぬ努力とキャッチアップ&lt;a href=&#34;https://t.co/acML0WOwYQ&#34;&gt;https://t.co/acML0WOwYQ&lt;/a&gt;&lt;/p&gt;&amp;mdash; h_doxas (@h_doxas) &lt;a href=&#34;https://twitter.com/h_doxas/status/1582287588978618369?ref_src=twsrc%5Etfw&#34;&gt;October 18, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>レイトレ合宿8参加レポート</title>
      <link>https://gam0022.net/blog/2022/10/17/rtcamp8/</link>
      <pubDate>Mon, 17 Oct 2022 10:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2022/10/17/rtcamp8/</guid>
      <description>&lt;p&gt;9月2日(金)～9月4日(日)に沖縄本島で開催された&lt;a href=&#34;https://sites.google.com/view/raytracingcamp8/&#34;&gt;レイトレ合宿8&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;自作のレンダラーでこんな動画を &lt;strong&gt;10分の制限時間&lt;/strong&gt; でレンダリングして5位をいただきました！&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/c7JqEpaR658&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;レイマーチングとポリゴンをハイブリッドに描画できる単方向パストレーシングのレンダラーをOptiXで開発して16人中7位でした。&lt;br&gt;&lt;br&gt;レンダリング時間は10分（1フレーム2秒）だったので、&lt;br&gt;NEEやMISなどサンプリングの高速化も行いました。&lt;br&gt;&lt;br&gt;動画は本戦で実際に出力されたファイルです。&lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt; &lt;a href=&#34;https://t.co/LDgKL7gLsY&#34;&gt;pic.twitter.com/LDgKL7gLsY&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1566269176314220544?ref_src=twsrc%5Etfw&#34;&gt;September 4, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;コロナの影響もあり、3年ぶりのレイトレ合宿でした…！&lt;/p&gt;

&lt;p&gt;台風11号がちょうど沖縄に直撃してしまい、天候には恵まれなかったのは残念でしたが、とても充実した合宿でした。&lt;/p&gt;

&lt;p&gt;合宿の様子や雰囲気を詳しく知りたい方は、Ki_NaN_komotiさんのブログ記事がオススメです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;２週間ぐらい経ちましたがレイトレ合宿の参加レポートを書きました&lt;br&gt;&lt;br&gt;レンダラー開発記とレイトレ合宿の様子を書いています&lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt;&lt;a href=&#34;https://t.co/Fhtvuz9n2H&#34;&gt;https://t.co/Fhtvuz9n2H&lt;/a&gt;&lt;/p&gt;&amp;mdash; Ki_NaN_komoti (@Kinakomoti2357) &lt;a href=&#34;https://twitter.com/Kinakomoti2357/status/1571122433763184640?ref_src=twsrc%5Etfw&#34;&gt;September 17, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;本戦用のレンダラーの解説&#34;&gt;本戦用のレンダラーの解説&lt;/h1&gt;

&lt;p&gt;こちらが本戦のプレゼン資料です。&lt;/p&gt;

&lt;div class=&#34;google-slide-wrap&#34;&gt;
&lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vTTvbJ3UILqFymar8yG4VOomRdeJzfeS8zoehGZruGQCmq8A2cQ4rru3WYfZdi3xRD4PkE3yamqRHjt/embed?start=false&amp;loop=false&amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;1440&#34; height=&#34;839&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;GitHubに&lt;a href=&#34;https://github.com/gam0022/redflash_rtcamp8&#34;&gt;リポジトリ&lt;/a&gt;も公開しています。急いで実装したので品質は低いです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/09/18/rtcamp7/&#34;&gt;前回のレイトレ合宿7&lt;/a&gt;で開発したRedflashというレンダラーを動画に対応させました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/slide_p2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/slide_p2.png&#34; alt=&#34;スライド 基本機能&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;前回までにこれらの基本的な機能は実装していました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;単方向のパストレーシング&lt;/li&gt;
&lt;li&gt;Disney BRDF&lt;/li&gt;
&lt;li&gt;NEE&lt;/li&gt;
&lt;li&gt;MIS&lt;/li&gt;
&lt;li&gt;レイマーチングの衝突判定（OptiXのカスタムプリミティブとして実装）&lt;/li&gt;
&lt;li&gt;ACES Filmic Tone Mapping&lt;/li&gt;
&lt;li&gt;Deep Learning Denoising（ディープラーニングによるデノイザー、OptiXを使えば簡単に利用できる）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今年から静止画部門が廃止されたので、動画部門への対応を行いました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;アニメーション（シーンの動的な更新）&lt;/li&gt;
&lt;li&gt;動画のための画像の連番出力&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;レンダラーの出力設定&#34;&gt;レンダラーの出力設定&lt;/h2&gt;

&lt;p&gt;出力解像度の高さ・フレーム数の多さは、分かりやすくアピールポイントになるので、ギリギリを攻めました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;解像度は1920x1080&lt;/li&gt;
&lt;li&gt;フレーム数は300（30FPS * 10秒）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;制限時間は10分（600秒）なので、1フレームあたりの時間は2秒でした。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;長さは3秒以上10秒以下&lt;/code&gt; というレギュレーションだったので、上限の10秒にしました。&lt;/p&gt;

&lt;p&gt;パストレーシングの場合はゆったりしたアニメーションの方が映えそうなので、60FPSではなく30FPSにしました。
普通のPCのモニターのリフレッシュレートは60Hzだと思うので、24FPSなど中途半端なのは選択肢から除外していました。&lt;/p&gt;

&lt;p&gt;PNGの保存（エンコード＋ファイル保存）と、レンダリングは別スレッドで並列実行するようにしました。
解像度は2160pにするとPNGのエンコード時間がレンダリングよりもボトルネックになるので1080pを選びました。&lt;/p&gt;

&lt;p&gt;前回のレイトレ合宿7の本戦の静止画部門では、1フレームに60秒使えました。
使える時間が30分の1まで急激に短くなったのは大変でした。&lt;/p&gt;

&lt;p&gt;さらに実行環境（AWSのEC2インスタンス）も大幅にスペックダウンしていたのも痛手でした。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;p3.16xlarge（レイトレ合宿7）&lt;/li&gt;
&lt;li&gt;g4dn.xlarge（レイトレ合宿8）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;g4dn.xlargeではRTコアが使えるようになったようですが、レイマーチングが主なので自分の場合は恩恵があまりありませんでした…&lt;/p&gt;

&lt;h2 id=&#34;optixのバージョンについて&#34;&gt;OptiXのバージョンについて&lt;/h2&gt;

&lt;p&gt;今回は最新のOptiX7でレンダラーを実装しようと思ったのですが、最終的には前回と同じOptiX6で提出しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/blog/2022/08/08/raymarching-vs-raycasting/&#34;&gt;アドベントカレンダー&lt;/a&gt;ではOptiX7で実装をしていました。&lt;/p&gt;

&lt;p&gt;OptiX7ではなぜかポリゴンとレイマーチングのプリミティブを混在するとパフォーマンスが異常に悪化する問題が発生してしまい、これを解決する方法が見つからず、提出まで時間もなかったので諦めてOptiX6を採用しました。&lt;/p&gt;

&lt;p&gt;もしパフォーマンスの問題を解決できたとしても、OptiX7はかなり低レイヤーのAPIになっていたので、何かしらのラッパーを開発しないと使うのは大変に思いました。セットアップするだけでもかなり大量のコードの実装が必要でした。&lt;/p&gt;

&lt;h2 id=&#34;アニメーション要素&#34;&gt;アニメーション要素&lt;/h2&gt;

&lt;p&gt;10秒の尺に3種類のアニメーション要素を詰め込みました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ライトのアニメーション&lt;/li&gt;
&lt;li&gt;レイマーチングのパラメーターのアニメーション&lt;/li&gt;
&lt;li&gt;マテリアルのアニメーション&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;動画の内容もそれぞれのアニメーションの要素を1つ1つ紹介するような感じにしました。&lt;/p&gt;

&lt;h3 id=&#34;ライトのアニメーション&#34;&gt;ライトのアニメーション&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/light_animation_960.gif&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/light_animation_960.gif&#34; alt=&#34;ライトのアニメーション&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2つのポイントライトをアニメーションしました。&lt;/p&gt;

&lt;p&gt;OptiX6系では以下のようにmarkDirtyしてからlaunchすることでアクセラレーション構造を更新できました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;light_group-&amp;gt;getAcceleration()-&amp;gt;markDirty();
light_group-&amp;gt;getContext()-&amp;gt;launch(0, 0, 0);

top_group_light-&amp;gt;getAcceleration()-&amp;gt;markDirty();
top_group_light-&amp;gt;getContext()-&amp;gt;launch(0, 0, 0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;シーン内のプリミティブの数が少ないので、このあたりは工夫しなくてもパフォーマンス上の問題はありませんでした。&lt;/p&gt;

&lt;p&gt;NEE用にライトの情報の構造体の配列（ComputeShaderのStructuredBufferのようなもの）を渡しているので、これも毎フレーム更新が必要でした。&lt;/p&gt;

&lt;h3 id=&#34;レイマーチングのパラメーターのアニメーション&#34;&gt;レイマーチングのパラメーターのアニメーション&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/raymarching-animation_960.gif&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/raymarching-animation_960.gif&#34; alt=&#34;レイマーチングのパラメーターのアニメーション&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;せっかくレイマーチングでフラクタル（Mandelboxの軽量版）を描画しているので、フラクタルのパラメーターをアニメーションさせてみました。&lt;/p&gt;

&lt;p&gt;CUDAでtimeを受け取るようにして、timeを元にパラメーターをアニメーションしているだけなので、とても簡単に実装できました。&lt;/p&gt;

&lt;h3 id=&#34;マテリアルのアニメーション&#34;&gt;マテリアルのアニメーション&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/menger_960.gif&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/menger_960.gif&#34; alt=&#34;マテリアルのアニメーション&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;マテリアルのパラメーターをアニメーション可能にして、ここではEmissiveをアニメーションさせるようにしました。&lt;/p&gt;

&lt;p&gt;Emissiveのアニメーションが映えるように、MengerSpongeにしました。平面が多いので光の反射が綺麗に見せられるかなと思ってこうなりました。
roughnessなどひたすら微調整して、最終的に気に入るルックにできました。&lt;/p&gt;

&lt;p&gt;実装的にはマテリアルのパラメーターを更新する専用のCallable Program（OptiX用語で関数ポインターのようなもの）を定義しました。&lt;/p&gt;

&lt;p&gt;CUDAの関数で好き勝手にアニメーションできるようにしました。&lt;/p&gt;

&lt;h2 id=&#34;アダプティブなeps&#34;&gt;アダプティブなeps&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/zoom-out_960.gif&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/zoom-out_960.gif&#34; alt=&#34;ズームアウト&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;前回のレイトレ合宿に引き続き、今回もアダプティブなeps計算をしています。&lt;/p&gt;

&lt;p&gt;カメラからの距離に応じてレイマーチングの衝突判定につかうepsを変化させることで、実質的なLODのようなことをしています。&lt;/p&gt;

&lt;p&gt;カメラ距離が変化してもちょうど良い感じのディテールでフラクタルを描画することができました。&lt;/p&gt;

&lt;h2 id=&#34;デバッグ機能&#34;&gt;デバッグ機能&lt;/h2&gt;

&lt;h3 id=&#34;wasd機能&#34;&gt;WASD機能&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/wasd-v1.gif&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/wasd-v1.gif&#34; alt=&#34;WASD機能&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;いい感じのカメラアングルを探るためにWASDでカメラを移動できるようにしました。&lt;/p&gt;

&lt;p&gt;余談ですが、Unityのシーンビューの右クリックでも同じようなことができます。Unityでカメラワークを実装するときもこの機能をよく活用しています。&lt;/p&gt;

&lt;h3 id=&#34;デバッグ用のレンダラー&#34;&gt;デバッグ用のレンダラー&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/redflash_debug_render.gif&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/redflash_debug_render.gif&#34; alt=&#34;デバッグ用のレンダラー&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;パストレーシングで描画すると処理が重くてフレーム落ちするのでアニメーションの確認には適しません。&lt;/p&gt;

&lt;p&gt;アニメーションをリアルタイムに確認できるように、レンダリングの品質を落としたデバッグ用のレンダラーも実装しました。&lt;/p&gt;

&lt;h2 id=&#34;awsの上限緩和申請は早めにやろう&#34;&gt;AWSの上限緩和申請は早めにやろう&lt;/h2&gt;

&lt;p&gt;AWSの上限緩和申請（4vCPU）は時間がかかる場合もあるので、提出直前にやるのは良くなかったです。&lt;/p&gt;

&lt;p&gt;他の参加者からはすぐに申請が通ったという声も聞いたので、自分だけ担当者ガチャに外れただけの可能性はあります。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;AWSの上限緩和申請(4vCPU)、1週間くらいかかったな&lt;br&gt;&lt;br&gt;申請: 2022/08/23 1:49&lt;br&gt;承認: 2022/08/29 10:37&lt;br&gt;&lt;br&gt;もっと事前にやっておくべきだった…&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1564068725212360704?ref_src=twsrc%5Etfw&#34;&gt;August 29, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;セミナー資料&#34;&gt;セミナー資料&lt;/h1&gt;

&lt;p&gt;レイトレ合宿ではセミナーも行われます。&lt;/p&gt;

&lt;p&gt;今年は参加者全員で発表を行ったので、朝から晩までたくさんのセミナーを聞くことができました。&lt;/p&gt;

&lt;div class=&#34;google-slide-wrap&#34;&gt;
&lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vSdZQILhwkXvTsW024mmgc5V0G0sdFY2CQ1a5GtN953__e5drmPzBqVqr1qin2EtZOelzu6cl9IT9M2/embed?start=false&amp;loop=false&amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;1440&#34; height=&#34;839&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;私は「レイマーチングのすすめ」という発表をしました。&lt;/p&gt;

&lt;p&gt;過去資料を参照しながら、レイマーチングについて個人的に意外だと感じる部分や、Shadertoyなどで使わているテクニックについて、広く浅く紹介しました。&lt;/p&gt;

&lt;p&gt;口頭での説明が前提の発表なので、資料だけでは分かりにくいと思いますが、雰囲気だけでも伝わればと思います。&lt;/p&gt;

&lt;h1 id=&#34;印象に残った作品&#34;&gt;印象に残った作品&lt;/h1&gt;

&lt;p&gt;どの作品も工夫があって面白かったのですが、その中でも個人的にかなり印象に残った作品をピックアップしました。&lt;/p&gt;

&lt;p&gt;たた (@8picoz) さんがRust 100%のGPUレンダラーを開発していて、前々回のレイトレ合宿までは私もRustを使っていたということもあり、個人的にとても参考にしたいと思いました。
Vulkanのレイトレーシング機能をつかっていて、VulkanではSPIR-Vというシェーダーの中間コードの仕組みが使えるようになっているので、任意の言語でシェーダーを実装できるようになりました。
SPIR-Vをつかうことで、GPUコードもRustで実装をしたそうです。すごい良さそう！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;こんな感じの動画をレンダリングして11位でした！ &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt; &lt;a href=&#34;https://t.co/aSEekYHQgr&#34;&gt;pic.twitter.com/aSEekYHQgr&lt;/a&gt;&lt;/p&gt;&amp;mdash; たた (@8picoz) &lt;a href=&#34;https://twitter.com/8picoz/status/1566239120065982465?ref_src=twsrc%5Etfw&#34;&gt;September 4, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;うしお (@ushiostarfish) さんはNeRFで絵を出していました。
既存の機械学習のライブラリを使わずに、CUDAでスクラッチ実装したとのことだったので、個人的にとても驚きした。
学習のための写真も自分で苦労して撮影したという裏話も聞けて良かったです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;一発ネタのNeRFで、もはやレイトレなのか分からなくなってきましたが、思いのほか反響があってよかったです！&lt;br&gt;実装と解説スライドなどこちらにあります&lt;a href=&#34;https://t.co/YdeNXrIYBF&#34;&gt;https://t.co/YdeNXrIYBF&lt;/a&gt;&lt;br&gt;&lt;br&gt;運営の皆さま、今年も大変お疲れ様でございました！大変充実したイベントをありがとうございました！&lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt;&lt;/p&gt;&amp;mdash; うしお (@ushiostarfish) &lt;a href=&#34;https://twitter.com/ushiostarfish/status/1568187460596953093?ref_src=twsrc%5Etfw&#34;&gt;September 9, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Shocker (@Shocker_0x15) さんのNeural Radiance Cachingをボリュームに適用して高速化をしていました。
他の参加者と差別化できていて、結果も綺麗ですごいと思いました。機械学習の波がレイトレ合宿にも来ているのを感じました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;3年ぶりの &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt; 8でMulti-scatteringな雲の動画をレンダリングして1位を頂きました！&lt;br&gt;普通にやると重すぎて間に合わないのでNeural Radiance Cachingをボリュームに適用して高速化しました。&lt;br&gt;&lt;br&gt;レンダラー紹介スライド&lt;a href=&#34;https://t.co/ry4W70XcgI&#34;&gt;https://t.co/ry4W70XcgI&lt;/a&gt; &lt;a href=&#34;https://t.co/82OFf5rYue&#34;&gt;pic.twitter.com/82OFf5rYue&lt;/a&gt;&lt;/p&gt;&amp;mdash; Shocker (@Shocker_0x15) &lt;a href=&#34;https://twitter.com/Shocker_0x15/status/1566267613440684033?ref_src=twsrc%5Etfw&#34;&gt;September 4, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;hole (@h013) はゴールベースコースティクスを実装していました。分散の発生する処理がほとんどなく、Deterministicに結果が決まるそうで、ノイズがまったくないめちゃくちゃ綺麗な結果でした。
他の参加者と違うアプローチで差別化ができていて、結果もめちゃくちゃ綺麗でいいなと思いました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;レイトレ合宿終わりました。皆さんありがとうござました！&lt;br&gt;&lt;br&gt;僕はコースティクスを実装し、こんな感じの動画をレンダリングして４位でした。 &lt;br&gt;&lt;br&gt; &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt; &lt;a href=&#34;https://t.co/NbHutC9KtB&#34;&gt;pic.twitter.com/NbHutC9KtB&lt;/a&gt;&lt;/p&gt;&amp;mdash; hole (@h013) &lt;a href=&#34;https://twitter.com/h013/status/1566238238959759361?ref_src=twsrc%5Etfw&#34;&gt;September 4, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Shinji Ogaki (@ShinjiOgaki) さんはCPUレンダラーかつデノイズしないという条件で、ノイズがまったくない綺麗な絵を出していて、圧倒的な実装力の違いを見せつけられました。強者の風格をとても感じる作品でした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;記事はまる一日で3000くらい閲覧があったようなので、合宿に興味がある人が多いのかも？&lt;br&gt;せっかくなので、少し尺の長い動画を載せておきます。&lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/generative?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#generative&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/creativecoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#creativecoding&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/processing?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#processing&lt;/a&gt; &lt;a href=&#34;https://t.co/RqMLxaUIMX&#34;&gt;pic.twitter.com/RqMLxaUIMX&lt;/a&gt;&lt;/p&gt;&amp;mdash; Shinji Ogaki (@ShinjiOgaki) &lt;a href=&#34;https://twitter.com/ShinjiOgaki/status/1566909271043817472?ref_src=twsrc%5Etfw&#34;&gt;September 5, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;年々と制限時間が短くなっているのに、ほとんどの参加者はノイズのない綺麗なレンダリング結果を出していて、参加者のレベルがどんどんインフレしているのを感じました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/time-limit.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/time-limit.png&#34; alt=&#34;レイトレ合宿の時間制限の遷移&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;もはやノイズの少ない絵を出すだけでは差別化が難しいので、それぞれの参加者がユニークな切り口で勝負してくるハイレベルな戦いでした。&lt;/p&gt;

&lt;p&gt;今年のセミナーは参加者全員で発表しました。参加者のバックグラウンドもさまざまだったので、いろんな分野の興味深い話や深い話を聞くことができて楽しかったです。&lt;/p&gt;

&lt;p&gt;レイトレ合宿を運営の方々、その他の参加者のみなさん、本当にありがとうございました！&lt;/p&gt;

&lt;h1 id=&#34;写真コーナー&#34;&gt;写真コーナー&lt;/h1&gt;

&lt;p&gt;天候には恵まれませんでしたが、ホテルがめちゃくちゃ豪華だったり、美味しいご飯を食べたりして沖縄を満喫しました。&lt;/p&gt;

&lt;p&gt;写真から雰囲気が少しでも伝われば幸いです。&lt;/p&gt;

&lt;p&gt;ホテルは棟ごと貸し切りをしました！まるでレンダリング用のシーンのようにピカピカなお部屋でした！すごい！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-1.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-1.jpg&#34; alt=&#34;ホテルの様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-2.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-2.jpg&#34; alt=&#34;ホテルの様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-3.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-3.jpg&#34; alt=&#34;ホテルの様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-4.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-4.jpg&#34; alt=&#34;ホテルの様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-5.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-5.jpg&#34; alt=&#34;ホテルの様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-6.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/hotel-6.jpg&#34; alt=&#34;ホテルの様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;沖縄の料理なども堪能しました。合宿自体は2泊でしたが、個人的に延泊して4泊したので料理の写真が多くなっています。&lt;/p&gt;

&lt;p&gt;しまぶた屋　地酒の飲み比べ
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-1.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-1.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;海ぶどう　茶碗蒸し
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-2.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-2.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;なかゆくい　ハブ酒
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-3.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-3.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;なかゆくい　マンゴーのかき氷
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-4.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-4.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;アメリカ食堂
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-5.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-5.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;タコライスcafe きじむなぁ
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-6.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-6.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;琉球ダイニング 桃香
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-7.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-7.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;沖縄のブルーシールアイスクリーム BLUE SEAL
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-8.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-8.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-9.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-9.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ステーキハウス88
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-10.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-10.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-11.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-11.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;土～夢 ごはんカフェ 琉球ガラス村店（ドーム）
食器がおしゃれ
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-12.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/food-12.jpg&#34; alt=&#34;沖縄の料理の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;琉球ガラス村のエントランス
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-1.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-1.jpg&#34; alt=&#34;沖縄の観光の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;DMMかりゆし水族館
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-2.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-2.jpg&#34; alt=&#34;沖縄の観光の様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-3.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-3.jpg&#34; alt=&#34;沖縄の観光の様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-4.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-4.jpg&#34; alt=&#34;沖縄の観光の様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-5.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-5.jpg&#34; alt=&#34;沖縄の観光の様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-6.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-6.jpg&#34; alt=&#34;沖縄の観光の様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-7.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-7.jpg&#34; alt=&#34;沖縄の観光の様子&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-8.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/sightseeing-8.jpg&#34; alt=&#34;沖縄の観光の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;本戦の景品です。組み立て式の時計でした。グリニッチ天文台で購入したものだそうです。
&lt;a href=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/gift.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-09-26-rtcamp8/gift.jpg&#34; alt=&#34;景品&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;!--

# 関連商品

レンダラー名の由来となった楽曲です。プリパラを見てください。

&lt;iframe sandbox=&#34;allow-popups allow-scripts allow-modals allow-forms allow-same-origin&#34; style=&#34;width:120px;height:240px;&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; src=&#34;//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=000000&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=gam00220c-22&amp;language=ja_JP&amp;o=9&amp;p=8&amp;l=as4&amp;m=amazon&amp;f=ifr&amp;ref=as_ss_li_til&amp;asins=B06Y3Z1PTK&amp;linkId=e1fef8b2771937a4232c7850b5dca2da&#34;&gt;&lt;/iframe&gt;

--&gt;</description>
    </item>
    
    <item>
      <title>速度比較！レイマーチングvsレイキャスティング</title>
      <link>https://gam0022.net/blog/2022/08/08/raymarching-vs-raycasting/</link>
      <pubDate>Mon, 08 Aug 2022 02:12:50 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2022/08/08/raymarching-vs-raycasting/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;https://sites.google.com/view/raytracingcamp8&#34;&gt;レイトレ合宿8&lt;/a&gt;のアドベントカレンダーです。&lt;/p&gt;

&lt;p&gt;レイマーチングはレイキャスティングと比べて遅いと感じていましたが、なるべく同じ条件で計測した場合に実際どのくらい差があるのか比較してみました。&lt;/p&gt;

&lt;h1 id=&#34;検証内容の概要&#34;&gt;検証内容の概要&lt;/h1&gt;

&lt;p&gt;メンガーのスポンジをレイマーチングとレイキャスティングでそれぞれ交差判定を実装し、フラクタルの深度を1～4に変化しながら計測しました。&lt;/p&gt;

&lt;p&gt;次の画像はレイマーチングによる深度4のメンガーのスポンジです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i4_s256_l300.png&#34; alt=&#34;レイマーチング 深度4 300ステップ&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;計測結果のサマリー&#34;&gt;計測結果のサマリー&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;先に結果から発表すると、なんとレイマーチングはレイキャスティングの15～20倍くらい遅いようでした。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ここまで遅いなんてショック😨…&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/result_graph.png&#34; alt=&#34;計測結果の棒グラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;256サンプリング時のレンダリング時間（秒）&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;フラクタルの深度&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;レイマーチング&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.85388秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i1_s256.png&#34; alt=&#34;レイマーチング 深度1&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.00077秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i2_s256.png&#34; alt=&#34;レイマーチング 深度2&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.14309秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i3_s256.png&#34; alt=&#34;レイマーチング 深度3&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.29724秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i4_s256.png&#34; alt=&#34;レイマーチング 深度4&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;レイキャスティング&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.445493秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i1_s256.png&#34; alt=&#34;レイキャスティング 深度1&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.466056秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i2_s256.png&#34; alt=&#34;レイキャスティング 深度2&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50258秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i3_s256.png&#34; alt=&#34;レイキャスティング 深度3&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.602458秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i4_s256.png&#34; alt=&#34;レイキャスティング 深度4&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;検証内容の詳細&#34;&gt;検証内容の詳細&lt;/h1&gt;

&lt;h2 id=&#34;検証pcのスペック&#34;&gt;検証PCのスペック&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;OS: Windows 11&lt;/li&gt;
&lt;li&gt;CPU: Core i7-12700K&lt;/li&gt;
&lt;li&gt;GPU: GeForce RTX 3080&lt;/li&gt;
&lt;li&gt;メモリ: 64GB (3200MHz)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このピカピカ光るPCで検証しました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;my new gear&amp;hellip; &lt;a href=&#34;https://t.co/eS2MbH7OKc&#34;&gt;pic.twitter.com/eS2MbH7OKc&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1546700194305437696?ref_src=twsrc%5Etfw&#34;&gt;July 12, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;共通条件&#34;&gt;共通条件&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;レンダラーはNVIDIA OptiX 7.5上で実装&lt;/li&gt;
&lt;li&gt;256サンプリングする時間を計測

&lt;ul&gt;
&lt;li&gt;1回のoptixLaunchで256サンプリング&lt;/li&gt;
&lt;li&gt;Ray generationプログラム（CUDAの関数）の中で256回ループ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;出力解像度は1920x1080&lt;/li&gt;
&lt;li&gt;計測時間の詳細

&lt;ul&gt;
&lt;li&gt;シーンの初期化やBVHの構築は含まない&lt;/li&gt;
&lt;li&gt;optixLaunchの実行時間を計測&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;シェーディングはパストレーシング

&lt;ul&gt;
&lt;li&gt;マテリアルは拡散反射のみ&lt;/li&gt;
&lt;li&gt;NEEやMISはしないシンプルなパストレーシング&lt;/li&gt;
&lt;li&gt;反射の最大深度は5&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;シーン全体で2つのGAS

&lt;ul&gt;
&lt;li&gt;床（巨大なカスタムプリミティブのSphere）のGASが1つ&lt;/li&gt;
&lt;li&gt;メンガーのスポンジのGASが1つ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;レイマーチング&#34;&gt;レイマーチング&lt;/h2&gt;

&lt;p&gt;レイマーチングは繰り返しの計算によって数値的に衝突判定を解く手法で、Sphere Tracingとも呼ばれます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;レイマーチングの最大ステップ回数（マーチングループのループ数）は100&lt;/li&gt;
&lt;li&gt;Intersectionプログラム（CUDAの関数）としてレイマーチングを実装

&lt;ul&gt;
&lt;li&gt;詳細は&lt;a href=&#34;https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/&#34;&gt;過去の記事&lt;/a&gt;を参照&lt;/li&gt;
&lt;li&gt;Optix6の内容なので、Optix7対応のために実装を多少修正&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;高速化のためにカメラからレイは飛ばさずに、バウンディングボックス（AABB）からレイを飛ばす

&lt;ul&gt;
&lt;li&gt;AABBは最適になるようにギリギリに設定&lt;/li&gt;
&lt;li&gt;カスタムプリミティブ全体で1つのAABB&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;レイキャスティング&#34;&gt;レイキャスティング&lt;/h2&gt;

&lt;p&gt;今回のレイキャスティングとは、レイと三角形の解析的な交差判定のことです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;メンガースポンジはHoudiniでモデリング

&lt;ul&gt;
&lt;li&gt;詳細は&lt;a href=&#34;https://gam0022.net/blog/2018/06/08/houdini/&#34;&gt;過去の記事&lt;/a&gt;を参照&lt;/li&gt;
&lt;li&gt;フラクタルの深度を指定可能にアップデート（ツイート参照）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Houdiniからobjで出力して自作のレンダラーで読み込み

&lt;ul&gt;
&lt;li&gt;OptiX7.xではobjのローダーが無かったので自作…&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OptiXのビルトインの機能で衝突判定

&lt;ul&gt;
&lt;li&gt;OptiX上では三角ポリゴンの集合として表現&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OptiXの機能でGAS（Geometry acceleration structure）を構築

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RTコアによるレイトレーシングのハードウェアアクセラレーションあり&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;フラクタルの再帰回数を自由に増やせるようになった。&lt;br&gt;HoudiniのTOPs Feedback Loopの良い使用例ですね。 &lt;a href=&#34;https://t.co/yTR60S5vgC&#34;&gt;https://t.co/yTR60S5vgC&lt;/a&gt; &lt;a href=&#34;https://t.co/OifBfoTCFa&#34;&gt;pic.twitter.com/OifBfoTCFa&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1556203400257503232?ref_src=twsrc%5Etfw&#34;&gt;August 7, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;結果詳細&#34;&gt;結果詳細&lt;/h1&gt;

&lt;p&gt;改めて計測結果を見てみましょう。&lt;/p&gt;

&lt;h2 id=&#34;レンダリング時間&#34;&gt;レンダリング時間&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/result_graph.png&#34; alt=&#34;計測結果の棒グラフ&#34; /&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;フラクタルの深度&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;レイマーチング&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.85388&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.00077&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.14309&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.29724&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;レイキャスティング&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.445493&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.466056&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50258&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.602458&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;レンダリング時間以外&#34;&gt;レンダリング時間以外&lt;/h2&gt;

&lt;p&gt;レンダリング時間以外のデータです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GAS（Geometry Acceleration Structure）の構築時間（秒）

&lt;ul&gt;
&lt;li&gt;レイキャスティングのみの結果&lt;/li&gt;
&lt;li&gt;レイマーチングではAABBはできてもBVHを構築できない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ポリゴンの頂点数&lt;/li&gt;
&lt;li&gt;レイマーチングがレイキャスティングの何倍の時間がかかっているか&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;フラクタルの深度&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;GASの構築時間（秒）&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0008289&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0010064&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0030907&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0135217&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ポリゴンの頂点数&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;480&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9600&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;192000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3840000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;倍率（Raymarching / Raycasting）&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.87434146&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.31263625&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18.19230769&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15.4321795&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;GASの構築は思ったより速いんですね。380万頂点でも0.01秒で完了しているのは驚きです。&lt;/p&gt;

&lt;p&gt;ポリゴンの頂点数は指数で増加しても描画時間は大きく変わらないので、Acceleration Structureは本当に偉大ですね🙏&lt;/p&gt;

&lt;p&gt;倍率について、フラクタルの深度が増えればレイマーチングの方が有利だと予想していましたが、予想通りにその傾向はありました。
ですが、思ったよりも差が縮まらないんだというのが率直な感想です。&lt;/p&gt;

&lt;h2 id=&#34;レンダリング結果&#34;&gt;レンダリング結果&lt;/h2&gt;

&lt;p&gt;大きなサイズのレンダリング結果です。&lt;/p&gt;

&lt;p&gt;異なるアルゴリズムでモデリングしているので、ジオメトリーは完全一致ではありません。&lt;/p&gt;

&lt;p&gt;記事を書いている途中で発覚しましたが、レイマーチングのステップ回数100では上部の法線とレイの角度が急な箇所でエラーが起きていました。
サムネではステップ回数300に増やして再レンダリングして15.7267秒でした。&lt;/p&gt;

&lt;h3 id=&#34;レイマーチング-深度1&#34;&gt;レイマーチング 深度1&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i1_s256.png&#34; alt=&#34;レイマーチング 深度1&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイマーチング-深度2&#34;&gt;レイマーチング 深度2&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i2_s256.png&#34; alt=&#34;レイマーチング 深度2&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイマーチング-深度3&#34;&gt;レイマーチング 深度3&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i3_s256.png&#34; alt=&#34;レイマーチング 深度3&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイマーチング-深度4&#34;&gt;レイマーチング 深度4&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i4_s256.png&#34; alt=&#34;レイマーチング 深度4&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイキャスティング-深度1&#34;&gt;レイキャスティング 深度1&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i1_s256.png&#34; alt=&#34;レイキャスティング 深度1&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイキャスティング-深度2&#34;&gt;レイキャスティング 深度2&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i2_s256.png&#34; alt=&#34;レイキャスティング 深度2&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイキャスティング-深度3&#34;&gt;レイキャスティング 深度3&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i3_s256.png&#34; alt=&#34;レイキャスティング 深度3&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイキャスティング-深度4&#34;&gt;レイキャスティング 深度4&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i4_s256.png&#34; alt=&#34;レイキャスティング 深度4&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;レイマーチングの高速化手法&#34;&gt;レイマーチングの高速化手法&lt;/h1&gt;

&lt;p&gt;レイマーチングの高速化手法を軽く調べてみました。&lt;/p&gt;

&lt;p&gt;EnhancedSphereTracingやAccelerating Sphere Tracingはレイマーチングのステップを少し大きく調整してステップ数を減らす手法です。
IFSやMod Repetitionと乱数の組み合わせによる非連続な距離関数だとうまくいかない気もしていますが、ちゃんと試したことはないので分かりません。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;EnhancedSphereTracing [Benjamin Keinert 2014]

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://erleuchtet.org/~cupe/permanent/enhanced_sphere_tracing.pdf&#34;&gt;論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/Hirai0827/items/eddcb73a1976c3088b88&#34;&gt;日本語解説 by @lucknknock さん&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Accelerating Sphere Tracing [Csaba Bálint 2018]

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/publication/331547302_Accelerating_Sphere_Tracing&#34;&gt;論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/Hirai0827/items/e05e13f343357d648b1b&#34;&gt;日本語解説 by @lucknknock さん&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cone Marchingは非連続な距離関数でもおそらく適用できそうです。
低解像度でDepthを計算しておいて、高解像度でDepthを引き継いでレイマーチングをすることで、トータルで距離関数の評価回数をかなり削減できます。
しかし、プライマリレイにしか適用できないため、パストレーシングでは効果が低そうです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.fulcrum-demo.org/wp-content/uploads/2012/04/Cone_Marching_Mandelbox_by_Seven_Fulcrum_LongVersion.pdf&#34;&gt;Cone_Marching_Mandelbox_by_Seven_Fulcrum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jp.gamesindustry.biz/article/1803/18032802/&#34;&gt;［GDC 2018］Cone Marching法で描くフラクタルVRの世界「CORAL」&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このあたりはよく読んでいません。自分のための備忘録です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A Geometric Method for Accelerated Sphere Tracing of Implicit Surfaces [Csaba Bálint 2021]

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cyber.bibl.u-szeged.hu/index.php/actcybern/article/view/4203&#34;&gt;論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;後で読む&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Real-Time Rendering of Complex Fractals

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-1-4842-7185-8_33&#34;&gt;リンク&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Real-Time Renderingの章らしいが、単なるレイマーチングの紹介かもしれない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Area Lights in Signed Distance Function Scenes

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://diglib.eg.org/bitstream/handle/10.2312/egs20191021/085-088.pdf?sequence=1&amp;amp;isAllowed=y&#34;&gt;論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;衝突判定ではないが気になるのでメモ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;レイマーチングはめちゃくちゃ遅いので、レイトレ合宿のようにレンダリング時間がシビアなら悪手かもしれません。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tokyo Demo Fest 2021のShader Showdownに参加しました</title>
      <link>https://gam0022.net/blog/2021/12/31/tdf2021-shader-showdown/</link>
      <pubDate>Fri, 31 Dec 2021 00:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2021/12/31/tdf2021-shader-showdown/</guid>
      <description>&lt;p&gt;12月11日～12日にオンラインで開催された&lt;a href=&#34;https://tokyodemofest.jp/&#34;&gt;Tokyo Demo Fest 2021&lt;/a&gt;（以下、TDF）に参加しました。&lt;/p&gt;

&lt;p&gt;TDFは、日本国内で唯一のデモパーティです。
リアルタイムに映像や音楽を生成するプログラムを「デモ」と言い、デモを鑑賞したり完成度を競ったりして楽しむイベントを「デモパーティ」と言います。
「デモシーン」はデモやデモパーティを中心としたコンピューターのサブカルチャーです。&lt;/p&gt;

&lt;p&gt;TDFのShader Showdownというイベントに競技者として参加しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-31-tdf2021-shader-showdown/Collage_Fotor_v3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-31-tdf2021-shader-showdown/Collage_Fotor_v3.jpg&#34; alt=&#34;Collage_Fotor_v3&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;また、TDFのGLSL Graphics Compoにも参加したので、こちらは別記事にまとめました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2021/12/20/tdf2021-glsl/&#34;&gt;Tokyo Demo Fest 2021のGLSL Graphics Compo優勝作品の解説 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;shader-showdownとは&#34;&gt;Shader Showdownとは&lt;/h1&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;TokyoDemoFestのShader Showdownは、世界的なDemoparty「Revision」と同じレギュレーションで開催します。&lt;br&gt;試合の放映はパーティー当日12/11-12となります。乞うご期待……！ &lt;a href=&#34;https://t.co/IlVue5npWz&#34;&gt;pic.twitter.com/IlVue5npWz&lt;/a&gt;&lt;/p&gt;&amp;mdash; Tokyo Demo Fest 2021 (2021/12/11-12) (@TokyoDemoFest) &lt;a href=&#34;https://twitter.com/TokyoDemoFest/status/1452275618997886976?ref_src=twsrc%5Etfw&#34;&gt;October 24, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Shader Showdownとは25分間でシェーダーを書き、どちらの作品が良いかを決める競技です。&lt;/p&gt;

&lt;p&gt;試合中は、一切のドキュメントの参照ができません。当然ながら必要な関数はすべて試合中に実装しないいけません。
時間が25分しかないので、バグを生み出すと修正する時間はありません。世界的なDemoparty「Revision」に準拠しためちゃくちゃ厳しいレギュレーションでの開催でした。&lt;/p&gt;

&lt;p&gt;1対1のトーナメント形式で開催され、試合の勝敗は観衆（ビジター）の投票によって決定します。今回は私を含めた8人でトーナメントを行いました。&lt;/p&gt;

&lt;p&gt;対戦はGLSLのライブコーディングで行われます。&lt;a href=&#34;https://github.com/TheNuSan/Bonzomatic/releases/tag/v11&#34;&gt;Bonzomatic&lt;/a&gt;というアプリを利用し、対戦者の書いているコードやカーソルの位置が共有されます。
Bonzomaticはシェーダーのライブコーディング専用のアプリです。&lt;/p&gt;

&lt;p&gt;次の初期状態のサイケなトンネルはBonzomaticのデフォルトのシェーダーです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-31-tdf2021-shader-showdown/bonzomatic-default.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-31-tdf2021-shader-showdown/bonzomatic-default.jpg&#34; alt=&#34;bonzomaticの初期状態&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;極座標による疑似3Dのシェーダーで汎用性に乏しいため、自分を含めてほどんどの競技者はまず初期状態のコードはコメントアウトするか消します。本当に無からシェーダーを書いています。&lt;/p&gt;

&lt;p&gt;ビジターは対戦者が25分の制限時間の中でどのような戦略とアイデアをもってコードを書いていくかをすぐ隣でみているかのように体験できます。&lt;/p&gt;

&lt;p&gt;詳しいGLSLライブコーディングの知識がなくても楽しめるよう、TDFでは対戦者がどのようなコードを書いているかのリアルタイムな解説があります。&lt;/p&gt;

&lt;h1 id=&#34;ライブコーディングした作品解説&#34;&gt;ライブコーディングした作品解説&lt;/h1&gt;

&lt;p&gt;今回のTDFのShader Showdownでライブコーディングした作品を簡単に解説します。&lt;/p&gt;

&lt;p&gt;TDFのShader Showdownの全作品は&lt;a href=&#34;https://livecode.demozoo.org/party_series/174.html&#34;&gt;livecode.demozoo.org&lt;/a&gt;にもアーカイブされています。&lt;/p&gt;

&lt;h2 id=&#34;lightning-tunnel-quarter-final&#34;&gt;Lightning Tunnel | Quarter-Final&lt;/h2&gt;

&lt;p&gt;準々決勝（Quarter-Final）の作品です。&lt;/p&gt;

&lt;p&gt;稲妻が轟くトンネルをイメージして作りました。&lt;/p&gt;

&lt;p&gt;ボリュームレンダリングをしてBloom感を出しています。ボリュームレンダリングの実装が雑なのでアーティファクトが発生しているのですが、むしろ雷の荒々しい感じが再現できて良かったです。&lt;/p&gt;

&lt;p&gt;時間が余ったのでカメラのFoVのアニメーションをしたのですが、ちょっとワープっぽい効果になりました。&lt;/p&gt;

&lt;p&gt;モデリングはIFSでやっています。IFSで狙った形状を出すことは困難なので、パラメーターは事前に調整をして暗記しておきました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;25分でライブコーディングしたシェーダーです。&lt;br&gt;&lt;br&gt;This shader was coded in 25 minutes.&lt;br&gt;&lt;br&gt;Shader showdown quarter-final at &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Bonzomatic?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Bonzomatic&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/LiveCoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#LiveCoding&lt;/a&gt; &lt;a href=&#34;https://t.co/WTw7tHVsbk&#34;&gt;pic.twitter.com/WTw7tHVsbk&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469562828831195140?ref_src=twsrc%5Etfw&#34;&gt;December 11, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/sl3XWM&#34;&gt;Shadertoy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://neort.io/art/c6qm3ls3p9f3hsje6360&#34;&gt;NEORT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;YouTubeのアーカイブ（Day1の2:15頃）です。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/2s9KfMn1J9M?start=8114&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;vj-feat-niko-14-semi-final&#34;&gt;VJ feat. Niko_14 | Semi-Final&lt;/h2&gt;

&lt;p&gt;準決勝（Semi-Final）の作品です。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/himazin917&#34;&gt;Niko_14&lt;/a&gt;さんの音楽がとても素晴らしかったので、音楽と同期したVJに挑戦しました。&lt;/p&gt;

&lt;p&gt;試合の前日に自分の試合の音楽担当はNiko_14さんと聞いたので、そのタイミングでVJをする決意をしました。&lt;/p&gt;

&lt;p&gt;VJっぽい絵を狙ったことが無かったのですが、ほぼ狙い通りのバキバキな感じにできたので良かったです。
シェーダーの構成としてはQuarter-Finalとほぼ同じで、IFSとボリュームレンダリングの組み合わせです。
IFSのパラメーターは適当だったのですが、ちゃんと狙い通りの絵になったので良かったです。&lt;/p&gt;

&lt;p&gt;色はFFT（音楽の周波数ごとのボリューム）に対応していて、低音が赤、中音が緑、高音が青に対応しています。
キックの音が支配的だったので、キックに合わせて赤～ピンクっぽいビームが発生しています。&lt;/p&gt;

&lt;p&gt;Twitterの動画の4秒頃のように、音が切り替わるタイミングでサウンドリアクティブになっているのが分かりやすいと思います。ぜひ音声をONにして再生してください！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;25分でライブコーディングしたシェーダーです。&lt;br&gt;かっこいい音楽は &lt;a href=&#34;https://twitter.com/himazin917?ref_src=twsrc%5Etfw&#34;&gt;@himazin917&lt;/a&gt; さん制作です！&lt;br&gt;&lt;br&gt;This shader was coded in 25 minutes.&lt;br&gt;Sound by &lt;a href=&#34;https://twitter.com/himazin917?ref_src=twsrc%5Etfw&#34;&gt;@himazin917&lt;/a&gt;&lt;br&gt;&lt;br&gt;Shader showdown semi-final at &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Bonzomatic?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Bonzomatic&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/LiveCoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#LiveCoding&lt;/a&gt; &lt;a href=&#34;https://t.co/HzUpd9le3t&#34;&gt;pic.twitter.com/HzUpd9le3t&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469924900257562627?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/NttSRS&#34;&gt;Shadertoy&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;ShadertoyのSoundcloud連携が機能していないため、音楽はNiko_14さんのものではなく、仮です。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;YouTubeのアーカイブ（Day2の1:41頃）です。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/bp37xTVNRrM?start=6086&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;VJっぽいバキバキとした絵の方向性やFFTを用いたサウンドリアクティブなシェーダーはこれまで挑戦したことのないジャンルだったので、新しい方向性を模索する良い経験になりました。&lt;/p&gt;

&lt;p&gt;Semi-Finalでは&lt;a href=&#34;https://twitter.com/kamoshika_vrc&#34;&gt;Kamoshika&lt;/a&gt;さんに負けてしまったのですが、試合後のコメントによると反射の処理には&lt;a href=&#34;https://gam0022.net/blog/2021/06/08/unity-bible2/&#34;&gt;『Unityゲーム プログラミング・バイブル 2nd Generation』の自分の章&lt;/a&gt;を参考にしてくださったそうで、めちゃくちゃありがてぇ🙏となりました。&lt;/p&gt;

&lt;p&gt;Jugem-Tさんも実況による盛り上げありがとうございました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;凄い画同士の殴り合いの中BGMもライブコーディングで生成してる(Niko_14氏)とんでもない光景になっててヤバい&lt;br&gt;&lt;br&gt;Shader Showdown準決勝 gam0022氏 vs Kamoshika氏&lt;br&gt;[LIVE]Tokyo Demo Fest 2021 Day2 &lt;a href=&#34;https://t.co/648ZNFJTxk&#34;&gt;https://t.co/648ZNFJTxk&lt;/a&gt; &lt;a href=&#34;https://twitter.com/YouTube?ref_src=twsrc%5Etfw&#34;&gt;@YouTube&lt;/a&gt;より &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/atG6c8hWiK&#34;&gt;pic.twitter.com/atG6c8hWiK&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jugem-T 𓆡作業中 (@Jugem_T) &lt;a href=&#34;https://twitter.com/Jugem_T/status/1469892859503734787?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;大変でしたが、楽しかったです。&lt;/p&gt;

&lt;p&gt;25分でできる範囲はかなり限られてくるので、詰め込める要素を取捨選択して、ミスをしないように実装するのは思っていたより難しく感じました。25分だとデバッグしている余裕はなくバグを生み出した瞬間に敗戦が濃厚になります。
距離関数も普段はコピペしているので暗記も大変でした。回転行列くらいは導出できるのですが、sdBoxは導出していたら時間がまったく足りません。&lt;/p&gt;

&lt;p&gt;正直に言うと、まさかここまでレベルの高い戦いになるとは思っておらず、参加者のみなさんが凄すぎてちょっと心が折れそうでした。&lt;/p&gt;

&lt;p&gt;とくにFinal（決勝）の&lt;a href=&#34;https://twitter.com/kamoshika_vrc&#34;&gt;Kamoshika&lt;/a&gt; vs &lt;a href=&#34;https://twitter.com/phi16_&#34;&gt;phi16&lt;/a&gt; の戦いは印象深かったです。&lt;/p&gt;

&lt;p&gt;Kamoshikaさんは蝶、phi16さんはライブゲームと、両者とも &amp;ldquo;生命&amp;rdquo; を誕生させていました。偶然にもテーマが一致していてちょっと面白かったです。&lt;/p&gt;

&lt;p&gt;とにかく実装量がえげつなく、これをライブコーディングでやるんだ…と驚かされました。
競技者として参加したことで、25分間でこの量をミスなく実装する困難さは痛いほど理解していたので、なおさら驚かされました。&lt;/p&gt;

&lt;p&gt;両者ともミスなく作品を仕上げており、まさに決勝戦に相応しい素晴らしい戦いを見せていただきました🙏心の底から感動しました。&lt;/p&gt;

&lt;p&gt;世界レベルの実力者の方々と戦えて本当に光栄でした！ありがとうございます！&lt;/p&gt;

&lt;p&gt;Kamoshikaさん&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;25 minutes live coding at Shader Showdown Final.&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/LiveCoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#LiveCoding&lt;/a&gt; &lt;a href=&#34;https://t.co/WeVq82f50E&#34;&gt;pic.twitter.com/WeVq82f50E&lt;/a&gt;&lt;/p&gt;&amp;mdash; Kamoshika (@kamoshika_vrc) &lt;a href=&#34;https://twitter.com/kamoshika_vrc/status/1470360600517971970?ref_src=twsrc%5Etfw&#34;&gt;December 13, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;phi16さん&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;und&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://t.co/qluYGj653s&#34;&gt;pic.twitter.com/qluYGj653s&lt;/a&gt;&lt;/p&gt;&amp;mdash; phi16 (@phi16&lt;em&gt;) &amp;lt;a href=&amp;ldquo;&lt;a href=&#34;https://twitter.com/phi16&#34;&gt;https://twitter.com/phi16&lt;/a&gt;&lt;/em&gt;/status/1470104161320849409?ref_src=twsrc%5Etfw&amp;rdquo;&amp;gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;記録 TDF2021 ShaderShowdown &lt;a href=&#34;https://t.co/mMcSoYwh5U&#34;&gt;https://t.co/mMcSoYwh5U&lt;/a&gt;&lt;/p&gt;&amp;mdash; phi16 (@phi16&lt;em&gt;) &amp;lt;a href=&amp;ldquo;&lt;a href=&#34;https://twitter.com/phi16&#34;&gt;https://twitter.com/phi16&lt;/a&gt;&lt;/em&gt;/status/1470415119708753921?ref_src=twsrc%5Etfw&amp;rdquo;&amp;gt;December 13, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;YouTubeのアーカイブ（Day2の4:27頃）です。&lt;/p&gt;

&lt;p&gt;Finalでは私も実況者の一人として参加しています。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/bp37xTVNRrM?start=16030&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;おつかれさまでした！&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/h2yXCGGBYa&#34;&gt;pic.twitter.com/h2yXCGGBYa&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469999619409350657?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;さいごに、関係者のみなさんに感謝を申し上げます。
TDFのオーガナイザーの方々、Shader Showdownで対戦してくださったgyaboさん、norargsさん、Kamoshikaさん、0b5vrさん、phi16さん、sp4ghetさん、gazさん、実況のamagiさん、doxasさん、hiraiさんmurasaqiさん、音楽を担当したNiko_14さん、寝る前さん、h0ffman1さん、アーカイブ関連でpsenoghさん、Zavieさん、応援してくださった観戦者みなさん、本当にありがとうございました！&lt;/p&gt;

&lt;h1 id=&#34;練習&#34;&gt;練習&lt;/h1&gt;

&lt;p&gt;ライブコーディングの練習中の作品です。&lt;/p&gt;

&lt;p&gt;Quarter-FinalのIFS+ボリュームレンダリングのアプローチは練習中に決めました。&lt;/p&gt;

&lt;p&gt;トンネルのIFSのモデリングもよく見ると面影が残っています。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;情報量を追加（エンコード耐久テスト）&lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Raymarching?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Raymarching&lt;/a&gt; &lt;a href=&#34;https://t.co/uBg43zGOk6&#34;&gt;pic.twitter.com/uBg43zGOk6&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1453405601971666944?ref_src=twsrc%5Etfw&#34;&gt;October 27, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Diamond Variation 🔷 &lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Raymarching?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Raymarching&lt;/a&gt; &lt;a href=&#34;https://t.co/IAEhBgdW5s&#34;&gt;pic.twitter.com/IAEhBgdW5s&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1453768374312263683?ref_src=twsrc%5Etfw&#34;&gt;October 28, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/Shadertoy?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shadertoy&lt;/a&gt; にポートしました。&lt;br&gt;&lt;br&gt;&amp;quot;Diamond Tunnel&amp;quot; by gam0022&lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt;&lt;a href=&#34;https://t.co/oyyz8mop2x&#34;&gt;https://t.co/oyyz8mop2x&lt;/a&gt; &lt;a href=&#34;https://t.co/DXnqCAKY1Z&#34;&gt;pic.twitter.com/DXnqCAKY1Z&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1476576224768331776?ref_src=twsrc%5Etfw&#34;&gt;December 30, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Unity][URP] Y軸ビルボードシェーダー</title>
      <link>https://gam0022.net/blog/2021/12/23/unity-urp-billboard-shader/</link>
      <pubDate>Thu, 23 Dec 2021 10:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2021/12/23/unity-urp-billboard-shader/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;https://qiita.com/advent-calendar/2021/unity&#34;&gt;Unity Advent Calendar 2021&lt;/a&gt;の23日目の記事です。&lt;/p&gt;

&lt;p&gt;前日は&lt;a href=&#34;https://twitter.com/UnagiHuman&#34;&gt;@UnagiHuman&lt;/a&gt;さんの&lt;a href=&#34;https://qiita.com/UnagiHuman/items/7db6c75adea0d5862acf&#34;&gt;「Unityの新MeshAPIでMeshColliderをリアルタイム変形させる」&lt;/a&gt;でした。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;こんな感じのY軸のビルボードをC#スクリプトを使わずに、シェーダーだけで実装しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-23-unity-urp-billboard-shader/Unity-URP-Billboard-trim.gif&#34; alt=&#34;Y軸ビルボード&#34; /&gt;&lt;/p&gt;

&lt;p&gt;GitHubリポジトリ: &lt;a href=&#34;https://github.com/gam0022/unity-urp-shader&#34;&gt;gam0022/unity-urp-shader&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;要約&#34;&gt;要約&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;シェーダーだけでY軸ビルボードを実装&lt;/li&gt;
&lt;li&gt;UnityのURP対応&lt;/li&gt;
&lt;li&gt;回転行列を生成するアプローチなので、プラットフォーム間の違い（Zの方向やUVの上下など）による問題が起きない&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;シェーダーで実装するメリット&#34;&gt;シェーダーで実装するメリット&lt;/h1&gt;

&lt;p&gt;シェーダーでビルボードを計算するメリットはたくさんあります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;C#スクリプトが不要でシェーダーだけで動作する

&lt;ul&gt;
&lt;li&gt;シェーダーのポータビリティは高い&lt;/li&gt;
&lt;li&gt;昔のVRCのようにユーザスクリプトが書けない環境でも使える&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;シーンビュー上でも動作する&lt;/li&gt;
&lt;li&gt;GPU（頂点シェーダー）でビルボード計算ができる

&lt;ul&gt;
&lt;li&gt;ビルボード計算のためのCPU負荷は0&lt;/li&gt;
&lt;li&gt;板ポリの頂点数は4なので、頂点シェーダーでビルボード処理をしても、GPU負荷はかなり軽い&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;シェーダーのコード-全体&#34;&gt;シェーダーのコード（全体）&lt;/h1&gt;

&lt;p&gt;最終的なシェーダーのコードはこちらです。&lt;/p&gt;

&lt;p&gt;単体で動作するので、コピペして使えます。&lt;a href=&#34;https://github.com/gam0022/unity-urp-shader/blob/master/LICENSE&#34;&gt;MITライセンス&lt;/a&gt;です。&lt;/p&gt;

&lt;p&gt;ファイル名: &lt;a href=&#34;https://github.com/gam0022/unity-urp-shader/blob/master/Assets/URP-Shaders/Billboard/Shaders/Unlit-Billboard.shader&#34;&gt;&lt;code&gt;Unlit-Billboard.shader&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// URP-Unlit-Billboard Shader by @gam0022 (MIT Licence)
// https://gam0022.net//blog/2021/12/23/unity-urp-billboard-shader/
Shader &amp;quot;Universal Render Pipeline/Unlit-Billboard&amp;quot;
{
    Properties
    {
        _BaseMap (&amp;quot;Base Map&amp;quot;, 2D) = &amp;quot;white&amp;quot; { }
        _BaseColor (&amp;quot;Base Color&amp;quot;, Color) = (1, 1, 1, 1)
        _Cutoff (&amp;quot;Alpha Cutoff&amp;quot;, Range(0, 1)) = 0.5
    }

    SubShader
    {
        Tags {
            &amp;quot;RenderPipeline&amp;quot; = &amp;quot;UniversalPipeline&amp;quot;
            &amp;quot;RenderType&amp;quot; = &amp;quot;TransparentCutout&amp;quot;
            &amp;quot;Queue&amp;quot; = &amp;quot;AlphaTest&amp;quot;
            &amp;quot;IgnoreProjector&amp;quot; = &amp;quot;True&amp;quot;
        }

        Pass
        {
            Tags { &amp;quot;LightMode&amp;quot; = &amp;quot;UniversalForward&amp;quot; }

            HLSLPROGRAM

            #pragma vertex vert
            #pragma fragment frag

            #include &amp;quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl&amp;quot;

            struct Attributes
            {
                float4 positionOS: POSITION;
                float2 uv: TEXCOORD0;
            };

            struct Varyings
            {
                float4 positionHCS: SV_POSITION;
                float2 uv: TEXCOORD0;
            };

            sampler2D _BaseMap;

            CBUFFER_START(UnityPerMaterial)
            float4 _BaseMap_ST;
            half4 _BaseColor;
            half _Cutoff;
            CBUFFER_END

            Varyings vert(Attributes IN)
            {
                Varyings OUT;

                // 回転行列を生成してビルボード処理をします
                float3 yup = float3(0.0, 1.0, 0.0);
                float3 up = mul((float3x3)unity_ObjectToWorld, yup);

                float3 worldPos = unity_ObjectToWorld._m03_m13_m23;
                float3 toCamera = _WorldSpaceCameraPos - worldPos;
                float3 right = normalize(cross(toCamera, up)) * length(unity_ObjectToWorld._m00_m10_m20);
                float3 forward = normalize(cross(up, right)) * length(unity_ObjectToWorld._m02_m12_m22);

                float4x4 mat = {
                    1, 0, 0, 0,
                    0, 1, 0, 0,
                    0, 0, 1, 0,
                    0, 0, 0, 1,
                };
                mat._m00_m10_m20 = right;
                mat._m01_m11_m21 = up;
                mat._m02_m12_m22 = forward;
                mat._m03_m13_m23 = worldPos;

                float4 vertex = float4(IN.positionOS.xyz, 1);
                vertex = mul(mat, vertex);
                OUT.positionHCS = mul(UNITY_MATRIX_VP, vertex);

                OUT.uv = TRANSFORM_TEX(IN.uv, _BaseMap);
                return OUT;
            }

            half4 frag(Varyings IN): SV_Target
            {
                half4 base = tex2D(_BaseMap, IN.uv);
                clip(base.a - _Cutoff);
                return base * _BaseColor;
            }
            ENDHLSL

        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;解説&#34;&gt;解説&lt;/h1&gt;

&lt;h2 id=&#34;前回の記事との違い&#34;&gt;前回の記事との違い&lt;/h2&gt;

&lt;p&gt;この記事は前回の記事&lt;a href=&#34;https://gam0022.net/blog/2019/07/23/unity-y-axis-billboard-shader/&#34;&gt;[Unity] Y軸ビルボードシェーダーの実装と解説&lt;/a&gt;の改訂版です。以下のような違いがあります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;URP（Universal Render Pipeline）に対応&lt;/li&gt;
&lt;li&gt;ビルボード処理のアプローチを改良（プラットフォーム依存をなくす）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;前回の記事-ビュー変換をスキップ-の欠点&#34;&gt;前回の記事（ビュー変換をスキップ）の欠点&lt;/h3&gt;

&lt;p&gt;前回の記事では、カメラのビュー行列の変換をスキップすることで、ビルボード処理を実装していました。&lt;/p&gt;

&lt;p&gt;Unityではプラットフォーム間の違い（Zの方向やUVの上下など）をビュー行列とプロジェクション行列でうまく吸収する設計になっており、ビュー行列の変換をスキップするとプラットフォームの対応を自力で行う必要が出てきて、かなり面倒でした。
将来的に新しいプラットフォームが増えた時などにシェーダーの修正が必要になる可能性もあり、このアプローチは筋が良くないな、と記事の公開後に思っていました。&lt;/p&gt;

&lt;p&gt;今回紹介する &lt;strong&gt;回転行列を生成するアプローチ&lt;/strong&gt; では、そのようなプラットフォーム依存の問題が起きません。&lt;/p&gt;

&lt;h2 id=&#34;回転行列を生成するアプローチ&#34;&gt;回転行列を生成するアプローチ&lt;/h2&gt;

&lt;p&gt;Unityが生成するモデル行列を使わずに、頂点シェーダーの中でうまく回転行列を生成することで、常にカメラ側を向くようにMeshを回転させてビルボード処理を実現します。&lt;/p&gt;

&lt;p&gt;シェーダーからビルボード処理を抜き出して、できるだけコメントを入れました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// 回転行列を生成してビルボード処理をします
// 常にカメラ側を向くようにMeshを回転させます

// Y-UPベクトル
float3 yup = float3(0.0, 1.0, 0.0);

// up = Y軸の基底ベクトル
// オブジェクトのTransformの回転を考慮
float3 up = mul((float3x3)unity_ObjectToWorld, yup);

// オブジェクトのワールド座標
float3 worldPos = unity_ObjectToWorld._m03_m13_m23;

// オブジェクトからカメラに向かうベクトル
float3 toCamera = _WorldSpaceCameraPos - worldPos;

// right = X軸の基底ベクトル
// 前半の項 : rightはtoCameraとupの両方に直交するので、crossから計算
// 後半の項 : オブジェクトのTransformのX方向のスケールを考慮
float3 right = normalize(cross(toCamera, up)) * length(unity_ObjectToWorld._m00_m10_m20);

// forward = Z軸の基底ベクトル
// 前半の項 : forwardはupとrightの両方に直交するので、crossから計算
// 後半の項 : オブジェクトのTransformのZ方向のスケールを考慮
float3 forward = normalize(cross(up, right)) * length(unity_ObjectToWorld._m02_m12_m22);

// 各基底ベクトルを並べてビルボード用の回転行列を生成
// （厳密には平行移動とスケールも含んだ変換行列）
float4x4 mat = {
    1, 0, 0, 0,
    0, 1, 0, 0,
    0, 0, 1, 0,
    0, 0, 0, 1,
};
mat._m00_m10_m20 = right;//     X軸の基底ベクトル
mat._m01_m11_m21 = up;//        Y軸の基底ベクトル
mat._m02_m12_m22 = forward;//   Z軸の基底ベクトル
mat._m03_m13_m23 = worldPos;//  平行移動のベクトル


// ローカル座標（平行移動のためにw=1）
float4 vertex = float4(IN.positionOS.xyz, 1);

// ビルボード用の回転行列を乗算してワールド空間に変換
vertex = mul(mat, vertex);

// ビュー行列とプロジェクション行列を乗算してクリップ空間に変換
OUT.positionHCS = mul(UNITY_MATRIX_VP, vertex);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これは超重要情報ですが、 &lt;strong&gt;回転後の空間の基底ベクトルを並べた行列が回転行列になります。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;これだけ覚えておけば、回転だけでなく、拡大縮小やSkew（せん断）の行列は自然に導出できます。&lt;/p&gt;

&lt;p&gt;知らなかった人はぜひ覚えておきましょう。CEDECで同じ話を2回くらいしています（&lt;a href=&#34;https://www.klab.com/jp/blog/creative/2020/cedec2020.html&#34;&gt;2020&lt;/a&gt;と&lt;a href=&#34;https://www.klab.com/jp/blog/tech/2021/cedec-kyushu-2021-online-3d.html&#34;&gt;2021&lt;/a&gt;）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-23-unity-urp-billboard-shader/kec2-1.png&#34; alt=&#34;基底ベクトルをイメージすればOK&#34; /&gt;
&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-23-unity-urp-billboard-shader/kec2-2.png&#34; alt=&#34;回転ベクトル1&#34; /&gt;
&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-23-unity-urp-billboard-shader/kec2-3.png&#34; alt=&#34;回転ベクトル2&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;スケール対応&#34;&gt;スケール対応&lt;/h2&gt;

&lt;p&gt;モデル行列 &lt;code&gt;unity_ObjectToWorld&lt;/code&gt; から各軸のスケールを取得することで、スケール対応ができます。
Y軸に関しては、upを計算するときにnormalizeしなければ自動でスケールが考慮されます。&lt;/p&gt;

&lt;h3 id=&#34;スケール対応なし&#34;&gt;スケール対応なし&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// up = Y軸の基底ベクトル
// オブジェクトのTransformの回転を考慮
float3 up = normalize(mul((float3x3)unity_ObjectToWorld, yup));

//...

// right = X軸の基底ベクトル
// rightはtoCameraとupの両方に直交するので、crossから計算
float3 right = normalize(cross(toCamera, up));

// forward = Z軸の基底ベクトル
// forwardはupとrightの両方に直交するので、crossから計算
float3 forward = normalize(cross(up, right));
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;スケール対応あり&#34;&gt;スケール対応あり&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// up = Y軸の基底ベクトル
// オブジェクトのTransformの回転を考慮
float3 up = mul((float3x3)unity_ObjectToWorld, yup);

//...

// right = X軸の基底ベクトル
// 前半の項 : rightはtoCameraとupの両方に直交するので、crossから計算
// 後半の項 : オブジェクトのTransformのX方向のスケールを考慮
float3 right = normalize(cross(toCamera, up)) * length(unity_ObjectToWorld._m00_m10_m20);

// forward = Z軸の基底ベクトル
// 前半の項 : forwardはupとrightの両方に直交するので、crossから計算
// 後半の項 : オブジェクトのTransformのZ方向のスケールを考慮
float3 forward = normalize(cross(up, right)) * length(unity_ObjectToWorld._m02_m12_m22);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;追記&lt;br&gt;GameObjectのスケールに対応しました。&lt;a href=&#34;https://twitter.com/hashtag/Unity3d?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Unity3d&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/HLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#HLSL&lt;/a&gt; &lt;a href=&#34;https://t.co/gI4a3zpmJQ&#34;&gt;pic.twitter.com/gI4a3zpmJQ&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1473858972558200843?ref_src=twsrc%5Etfw&#34;&gt;December 23, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;srp-batcher&#34;&gt;SRP Batcher&lt;/h2&gt;

&lt;p&gt;URP（SRP）からSRP Batcherというドローコールバッチング（厳密にはドローコールの数を減らすわけではなく、ドローコール間のGPUの設定コストを削減）の仕組みが導入されました。&lt;/p&gt;

&lt;p&gt;以前のビルドインレンダーパイプラインのドローコールバッチングではMeshが結合されるので、ビルボードのように特殊な頂点変換をするシェーダーでは考慮が必要で、けっこう面倒でした。&lt;/p&gt;

&lt;p&gt;SRP BatcherはMeshを結合しないので、頂点変換で特別な考慮をしなくてもシェーダーが動くようになりました！めでたい🎉&lt;/p&gt;

&lt;p&gt;今回のシェーダーをフレームデバッガーで確認すると、ちゃんとSRP Batcherで描画されているのが分かります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-23-unity-urp-billboard-shader/frame-debugger.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-23-unity-urp-billboard-shader/frame-debugger.png&#34; alt=&#34;SRP Batcher&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SRP Batcherについては、以下の記事が詳しいです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.unity.com/ja/technology/srp-batcher-speed-up-your-rendering&#34;&gt;SRP Batcher：レンダリングをスピードアップ | Unity Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;リンク&#34;&gt;リンク&lt;/h1&gt;

&lt;p&gt;参考にさせていただきました。ありがとうございます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;URP対応（SRP Batcherも対応👍）

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://light11.hatenadiary.com/entry/2021/07/29/194213&#34;&gt;【Unity】URP用のシェーダの書き方が旧パイプラインと微妙に違ってややこしいのでまとめた - LIGHT11&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;利用したテクスチャ素材

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pngall.com/tree-png/download/23754&#34;&gt;Tree PNG Clipart Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.deviantart.com/fabooguy/art/Dirt-Ground-Texture-Tileable-2048x2048-441212191&#34;&gt;Dirt/Ground Texture [Tileable | 2048x2048]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Tokyo Demo Fest 2021のGLSL Graphics Compo優勝作品の解説</title>
      <link>https://gam0022.net/blog/2021/12/20/tdf2021-glsl/</link>
      <pubDate>Mon, 20 Dec 2021 12:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2021/12/20/tdf2021-glsl/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;http://qiita.com/advent-calendar/2021/klab&#34;&gt;KLab Engineer Advent Calendar 2021&lt;/a&gt;の20日目の記事です。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;12月11日～12日にオンラインで開催された&lt;a href=&#34;https://tokyodemofest.jp/&#34;&gt;Tokyo Demo Fest 2021&lt;/a&gt;（以下、TDF）に参加しました。&lt;/p&gt;

&lt;p&gt;TDFは、日本国内で唯一のデモパーティです。
リアルタイムに映像や音楽を生成するプログラムを「デモ」と言い、デモを鑑賞したり完成度を競ったりして楽しむイベントを「デモパーティ」と言います。
「デモシーン」はデモやデモパーティを中心としたコンピューターのサブカルチャーです。&lt;/p&gt;

&lt;p&gt;今年のTDFでは、『Alien Spaceship』という作品を発表しました。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/_F0Pxq7TKqs&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Released &amp;quot;Alien Spaceship&amp;quot; at GLSL Graphics compo, &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; 2021&lt;br&gt;&lt;br&gt;It&amp;#39;s running on &lt;a href=&#34;https://twitter.com/hashtag/GLSLSandbox?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSLSandbox&lt;/a&gt; &lt;br&gt;Only 1Pass Shader! No post-effects used&lt;a href=&#34;https://twitter.com/hashtag/GLSLSandbox?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSLSandbox&lt;/a&gt; で動作します。&lt;br&gt;1パスのシェーダーのみの制約で実装しており、ポストエフェクトは未使用です。 &lt;a href=&#34;https://t.co/lJBQQjjHMR&#34;&gt;pic.twitter.com/lJBQQjjHMR&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469977106612649985?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/_F0Pxq7TKqs&#34;&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/fl3SRB&#34;&gt;Shadertoy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pouet.net/prod.php?which=90438&#34;&gt;Pouet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://glslsandbox.com/e#77788.0&#34;&gt;GLSL Sandbox&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TDFのGLSL Graphics Compoにて、&lt;a href=&#34;https://tokyodemofest.jp/tdf2021-results.txt&#34;&gt;本作品が1位&lt;/a&gt;に選ばれました！&lt;/p&gt;

&lt;p&gt;この記事では『Alien Spaceship』の利用技術と制作の裏側について解説します。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;glsl-graphics-compoとは&#34;&gt;GLSL Graphics Compoとは？&lt;/h1&gt;

&lt;p&gt;デモシーンの文化に馴染みのない方に向けて、簡単にGLSL Graphics Compoの概要や制約について説明します。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://glslsandbox.com/&#34;&gt;GLSL sandbox&lt;/a&gt;はWeb上でGLSLのフラグメントシェーダーを編集・実行できるWebGLで実装されたサービスです。作品を公開したり共有もできます。&lt;/p&gt;

&lt;p&gt;GLSL Graphics CompoはGLSL Sandbox上で動作するGLSLのシェーダーによるグラフィックスを競うコンポです。
コンポはコンペティションの意味で、参加者投票によって順位が決まります。&lt;/p&gt;

&lt;h2 id=&#34;glslシェーダーだけで映像をつくる&#34;&gt;GLSLシェーダーだけで映像をつくる&lt;/h2&gt;

&lt;p&gt;そもそもGLSLシェーダー、つまり &lt;strong&gt;プログラミングのソースコードだけで映像をつくる&lt;/strong&gt; 行程を一般的には想像しづらいかもしれません。&lt;/p&gt;

&lt;p&gt;まずは次の図を見ていただけると、具体的にイメージを掴めるかもしれません。
GLSLのコードからコメントや改行・空白文字を取り除き、処理の内容で色分けしました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/minify-text.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/minify-text.png&#34; alt=&#34;GLSLのコードの処理&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;この7756文字のGLSLのシェーダーに映像のすべてが実装されています。&lt;/p&gt;

&lt;p&gt;見てのとおり &lt;strong&gt;シーンのモデリング、ライティング、カメラワーク、演出のシーケンスがすべて含まれています。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;変数名や関数名を1文字に短縮したり、デバッグ用のコードの削除はしていないので、まだまだ文字数を削る余地はあります。
今回は文字数をそこまで意識してコーディングせずに、可読性を重視しました。&lt;/p&gt;

&lt;p&gt;GLSL sandboxでは音楽を再生できないので、YouTubeの音楽は後付けです。Shadertoy標準楽曲「Most Geometric Person」を使わせていただきました。&lt;/p&gt;

&lt;h2 id=&#34;レイマーチング&#34;&gt;レイマーチング&lt;/h2&gt;

&lt;p&gt;GLSL sandbox用のGLSLのフラグメントシェーダーで記述できるのは、フルスクリーンのMeshを描画する2D処理のみです。&lt;/p&gt;

&lt;p&gt;入力は描画対象のピクセルの座標、出力はピクセルの画素値の単純な2D処理です。
また、時間やマウス座標を入力にすることで、アニメーションもできます。&lt;/p&gt;

&lt;p&gt;3Dを描画するためには、GLSLコードの中に3Dのカメラや3Dのシーンの形状を定義する必要があります。&lt;/p&gt;

&lt;p&gt;2DのGLSLのシェーダーで3D空間を描画するためのテクニックとして、レイマーチングがよく使われます。&lt;/p&gt;

&lt;p&gt;レイマーチングは、距離関数の長さだけひたすらレイを進める処理をくり返し、距離関数が0になったら衝突したと判定する単純なアルゴリズムです。
つまり、レイトレーシングの交差判定のアルゴリズムのひとつです。
レイマーチングは、描画する形状を距離関数という数式によってプロシージャルに定義できるため、3Dのモデリングなしに3Dシーンを描画できます。&lt;/p&gt;

&lt;p&gt;レイマーチングの詳細については、過去に勉強会のスライドや書籍で紹介しています。&lt;/p&gt;

&lt;iframe src=&#34;//www.slideshare.net/slideshow/embed_code/key/rS2j757JUrqeWL&#34; width=&#34;595&#34; height=&#34;485&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt; &lt;div style=&#34;margin-bottom:5px&#34;&gt; &lt;strong&gt; &lt;a href=&#34;//www.slideshare.net/shohosoda9/threejs-58238484&#34; title=&#34;シェーダだけで世界を創る！three.jsによるレイマーチング&#34; target=&#34;_blank&#34;&gt;シェーダだけで世界を創る！three.jsによるレイマーチング&lt;/a&gt; &lt;/strong&gt; de &lt;strong&gt;&lt;a href=&#34;https://www.slideshare.net/shohosoda9&#34; target=&#34;_blank&#34;&gt;Sho Hosoda&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;

&lt;iframe style=&#34;width:120px;height:240px;&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; src=&#34;//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=000000&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=gam00220c-22&amp;language=ja_JP&amp;o=9&amp;p=8&amp;l=as4&amp;m=amazon&amp;f=ifr&amp;ref=as_ss_li_til&amp;asins=B097GBR2N3&amp;linkId=ad2164f51c3a4574701f9097c0eb7fde&#34;&gt;&lt;/iframe&gt;

&lt;h1 id=&#34;alien-spaceshipの技術解説&#34;&gt;Alien Spaceshipの技術解説&lt;/h1&gt;

&lt;p&gt;前置きが長くなりましたが、ここからレイマーチング経験者に向けた技術解説をします。&lt;/p&gt;

&lt;p&gt;技術的なポイントとしては次の3点です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;宇宙船の船内のような具体的な対象を目指したモデリング

&lt;ul&gt;
&lt;li&gt;SDF（距離関数）によるモデリングでは少し難しい&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;リアルタイムなグローバルイルミネーション（GI）あるライティング

&lt;ul&gt;
&lt;li&gt;事前計算なしのGIのリアルタイム計算は技術的にとても難しい課題&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;長尺のタイムラインのシーケンス

&lt;ul&gt;
&lt;li&gt;シェーダーはカメラワークや演出のシーケンスの実装に適した道具ではないが、なるべくスマートな実装になるように工夫&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;モデリング&#34;&gt;モデリング&lt;/h2&gt;

&lt;p&gt;全編を通してプリミティブとしてはBoxとSphere（卵）の2種類しか使っていません。&lt;/p&gt;

&lt;h3 id=&#34;前半のhallwayシーン&#34;&gt;前半のHallwayシーン&lt;/h3&gt;

&lt;p&gt;壁の光る部分はBoxをSkewしたり、床はBoxにDisplacement Mapでディテールを加えています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party1164.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party1164.jpg&#34; alt=&#34;party1164.jpg&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;壁のskew&#34;&gt;壁のSkew&lt;/h4&gt;

&lt;p&gt;壁の &lt;strong&gt;く&lt;/strong&gt; の字の折り曲がった形状には、BoxをSkewで変形させています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;p.x -= W - 0.5 * abs(p.y);// Skewで変形
opUnion(m, sdBox(p, vec3(a * 1.7, H, 0.24)), SOL, roughness, 0.0);
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;床のdisplacement-map&#34;&gt;床のDisplacement Map&lt;/h4&gt;

&lt;p&gt;床のDisplacement Mapは次のような数式で実装しています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// hをsdBoxの第2引数のサイズに加算すると、Displacement Mapになる
float h = 0.1 * floor(2. * sin(p.x)) + 0.2 * floor(sin(2. * p.z));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sinから滑らかなカーブを得て、それをfloorで階段状に離散化しているだけです。&lt;/p&gt;

&lt;p&gt;pは事前にabs(p.x)により左右ミラーしています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/floor_graph.png&#34; alt=&#34;床の断面&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;扉の台形波&#34;&gt;扉の台形波&lt;/h4&gt;

&lt;p&gt;扉の台形のギザギザの関数は&lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;kaneta先生&lt;/a&gt;のコードをお借りしました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/3dd3WB&#34;&gt;Energy Lab by kaneta&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float smoothPulse(float start, float end, float period, float smoothness, float t) {
    float h = abs(end - start) * 0.5;
    t = mod(t, period);
    return smoothstep(start, start + h * smoothness, t) - smoothstep(end - h * smoothness, end, t);
}

float y(float x) {
    return smoothPulse(0.0, 0.6, 1.0, 0.5, x);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/smoothPulse.png&#34; alt=&#34;扉の台形波&#34; /&gt;&lt;/p&gt;

&lt;p&gt;床のEmissiveや扉を開けたときのEmissiveの模様のパターンもsmoothPulse関数を用いました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party2085.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party2085.jpg&#34; alt=&#34;party2085.jpg&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/smoothPulsePattern.png&#34; alt=&#34;smoothPulsePattern.png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Floor Emissive Pattern
float py = smoothPulse(0.0, 0.6, 1.0, 0.5, 0.25 * p.y);
float emi = smoothPulse(0.2, 0.25, 1.0, 0.5, py + p.x / 2.0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Shadertoyに簡単なサンプルを用意しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/7ttXWf&#34;&gt;smoothPulse Pattern&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;hallwayシーンまとめ&#34;&gt;Hallwayシーンまとめ&lt;/h4&gt;

&lt;p&gt;天井についても、係数を調整しながら箱を並べることで、狙った形状をモデリングしていきました。
特殊なことは何もしていませんが、sdBoxの評価回数が増えると負荷が高くなるので、なるべくsdBoxの数を減らすように意識しました。
レイマーチングでは、座標をmodで繰り返すと特定の軸に対して無限にオブジェクトを配置できます（opRep）。
前述の左右のミラー化もsdBoxの評価回数を減らすための工夫のひとつです。&lt;/p&gt;

&lt;p&gt;ほぼopRepとSkewとDisplacement Mapのテクニックの繰り返しで地道にモデリングしているだけです。&lt;/p&gt;

&lt;p&gt;ライティングの問題とモデリングの問題を切り分けるためにシンプルなレイマーチングの描画モードも用意しました。&lt;/p&gt;

&lt;p&gt;よく見ると強引にSkewとDisplacement Mapをしたために、よく見るとアーティファクトが発生しています。
最終的なライティングでは暗い箇所となってほとんど目立たなかったので、今回はそのままにしました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/debug-scene.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/debug-scene.png&#34; alt=&#34;debug-scene.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;後半のalienの巣のシーン&#34;&gt;後半のAlienの巣のシーン&lt;/h3&gt;

&lt;p&gt;IFS（Iterated Function Systems）をつかっています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party6370.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party6370.jpg&#34; alt=&#34;party6370.jpg&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party7186.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party7186.jpg&#34; alt=&#34;party7186.jpg&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;IFSでは狙った形をモデリングすることは困難なので、パラメーターを延々と調整しながら、理想的な見た目になるまで試行錯誤を繰り返しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// IFSのパラメーター
vec4 ifs = vec4(875, 482, 197, 545) / vec2(1200, 675).xyxy;

// IFSでモデリング
p = pos;
p -= vec3(0, H, 16. * 3.5);

for (int i = 0; i &amp;lt; 5; i++) {
    p = abs(p) - ifs.w;
    rot(p.xz, -4. * ifs.x);
    p = abs(p) - ifs.z;
    rot(p.xy, -4. * ifs.y);
}

opUnion(m, sdEgg(p, 0.1), SOL, 0.0, 0.0);
opUnion(m, sdBox(p, vec2(1, 0.01).xyy), SOL, roughness, 0.0);
opUnion(m, sdBox(p - vec2(0.001, 0).yxy, vec2(1, 0.01).xyy), VOL, 2.4 * saturate(cos(beatTau / 2. + 10. * p.x)), 2.4);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ライティング-グローバルイルミネーション&#34;&gt;ライティング（グローバルイルミネーション）&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party1895.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party1895.jpg&#34; alt=&#34;party1895.jpg&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;全編を通してグローバルイルミネーション（GI）や、少しラフな反射（roughness = 0.05くらい）をしています。&lt;/p&gt;

&lt;p&gt;グラフィックスエンジニアなら性癖に刺さるポイントだと思います。&lt;/p&gt;

&lt;p&gt;GIをリアルタイムに計算するのは技術的にはとても難しい課題です。&lt;/p&gt;

&lt;p&gt;今回は&lt;a href=&#34;https://twitter.com/Virgill74&#34;&gt;Virgillさん&lt;/a&gt;が開発したMadtracingを用いてGIを計算しました。&lt;/p&gt;

&lt;p&gt;Madtracingは&lt;a href=&#34;https://www.pouet.net/prod.php?which=77102&#34;&gt;End of time by Alcatraz &amp;amp; Altair&lt;/a&gt;というデモで使われた手法です。&lt;/p&gt;

&lt;p&gt;Madtracing解説用のシェーダーがShadertoyに公開されています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/Xt3cWS&#34;&gt;EOT - Grid scene by Virgill&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;パストレーシングと同じように表面のroughnessに応じてセカンダリレイを飛ばしてGIを計算します。&lt;/p&gt;

&lt;p&gt;通常のパストレーシングでは物体の表面にヒットしてからセカンダリレイを複数回飛ばすと思いますが、
Madtracingではレイマーチングのステップ中にセカンダリレイを近傍のオブジェクトのroughnessに応じて飛ばします。&lt;/p&gt;

&lt;p&gt;これによってボリューム感やBloom感のあるライティングを実現できます。その代償として、少々負荷が高い印象です。&lt;/p&gt;

&lt;p&gt;今回のデモでは、Madtracingを自分の使いやすい形に少しだけフォークして利用しました。&lt;/p&gt;

&lt;p&gt;まず、マテリアルのフォーマット（map関数の返り値）を以下のように定義しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec4 m = vec4(1, VOL, 0, 0);
// x: Distance
// y: MaterialType (VOL or SOL)
// z: Roughness in (0-1), Emissive when z&amp;gt;1
// w: ColorPalette
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MadtracingからAA処理を削除して、AA処理はプライマリレイの生成に移動しました。これで少し負荷削減とシンプル化ができました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Ref. EOT - Grid scene by Virgill
// https://www.shadertoy.com/view/Xt3cWS
void madtracer(vec3 ro1, vec3 rd1, float seed) {
    scol = vec3(0);
    float t = 0., t2 = 0.;
    vec4 m1, m2;
    vec3 rd2, ro2, nor2;
    for (int i = 0; i &amp;lt; 160; i++) {
        m1 = map(ro1 + rd1 * t);
        // t += m1.y == VOL ? 0.25 * abs(m1.x) + 0.0008 : 0.25 * m1.x;
        t += 0.25 * mix(abs(m1.x) + 0.0032, m1.x, m1.y);
        ro2 = ro1 + rd1 * t;
        nor2 = normal(ro2);
        rd2 = mix(reflect(rd1, nor2), hashHs(nor2, vec3(seed, i, iTime)), saturate(m1.z));
        m2 = map(ro2 + rd2 * t2);
        // t2 += m2.y == VOL ? 0.25 * abs(m2.x) : 0.25 * m2.x;
        t2 += 0.25 * mix(abs(m2.x), m2.x, m2.y);
        scol += .007 * (pal(m2) * step(1., m2.z) + pal(m1) * step(1., m1.z));

        // force disable unroll for WebGL 1.0
        if (t &amp;lt; -1.) break;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;絶対に実行されないbreak-によるコンパイル時間削減&#34;&gt;「絶対に実行されないbreak」によるコンパイル時間削減&lt;/h3&gt;

&lt;p&gt;madtracer関数に、謎の &lt;code&gt;if (t &amp;lt; -1.) break;&lt;/code&gt; があることに気がついたでしょうか？&lt;/p&gt;

&lt;p&gt;tはレイの進んだ距離で、絶対にマイナス値にはなりません。つまり絶対に実行されないbreak処理です。
普通に考えれば不要な処理ですが、これはGLSLコンパイル時間削減のハックです。&lt;/p&gt;

&lt;p&gt;breakを追加することで、GLSLコンパイラによってforがunrollされずにloopとして処理されて、コンパイル時間を大きく削減できます。&lt;/p&gt;

&lt;p&gt;ChromeデフォルトのWebGLのANGLE有効時にはかなり効果的で、自分の環境ではコンパイル時間を32.9秒から1.7秒に削減できました。&lt;/p&gt;

&lt;p&gt;コンポ提出当日はずっとコンパイル時間の削減に工数を費やしていて、提出2.5時間前くらいに気がついたので、もっと早く気がついていればという気持ちです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; が終わったので、&lt;br&gt;コンパイル時間を32.9秒から1.7秒に削減する&lt;br&gt;「絶対に実行されないbreak」の実例を貼っておきます。&lt;br&gt;&lt;br&gt;breakを追加することで、GLSLコンパイラによってforがunrollされずにloopに処理されて、コンパイル時間を大きく削減できます。&lt;a href=&#34;https://t.co/SC7A9WAkll&#34;&gt;https://t.co/SC7A9WAkll&lt;/a&gt; &lt;a href=&#34;https://t.co/XRakPPq0TU&#34;&gt;pic.twitter.com/XRakPPq0TU&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1470408956866883584?ref_src=twsrc%5Etfw&#34;&gt;December 13, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;同様のテクニックとして、&lt;code&gt;N + min(0, iFrame)&lt;/code&gt; をループ回数にする手法があります。&lt;a href=&#34;https://twitter.com/AruGL&#34;&gt;Danilさん&lt;/a&gt;に教えていただきました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;maybe you know usual trick with loop N+min(0,iFrame) it also can speedup compiling&lt;a href=&#34;https://t.co/XPfP9CZms0&#34;&gt;https://t.co/XPfP9CZms0&lt;/a&gt;&lt;/p&gt;&amp;mdash; Danil (@AruGL) &lt;a href=&#34;https://twitter.com/AruGL/status/1466751715038879755?ref_src=twsrc%5Etfw&#34;&gt;December 3, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;コードにすると、こういう感じです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for(int i = 0; i &amp;lt; 160 + min(0, iFrame); i++) {
    // ループ中の処理
    // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ShadertoyなどのWebGL2.0環境であれば、この方法で同じコンパイル時間削減の効果を得られます。&lt;/p&gt;

&lt;p&gt;WebGL1.0の場合はダイナミックループをサポートしていないので、WebGL1.0で動くGLSLSandboxでは &lt;code&gt;N + min(0, iFrame)&lt;/code&gt; のハックは使えません。&lt;/p&gt;

&lt;p&gt;GLSLSandbox用なら、&lt;code&gt;絶対に実行されないbreak&lt;/code&gt; のハックを使うと良いでしょう。&lt;/p&gt;

&lt;h2 id=&#34;タイムラインのシーケンス&#34;&gt;タイムラインのシーケンス&lt;/h2&gt;

&lt;p&gt;タイムラインのシーケンス管理のために次の簡単なマクロを実装しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Timeline
float prevEndTime = 0., t = 0.;
#define TL(beat, end) if (t = beat - prevEndTime, beat &amp;lt; (prevEndTime = end))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使い方は簡単で、TLの引数に現在時刻と境界値（区間の終了タイミング）を指定します。
単位は区別していないので、時間単位でもビート単にでも統一されていてばOKです。&lt;/p&gt;

&lt;p&gt;グローバル変数tに現在区間の相対的な時間が自動的に設定されるため、処理をスッキリと書けます。&lt;/p&gt;

&lt;p&gt;ifの条件の中にカンマを複数の式を書けるのは今回はじめて知りました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// カメラワーク制御の実装例

// 0～ 4*8ビート目までの処理
TL(beat, 4. * 8.) setCamera(vec4(600, 250. + t * 3., 600, 243. - t * 6.), 3.);

// 4*8～4*10ビート目までの処理
else TL(beat, 4. * 10.) setCamera(vec4(600, 307, 600, 44. + t * 4.), 3.);

// 4*10～4*12ビート目までの処理
else TL(beat, 4. * 12.) setCamera(vec4(494, 322, 695, 216), 2.4 + 0.2 * t);

// 4*12～4*14ビート目までの処理
else TL(beat, 4. * 14.) setCamera(vec4(600, 481. + 10. * t, 600, 59), 3.);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回はカットごとにカメラを完全に切り替えていたので、このような仕組みでうまくカメラワークを実装できました。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;kanetaさんのsmoothPulse関数や、VirgillさんのMadtracing以外にも、数え切れないほどたくさんの解説記事とシェーダーを参考にしたり、たくさんの作品に影響を受けました。
たくさんの方々に感謝します。ありがとうございました！&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;ここからは技術的なこと以外のポエムをつらつらと書きます。&lt;/p&gt;

&lt;h2 id=&#34;glsl-graphics-compo初優勝&#34;&gt;GLSL Graphics Compo初優勝！&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;2018年のPC Demo Compo&lt;/a&gt;に引き続き、Tokyo Demo Festでのコンポ優勝は2回目です。&lt;/p&gt;

&lt;p&gt;これまでGLSL Graphics Compoはずっと3位で、なかなか優勝できなかったので、ようやく心残りを解消できました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;I won the GLSL Graphics compo at &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; 2021!&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; 2021 の GLSL Graphics compo で優勝しました！めちゃくちゃ嬉しいです！&lt;br&gt;&lt;br&gt;&amp;quot;Alien Spaceship&amp;quot; by &lt;a href=&#34;https://twitter.com/gam0022?ref_src=twsrc%5Etfw&#34;&gt;@gam0022&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/KQaQo1NI0R&#34;&gt;pic.twitter.com/KQaQo1NI0R&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469994430950445057?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;GLSL Graphics compo 1位のトロフィーを受け取りました🏆&lt;br&gt;&lt;br&gt;今年のトロフィーは例年よりもずっと重厚感があります。&lt;br&gt;&lt;br&gt;副賞の光るキーボードもありがとうございました。&lt;br&gt;家にある光るキーボードは3台目ですが、大切にします🙏&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/vC3ce68i7S&#34;&gt;pic.twitter.com/vC3ce68i7S&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1472229449433481220?ref_src=twsrc%5Etfw&#34;&gt;December 18, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;トロフィーの素材や厚みが例年よりも高級感があって、個人的にもなんだか嬉しい気持ちです（笑）。&lt;/p&gt;

&lt;p&gt;GUNCY&amp;rsquo;Sさんによる副賞のRazer BlackWidow V3 Green Switchもありがとうございます。&lt;/p&gt;

&lt;h2 id=&#34;気軽にtdfにエントリーしてほしい&#34;&gt;気軽にTDFにエントリーしてほしい&lt;/h2&gt;

&lt;p&gt;GLSL Graphics CompoはTDF独自のコンポで、海外のパーティでは見たことのない形式ですが、個人的にはとても好きです。&lt;/p&gt;

&lt;p&gt;2016年のTDFに初参加したとき、一晩でGLSLSandboxのシェーダーを書いて、GLSL Graphics Compoにエントリーした記憶は今でも鮮明に覚えています。
自分のシェーダーが巨大なスクリーンに映し出されたとき、オーディエンスの歓声が聞こえて本当に嬉しかったです。
この体験がなければデモシーンやシェーダーを続けていないような気がします。勇気を出してエントリーして良かったと本当に思います。&lt;/p&gt;

&lt;p&gt;デモを1本完成させるのは本当に大変ですが、GLSL Graphics Compoなら気軽に参加できることがメリットだと思います。&lt;/p&gt;

&lt;p&gt;気軽に参加できる数少ないコンポですが、近年のGLSL Graphics Compoのレベルはインフレを続けて、上位勢はかなりガチな作品を出してくるなという印象があります。&lt;/p&gt;

&lt;p&gt;本来のGLSL Graphics Compoは数秒から10秒程度の短いグラフィックス作品の部門だと自分は認識しています。
&lt;a href=&#34;https://nanka.hateblo.jp/entry/2018/12/13/080322&#34;&gt;Traveler 2&lt;/a&gt;やAlien Spaceshipのような長尺のデモっぽい作品がGLSL Graphics Compoに増えることで、もし他の参加者が萎縮してしまったらとても不本意な気持ちです。&lt;/p&gt;

&lt;p&gt;GLSL Graphics Compoは順位や周りを気にせず、1晩クオリティの雑なシェーダーでも構わず気軽にエントリーできる雰囲気にして、新規参入者が増える未来を望んでいます。&lt;/p&gt;

&lt;h2 id=&#34;オンラインパーティの体験&#34;&gt;オンラインパーティの体験&lt;/h2&gt;

&lt;p&gt;今回のTDF初のオンライン開催でした。&lt;/p&gt;

&lt;p&gt;TDFのオーガナイザーの方々の努力のおかげで、実際のデモパーティにかなり近い体験を再現できていたのではないかと思います。&lt;/p&gt;

&lt;p&gt;Day2のYouTubeの視聴回数が3000回を超えているので、例年のオフラインパーティよりもたくさんの人に見てもらえたなど、オンラインのメリットも感じました。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/2s9KfMn1J9M&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/bp37xTVNRrM&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;ですが、やはり正直に言うと「オンラインだと物足りないなぁ…」というのが正直な感想でした。
とくにオーディエンスの反応や会場の熱気を直接感じられないのはとても寂しかったです。またオフラインでデモパーティできる日が本当に待ち遠しいです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;またオフラインでデモパーティできる日が待ち遠しい… &lt;a href=&#34;https://t.co/WsyEHySE28&#34;&gt;https://t.co/WsyEHySE28&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1470764587834568715?ref_src=twsrc%5Etfw&#34;&gt;December 14, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;shader-showdown&#34;&gt;Shader Showdown&lt;/h2&gt;

&lt;p&gt;TDF初の試みであるShader Showdownは本当に激熱でした。&lt;/p&gt;

&lt;p&gt;とくに決勝戦の &lt;a href=&#34;https://twitter.com/phi16_&#34;&gt;phi16&lt;/a&gt; vs. &lt;a href=&#34;https://twitter.com/kamoshika_vrc&#34;&gt;Kamoshika&lt;/a&gt; の戦いは一生忘れないくらい印象に残りました。&lt;/p&gt;

&lt;p&gt;Shader Showdownについては、別の記事に書きました（12/31）。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2021/12/31/tdf2021-shader-showdown/&#34;&gt;Tokyo Demo Fest 2021のShader Showdownに参加しました | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;TokyoDemoFestのShader Showdownは、世界的なDemoparty「Revision」と同じレギュレーションで開催します。&lt;br&gt;試合の放映はパーティー当日12/11-12となります。乞うご期待……！ &lt;a href=&#34;https://t.co/IlVue5npWz&#34;&gt;pic.twitter.com/IlVue5npWz&lt;/a&gt;&lt;/p&gt;&amp;mdash; Tokyo Demo Fest 2021 (2021/12/11-12) (@TokyoDemoFest) &lt;a href=&#34;https://twitter.com/TokyoDemoFest/status/1452275618997886976?ref_src=twsrc%5Etfw&#34;&gt;October 24, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;おわりに-1&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;さいごに、関係者のみなさんに感謝を申し上げます。
TDFのオーガナイザーの方々、エントリーしてくださったみなさん、YouTubeで視聴してくださったみなさん、応援してくださった方々、ありがとうございました！&lt;/p&gt;

&lt;h1 id=&#34;その他&#34;&gt;その他&lt;/h1&gt;

&lt;p&gt;本編では言及しなかったけれども一応書いておきたいことを箇条書きでつらつら書きます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;今年のTDFでは、KLabはゴールドスポンサーとして協賛

&lt;ul&gt;
&lt;li&gt;協賛できて良かった&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;なぜGLSL Graphics Compoに出したの？

&lt;ul&gt;
&lt;li&gt;音楽を作る能力と余裕があれば、IntroとしてPC Demo Compoに出したかったが、間に合わなかった&lt;/li&gt;
&lt;li&gt;sadakkeyさん多忙&lt;/li&gt;
&lt;li&gt;来年は音楽も勉強したい（毎年言っている気もする）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;計画的にデモを作りたい

&lt;ul&gt;
&lt;li&gt;TDF直後には、他の人や作品に感化されて、溢れるモチベーションとやる気があるはずなのに&lt;/li&gt;
&lt;li&gt;結局毎年締切ギリギリまで着手できない&lt;/li&gt;
&lt;li&gt;だんだん徹夜もつらくなってきた&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;着想点

&lt;ul&gt;
&lt;li&gt;グローバルイルミネーションをやりたかった&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.magnum.graphics/guest-posts/area-lights-with-ltcs/&#34;&gt;Area Lights with LTCs&lt;/a&gt;も調査はした

&lt;ul&gt;
&lt;li&gt;BRDFなどに依存したルックアップテーブルが必要で、1Pass実装にフォールバックが不可能っぽいので諦めた&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;作業日記&#34;&gt;作業日記&lt;/h1&gt;

&lt;p&gt;ネタ供養🙏です。&lt;/p&gt;

&lt;h2 id=&#34;2021-11-07&#34;&gt;2021-11-07&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-07-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-07-v1-1.png&#34; alt=&#34;2021-11-07-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-16&#34;&gt;2021-11-16&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-1.png&#34; alt=&#34;2021-11-16-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-2.png&#34; alt=&#34;2021-11-16-v1-2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-3.png&#34; alt=&#34;2021-11-16-v1-3.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;この頃はIFSを弄っていた。&lt;/p&gt;

&lt;h2 id=&#34;2021-11-17&#34;&gt;2021-11-17&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-17-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-17-v1-1.png&#34; alt=&#34;2021-11-17-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-17-v1-2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-17-v1-2.png&#34; alt=&#34;2021-11-17-v1-2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-18&#34;&gt;2021-11-18&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-18-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-18-v1-1.png&#34; alt=&#34;2021-11-18-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-18-v2-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-18-v2-1.png&#34; alt=&#34;2021-11-18-v2-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-19&#34;&gt;2021-11-19&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-1.png&#34; alt=&#34;2021-11-19-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ボロノイでザラザラとした床にする案&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-2.png&#34; alt=&#34;2021-11-19-v1-2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-3.png&#34; alt=&#34;2021-11-19-v1-3.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-4.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-4.png&#34; alt=&#34;2021-11-19-v1-4.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-20&#34;&gt;2021-11-20&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-20-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-20-v1-1.png&#34; alt=&#34;2021-11-20-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-21&#34;&gt;2021-11-21&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v1-1.png&#34; alt=&#34;2021-11-21-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v1-2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v1-2.png&#34; alt=&#34;2021-11-21-v1-2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v2-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v2-1.png&#34; alt=&#34;2021-11-21-v2-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-22&#34;&gt;2021-11-22&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-22-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-22-v1-1.png&#34; alt=&#34;2021-11-22-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-22-v2-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-22-v2-1.png&#34; alt=&#34;2021-11-22-v2-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-12-02&#34;&gt;2021-12-02&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-12-02-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-12-02-v1-1.png&#34; alt=&#34;2021-12-02-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-12-02-v2-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-12-02-v2-1.png&#34; alt=&#34;2021-12-02-v2-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-12-03&#34;&gt;2021-12-03&lt;/h2&gt;

&lt;p&gt;締切当日はコンパイル時間の削減をがんばっていた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メガデモ勉強会2021で発表しました</title>
      <link>https://gam0022.net/blog/2021/02/15/demoscene-study-session/</link>
      <pubDate>Mon, 15 Feb 2021 13:26:18 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2021/02/15/demoscene-study-session/</guid>
      <description>&lt;p&gt;昨日の2/14（バレンタインデー）に開催された&lt;a href=&#34;https://connpass.com/event/200294/&#34;&gt;The Tokyo Demo Fest team presents: メガデモ勉強会2021&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;私は「64KBのWebGLデモを実装する技術とデモ制作から得た『学びと発見』」というタイトルで発表を行いました。&lt;/p&gt;

&lt;p&gt;発表スライドはこちらです。&lt;/p&gt;

&lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vRd-L7WcWWzcoE9zNpBsJdeMjJf9HelDg1Pto8cFGJTjinejpjZ1mGmzWCZPANJZ0QOCObuVOIdPuy-/embed?start=false&amp;loop=false&amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt; の発表資料です！&lt;br&gt;&lt;br&gt;Revision2020のPC 64K Introで優勝したデモ作品『RE: SIMULATED』を題材にして、効率的なデモ制作に必要なエディタ機能やWebGLのプロジェクトの構成、制作中に直面した問題と解決について解説しました。&lt;br&gt;&lt;br&gt;レイマーチングはいいぞ！&lt;a href=&#34;https://t.co/QWHOXHmZqu&#34;&gt;https://t.co/QWHOXHmZqu&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1360889255669633024?ref_src=twsrc%5Etfw&#34;&gt;February 14, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Revision2020のPC 64K Introで優勝したデモ作品『RE: SIMULATED』を題材にして、効率的なデモ制作に必要なエディタ機能やWebGLのプロジェクトの構成、制作中に直面した問題と解決方法について解説しました。&lt;/p&gt;

&lt;p&gt;発表の締めとして「CGを学ぶことで世界の解像度を上げるのが楽しい」「レイマーチングはCG入門に最適」という持論について語りました。&lt;/p&gt;

&lt;h1 id=&#34;質疑応答と補足&#34;&gt;質疑応答と補足&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;質問1: シェーダーを分割することで容量がどのくらい増えるか？

&lt;ul&gt;
&lt;li&gt;マルチパスを前提のエンジン設計にしたので、シェーダー分割してもTypeScriptのコード量は増えない&lt;/li&gt;
&lt;li&gt;重複コードはzlib（pnginator.rb）で圧縮されるため、シェーダーの圧縮後のコードもほとんど増えない&lt;/li&gt;
&lt;li&gt;前半と後半で2分割したときは45byteだけ増えた（&lt;a href=&#34;https://github.com/gam0022/resimulated/pull/112&#34;&gt;PR&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;質問2: シェーダーの数と行数について

&lt;ul&gt;
&lt;li&gt;サウンドシェーダーは1ファイル。グラフィックス用のシェーダーは合計10ファイル&lt;/li&gt;
&lt;li&gt;サウンドシェーダーは行数が1800行ほどだが、zlibで効率よく圧縮できるので、最終的なファイル容量にはあまり影響しなかった&lt;/li&gt;
&lt;li&gt;グラフィックス用のシェーダーは最大（宇宙空間のレイマーチング）で700行、最小（Bloomのポストエフェクト）で10行ほど&lt;/li&gt;
&lt;li&gt;用途によって幅があるが、レイマーチング用のシェーダーだと平均して400行くらい&lt;/li&gt;
&lt;li&gt;Shadertoyと同じようにCommonのシェーダーの仕組みも用意したが、重複したシェーダーはzlibで圧縮されるため、容量削減の効果は低かった&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;質問3: ディレクションについて

&lt;ul&gt;
&lt;li&gt;制作前に打ち合わせをしてBPMは決めていた

&lt;ul&gt;
&lt;li&gt;音楽と絵の同期はBPMで行っているので重要&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;方向性は絵が先行&lt;/li&gt;
&lt;li&gt;尺については音楽が先行&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;補足1: Bloomのポストエフェクトはエンジンのビルトイン機能にした

&lt;ul&gt;
&lt;li&gt;縮小バッファーを利用するマルチパスのBloomにしたので、ビルトインにしたほうがサイズを小さく効率よく実装できそうだったから&lt;/li&gt;
&lt;li&gt;フォント描画用のテクスチャ生成機能などShadertoyにはない仕様も何個か実装した&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;補足2: OpenGLよりWebGLの方がGLSLのコンパイル時間が長い

&lt;ul&gt;
&lt;li&gt;WebGLのデモではなく、OpenGLのexeによるデモにすれば、GLSLのコンパイル時間を短縮できる&lt;/li&gt;
&lt;li&gt;Windows版のChromeおよびFirefoxでは、ANGLEを経由してDirect3D上でWebGLを実現しているため、ANGLEを経由する分だけGLSLコンパイルに時間のかかるケースが多い（&lt;a href=&#34;https://twitter.com/gaziya5/status/1361134297315348482&#34;&gt;Twitter&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;chrome.exe --use-angle=gl&lt;/code&gt; というオプション付きでChromeを起動すると、ANGLEを経由せずにWebGLを利用できる（&lt;a href=&#34;https://twitter.com/gaziya5/status/1350418640093413377&#34;&gt;Twitter&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;かなり久しぶりに日本のデモシーンの人たちとワイワイできて楽しかったです！&lt;/p&gt;

&lt;p&gt;最後のTokyoDemoFestは2018年の12月なので、もう2年以上も前なんですよね。時間が経つのは早いです。&lt;/p&gt;

&lt;p&gt;discord上の懇親会では「どうすればライブコーディングを普及できるのか？一般人でも理解できるような実況が必要という仮説」「物理的な会場のクラブの体験とVRの違い」など興味深いお話を聞けて面白かったです。&lt;/p&gt;

&lt;p&gt;素晴らしいイベントを企画・開催してくださったTDFのオーガナイザーのみなさん、本当にありがとうございました！&lt;/p&gt;

&lt;h1 id=&#34;関連記事&#34;&gt;関連記事&lt;/h1&gt;

&lt;p&gt;過去の関連登壇や記事のリンクです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2020/04/30/revision2020/&#34;&gt;Revision2020 PC 64K Intro 優勝作品『RE: SIMULATED』の技術解説&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/03/16/demoscene-study-session/&#34;&gt;メガデモ勉強会!2018で発表しました&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2016/02/16/glsl-tech/&#34;&gt;GLSL シェーダテクニック勉強会 #GLSLTechで登壇しました&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;この勉強会も5年前のバレンタインデーだったので何かの運命を感じました&lt;/li&gt;
&lt;li&gt;私がレイマーチングを始めてから5年以上も経過しているのもちょっと驚きでした&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>CGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました</title>
      <link>https://gam0022.net/blog/2020/09/13/cgworld-vol266/</link>
      <pubDate>Sun, 13 Sep 2020 20:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2020/09/13/cgworld-vol266/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-09-13-cgworld-vol266/Collage_Fotor.jpg&#34; alt=&#34;CGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました&#34; /&gt;&lt;/p&gt;

&lt;p&gt;9/10（木）発売のCGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました。&lt;/p&gt;

&lt;p&gt;デモシーンの魅力や、64KB制限で映像作品を創るための3Dモデルやテクスチャのプロシージャル生成について解説しています。&lt;/p&gt;

&lt;p&gt;この記事をきっかけにCGWORLD読者の方々にもデモシーンに興味をもっていただき、国内のデモシーンが盛り上がっていくことを願っています。&lt;/p&gt;

&lt;p&gt;もちろん自分の活動を知っている方々もお手に取っていただければとても嬉しいです！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;9/10（木）発売のCGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました。&lt;br&gt;&lt;br&gt;デモシーンの魅力や、64KB制限で映像作品を創るための3Dモデルやテクスチャのプロシージャル生成について解説しています。&lt;a href=&#34;https://t.co/BPf1txlSxU&#34;&gt;https://t.co/BPf1txlSxU&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/CGWjp?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CGWjp&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/demoscene?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#demoscene&lt;/a&gt; &lt;a href=&#34;https://t.co/XXpCh1xiFw&#34;&gt;pic.twitter.com/XXpCh1xiFw&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ #CEDEC2020 9/4登壇, CGWORLD 10月号 (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1301514617588518915?ref_src=twsrc%5Etfw&#34;&gt;September 3, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;購入方法&#34;&gt;購入方法&lt;/h1&gt;

&lt;p&gt;Amazonのアフェリエイトリンクを貼っておきます。&lt;/p&gt;

&lt;iframe style=&#34;width:120px;height:240px;&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; src=&#34;//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=000000&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=gam00220c-22&amp;language=ja_JP&amp;o=9&amp;p=8&amp;l=as4&amp;m=amazon&amp;f=ifr&amp;ref=as_ss_li_til&amp;asins=B08FP5NM5P&amp;linkId=8ed32da93c5253b64ba074583462b34a&#34;&gt;&lt;/iframe&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;Twitter上の反響を認知している範囲でメモしておきます。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;すごい、、表紙に「デモシーン」の文字があるぅ、、！&lt;a href=&#34;https://twitter.com/hashtag/CGWjp?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CGWjp&lt;/a&gt;&lt;/p&gt;&amp;mdash; Setsuko (@setsuko_h) &lt;a href=&#34;https://twitter.com/setsuko_h/status/1303997649582874625?ref_src=twsrc%5Etfw&#34;&gt;September 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;CGWORLD vol.266「デモシーンを支えるプロシージャル技術」を買ってきて読んだ。ディファードレンダリングか。まさに俺が手を付けようとしてるとこだね。これとエフェクトを何とかしないと勝負にはならないな。&lt;/p&gt;&amp;mdash; gaziya (@gaziya5) &lt;a href=&#34;https://twitter.com/gaziya5/status/1303907439134220288?ref_src=twsrc%5Etfw&#34;&gt;September 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;がむさん…！ &lt;a href=&#34;https://t.co/0SV02Jq91M&#34;&gt;pic.twitter.com/0SV02Jq91M&lt;/a&gt;&lt;/p&gt;&amp;mdash; さだきち : sadakkey (@sadakkey) &lt;a href=&#34;https://twitter.com/sadakkey/status/1304006171674640386?ref_src=twsrc%5Etfw&#34;&gt;September 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;余談&#34;&gt;余談&lt;/h1&gt;

&lt;p&gt;ついに商業誌デビュー！と思ったら、よく考えたら2007年にWindows100%のフリーゲーム紹介コーナーに自作ゲームがちょっとだけ掲載されたのを思い出しました（当時は中学生）。&lt;/p&gt;

&lt;p&gt;今回は4ページしっかりと担当できましたし、CGWORLDという映像業界において圧倒的な知名度のある雑誌に寄稿する機会をいただけて、本当に嬉しいです。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Revision2020 PC 64K Intro 優勝作品『RE: SIMULATED』の技術解説</title>
      <link>https://gam0022.net/blog/2020/04/30/revision2020/</link>
      <pubDate>Thu, 30 Apr 2020 12:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2020/04/30/revision2020/</guid>
      <description>&lt;p&gt;4月10日～4月13日に世界最大のデモパーティ&lt;a href=&#34;https://2020.revision-party.net/start&#34;&gt;Revision 2020&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;Revision 2020内で開催されたコンペのうち、&lt;a href=&#34;https://2020.revision-party.net/competitions/pc-competitions&#34;&gt;PC 64K Intro&lt;/a&gt;という64KBの容量制約のある部門で『RE: SIMULATED by gam0022 &amp;amp; sadakkey』という作品を発表しました。&lt;/p&gt;

&lt;p&gt;Tokyo Demo Fest 2018に続き、私（&lt;a href=&#34;https://twitter.com/gam0022&#34;&gt;@gam0022&lt;/a&gt;）が映像を、さだきちさん（&lt;a href=&#34;https://twitter.com/sadakkey&#34;&gt;@sadakkey&lt;/a&gt;）が音楽を制作しました。&lt;/p&gt;

&lt;p&gt;……なんと、本作品が参加者投票により1位に選ばれました！
日本人のチームがPC 64K Intro部門で優勝するのは Revision 史上初です。とても嬉しいです！&lt;/p&gt;

&lt;p&gt;本記事では、技術解説をメインに、『RE: SIMULATED by gam0022 &amp;amp; sadakkey』を紹介したいと思います。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/resimulated-collage.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/resimulated-collage.jpg&#34; alt=&#34;resimulated-collage&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;作品へのリンク&#34;&gt;作品へのリンク&lt;/h1&gt;

&lt;p&gt;WebGLとWebAudioによる64K Introなので、最新のChromeと高性能なGPUがあれば、ブラウザ上で動作します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/webgl/64k-intro_resimulated.html&#34;&gt;64KB HTML version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://neort.io/art/bqa4pgs3p9f6qoqnmujg&#34;&gt;NEORT version&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;高スペックのPCを持っていない方は、YouTubeの動画をご覧ください。&lt;/p&gt;

&lt;p&gt;フラクタルをつかった映像のビットレートの高い作品ですが、4K解像度を選ぶことである程度は綺麗な状態で見れます。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/tirAdWbceak&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;こちらはpouet（デモシーンのコミュニティサイト）のリンクです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pouet.net/prod.php?which=85260&#34;&gt;RE: SIMULATED by Gam0022 &amp;amp; Sadakkey :: pouët.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;技術解説&#34;&gt;技術解説&lt;/h1&gt;

&lt;p&gt;ソースコードはすべてGitHubに公開しているので、興味がある方はぜひ見てください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/resimulated&#34;&gt;gam0022/resimulated: 1st place at Revision 2020 (PC 64K Intro)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;サウンド編についてはさだきちさんが解説されています。あわせてご覧ください！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.klab.com/jp/blog/creative/2020/revision-2020-pc-64k-intro.html&#34;&gt;Revision 2020 のPC 64K INTRO 優勝作品のサウンドについて&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;キーワードとしては、以下の技術が使われています。&lt;/p&gt;

&lt;p&gt;TypeScript, WebGL, WebAudio, webpack, pnginator.rb, Raymarching, GLSL Sound&lt;/p&gt;

&lt;h2 id=&#34;シンプルなwebglエンジン-chromatiq&#34;&gt;シンプルなWebGLエンジン『Chromatiq』&lt;/h2&gt;

&lt;p&gt;64KBの容量制約があるため、Unityやthree.jsといった既存のゲームエンジンやフレームワークを利用せずに、描画用のWebGLエンジンと制作用のツール（エディタ機能）を自作する必要がありました。&lt;/p&gt;

&lt;p&gt;OpenGLやDirectXを使わずに、WebGLを選択した理由は以下です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;WebGLでブラウザ上で動かせれば、手元のPCで動かしてもらえる可能性が高いと考えた

&lt;ul&gt;
&lt;li&gt;自分の作品は映像のビットレートが高く、動画だと綺麗にならない&lt;/li&gt;
&lt;li&gt;手元のPCで実行して綺麗な状態で見てもらいたい&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Webフロントエンドの技術をキャッチアップしたかった&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;そこで、64K Intro向けに&lt;strong&gt;ファイルサイズの最小化を目指したシンプルなWebGLエンジン『Chromatiq』&lt;/strong&gt;を開発しました。&lt;/p&gt;

&lt;p&gt;WebGLエンジンとは言うものの、本当にシンプルで最小限な機能しか &amp;ldquo;現段階では&amp;rdquo; 実装していません。&lt;/p&gt;

&lt;p&gt;なるべく作品に依存した機能は用意したくなかったので、汎用的な設計になっています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;マルチパスのImageShaderによるレンダリング（viewport square）&lt;/li&gt;
&lt;li&gt;ビルドインのBloomのポストエフェクト

&lt;ul&gt;
&lt;li&gt;どんな作品でも利用できそうなので、これだけビルドインにした&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;TypeScriptからuniformをアニメーションするためのインターフェース&lt;/li&gt;
&lt;li&gt;Shadertoyと互換性のあるGLSL Sound&lt;/li&gt;
&lt;li&gt;オーディオファイルの再生（mp3 / ogg）

&lt;ul&gt;
&lt;li&gt;DAWによる音楽の再生用の機能&lt;/li&gt;
&lt;li&gt;今回は先にDAWで作曲し、後からGLSLに移植する作戦にした&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;フォントをレンダリングするためのcanvasからのテクスチャ生成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;イメージとしてはGLSLエディタを排除したスタンドアローンなShadertoyが近いかもしれません。&lt;/p&gt;

&lt;p&gt;ソースコードは&lt;a href=&#34;https://github.com/gam0022/resimulated/blob/master/src/chromatiq.ts&#34;&gt;こちら&lt;/a&gt;です。単一ファイルのTypeScriptで実装しました。&lt;/p&gt;

&lt;p&gt;圧縮後のコードサイズを気にして、変な感じの実装になっているので、微妙に読みづらいかもしれません。&lt;/p&gt;

&lt;p&gt;例えば、フィールド参照の this を頭につけるとコードサイズが増えるため、コンストラクタの中で動的にインスタンスメソッドを定義することで、this の利用を最小限にしたり、
クラス外から値を参照・設定する必要があるデータのみ、フィールドとして定義する方針とています。enumもコードサイズが増えるので禁止にしました。&lt;/p&gt;

&lt;p&gt;製作の終盤から容量が余裕そうなことが判明したので、途中からファイルサイズを考慮するのを止め、mini化の中途半端感は否めないです。
このあたりは、次のデモに向けて改良していきたいと考えています。&lt;/p&gt;

&lt;p&gt;uniform名は基本的にはShadertoyと一致させているのですが、テクスチャのサンプラーはShadertoyを踏襲せずに、直前のパスを参照する &lt;code&gt;iPrevPass&lt;/code&gt; を定義しました。
これによってGLSLを書き換えずにエフェクトの順番を入れ替えたり、気軽にパスを増やしてエフェクトをチェインしやすくしました。
このあたりの仕様も、作品の需要に応じて変更していく可能性は高いです。&lt;/p&gt;

&lt;h2 id=&#34;ファイル圧縮のためのビルドプロセス&#34;&gt;ファイル圧縮のためのビルドプロセス&lt;/h2&gt;

&lt;p&gt;圧縮には&lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;と&lt;a href=&#34;https://gist.github.com/gasman/2560551&#34;&gt;pnginator.rb&lt;/a&gt;を利用しています。&lt;/p&gt;

&lt;p&gt;ビルドプロセスを図にしました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/build-process.svg&#34; alt=&#34;build-process&#34; /&gt;&lt;/p&gt;

&lt;p&gt;webpackですべてのファイルをbundle.jsという単一のJavaScriptに固めてから、pnginator.rbで自己解凍形式のPNGにしています。&lt;/p&gt;

&lt;p&gt;TypeScriptのminifyは完全にwebpack任せです。&lt;/p&gt;

&lt;p&gt;PNGでは画像データをzlib圧縮するため、画像データではなくても、例えば今回のようなプログラムのソースコードでちゃんと圧縮できます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/gam0022/items/364c7f76f2787e385161&#34;&gt;GLSLのminifyも検証&lt;/a&gt;はしていて、webpackのLoaderを開発する予定もあったのですが、容量が余裕だったのでGLSLの圧縮はPNG（zlib）だけになりました。&lt;/p&gt;

&lt;p&gt;また、開発用にしか必要ないコードの削除もwebpackの&lt;a href=&#34;https://webpack.js.org/plugins/define-plugin/&#34;&gt;define-plugin&lt;/a&gt;で実現できました。&lt;/p&gt;

&lt;p&gt;webpackとpnginator.rbを組み合わせる手法は、&lt;a href=&#34;https://twitter.com/FMS_Cat&#34;&gt;FMS_Catさん&lt;/a&gt;の&lt;a href=&#34;https://github.com/FMS-Cat/until/&#34;&gt;Until&lt;/a&gt;を参考にしました。&lt;/p&gt;

&lt;p&gt;当初はnode.jsでGLSLのホットリロード機能付きのWebサーバを開発しようと技術検証していたのですが、
要件は&lt;a href=&#34;https://github.com/webpack/webpack-dev-server&#34;&gt;webpack-dev-server&lt;/a&gt;ですべて実現可能だったので、webpackを採用しました。&lt;/p&gt;

&lt;p&gt;PRごとに圧縮後のファイルサイズを確認するようにしたら、圧縮後のファイルサイズについて知見が貯まりました（例）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;コードの自動フォーマットをかけると、圧縮効率が上がってファイルサイズが減る&lt;/li&gt;
&lt;li&gt;コードをコピペすると圧縮効率が高くなるので、実は無理にコードを共通化する意味は実は薄い&lt;/li&gt;
&lt;li&gt;似たよな構造になるようにコードを意識すると圧縮効率が良くなる&lt;/li&gt;
&lt;li&gt;関数の順番を入れ替えただけで微妙にサイズが減ったりと謎が多い&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;制作用のエディタ機能の紹介&#34;&gt;制作用のエディタ機能の紹介&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/chromatiq-editor.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/chromatiq-editor.png&#34; alt=&#34;chromatiq-editor&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;製作のイテレーションを高速化するため、必要なエディタ機能は一通り実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;再生位置のシーク機能

&lt;ul&gt;
&lt;li&gt;再生・一時停止・停止・フレームのコマ送り・時間の表示単位の秒とビートの切り替え&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;GLSLやTypeScriptのホットリロード機能&lt;/li&gt;
&lt;li&gt;uniformのパラメータのインスペクタ&lt;/li&gt;
&lt;li&gt;カメラの自由移動&lt;/li&gt;
&lt;li&gt;デバッグ用に特定のパスの表示&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;エディタ機能は容量制約に影響しないので、既存のライブラリを積極的に利用しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ボタン用のアイコンのために、&lt;a href=&#34;https://fontawesome.com/&#34;&gt;fontawesome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;uniformのパラメータのインスペクタのために、&lt;a href=&#34;https://github.com/dataarts/dat.gui&#34;&gt;dat.gui&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;カメラの自由移動のために、&lt;a href=&#34;https://threejs.org/&#34;&gt;three.js&lt;/a&gt;の&lt;a href=&#34;https://threejs.org/docs/#examples/en/controls/OrbitControls&#34;&gt;OrbitControls&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/gam0022/resimulated#1-get-started&#34;&gt;リポジトリ&lt;/a&gt;をcloneして、 &lt;code&gt;npm run start&lt;/code&gt; すれば、エディタ機能が使えますので、興味がある人はお試しください。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:gam0022/resimulated.git
cd resimulated
npm install

# 制作用のエディタを起動
npm run start

# 提出用のビルド（dist\resimulated.html）を生成
npm run build
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;uniformのパラメータのインスペクタ&#34;&gt;uniformのパラメータのインスペクタ&lt;/h3&gt;

&lt;p&gt;GLSL上で以下のようなuniformを宣言するだけで、そのままインスペクタに表示されるような仕組みを実装しました。&lt;/p&gt;

&lt;p&gt;コメントでは左から順に &lt;code&gt;初期値 min max カテゴリー名&lt;/code&gt; を指定しています。初期値は必須ですが、それ以外は省略可能としました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;uniform float gEmissiveIntensity;     // 6.0 0 20 emissive
uniform float gEmissiveSpeed;         // 1 0 2
uniform float gEmissiveHue;           // 0.33947042613522904 0 1
uniform float gEmissiveHueShiftBeat;  // 0 0 1
uniform float gEmissiveHueShiftZ;     // 0 0 1
uniform float gEmissiveHueShiftXY;    // 0 0 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;uniform宣言をすると、自動的にインスペクタにパラメータが追加されます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/chromatiq-editor-emissive.png&#34; alt=&#34;chromatiq-editor-emissive&#34; /&gt;&lt;/p&gt;

&lt;p&gt;私の作品では、フラクタルやIFSといったパラメータの細かな調整が重要になる表現を多用しているため、気軽にパラメータを増やして、気軽に値を調整できるようにしました。&lt;/p&gt;

&lt;p&gt;値の当たりをつけた後に、パラメータのアニメーションを&lt;a href=&#34;https://github.com/gam0022/resimulated/blob/master/src/index.common.ts#L142-L569&#34;&gt;TypeScriptのコード&lt;/a&gt;に落とし込むワークフローにしました。&lt;/p&gt;

&lt;p&gt;これは、インスペクタを動かしている様子の動画です。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;三谷先生に便乗して、MengerSponge をカットしてみました。&lt;br&gt;断面が星みたいになって面白いですね⭐️ &lt;a href=&#34;https://t.co/mCqFnfbjBF&#34;&gt;https://t.co/mCqFnfbjBF&lt;/a&gt; &lt;a href=&#34;https://t.co/QF73xfFL1y&#34;&gt;pic.twitter.com/QF73xfFL1y&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ / encoder killer (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1253296266424930304?ref_src=twsrc%5Etfw&#34;&gt;April 23, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&#34;動画の保存機能&#34;&gt;動画の保存機能&lt;/h3&gt;

&lt;p&gt;処理落ちなしに4K解像度で動画を出力したかったので、以下の機能を実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;映像の連番PNG保存機能&lt;/li&gt;
&lt;li&gt;サウンドの wav 保存機能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;.png と .wav を ffmpeg で .mp4 に変換してYouTubeにアップロードしました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ffmpeg.exe -r 60 -i chromatiq%04d.png -i chromatiq.wav -c:v libx264 -preset slow -profile:v high -coder 1 -pix_fmt yuv420p -movflags +faststart -g 30 -bf 2 -c:a aac -b:a 384k -profile:a aac_low -b:v 68M chromatiq_68M.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;YouTube用のffmpegのエンコード設定については、以下を参考にしました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://support.google.com/youtube/answer/1722171?hl=ja&#34;&gt;アップロードする動画におすすめのエンコード設定&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;映像ビットレート 2160p（4k）53～68 Mbps&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/mikoim/27e4e0dc64e384adbcb91ff10a2d3678&#34;&gt;YouTube recommended encoding settings on ffmpeg (+ libx264)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/sasaki_0222/status/1248910333835530241&#34;&gt;解像度とビットレードについて by sasaki_0222&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;映像について&#34;&gt;映像について&lt;/h2&gt;

&lt;p&gt;映像の3D描画は基本的に全部レイマーチングです。&lt;/p&gt;

&lt;p&gt;前半のサイバーなシーンはMandelboxをベースにしました。&lt;/p&gt;

&lt;p&gt;後半の宇宙空間とグリーティングのシーンでは、宇宙空間はレイマーチング、惑星の上のグリーティングの文字はAABBとして解析的に衝突判定をするハイブリッドなレイトレをしています。&lt;/p&gt;

&lt;p&gt;パスの構成は、最終的にこうなりました。&lt;/p&gt;

&lt;p&gt;1パス目と2パス目を分離したのは、シェーダーのコンパイル時間の短縮のためです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1パス目: 前半のシーンのレイマーチング&lt;/li&gt;
&lt;li&gt;2パス目: 後半のシーンのレイマーチング&lt;/li&gt;
&lt;li&gt;3パス目: テキストの描画&lt;/li&gt;
&lt;li&gt;4～13パス目: Bloomのポストエフェクト&lt;/li&gt;
&lt;li&gt;14パス目: ポストエフェクトとトーンマッピング&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;惑星のバリエーション生成の仕組み&#34;&gt;惑星のバリエーション生成の仕組み&lt;/h3&gt;

&lt;p&gt;後半のグリーティングでは、自分が特に尊敬しているデモグループをイメージした惑星が合計14パターン登場します。&lt;/p&gt;

&lt;p&gt;様々なバリエーションの惑星を効率的に生成するための仕組みを実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;地形の高さマップの自動生成&lt;/li&gt;
&lt;li&gt;テクスチャの色のグラデーションの自動生成&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;地形の高さマップの自動生成&#34;&gt;地形の高さマップの自動生成&lt;/h4&gt;

&lt;p&gt;2DのValue Noiseを重ね合わせたfbm（Fractal Brownian Motion）で地形の高さマップを生成しました。&lt;/p&gt;

&lt;p&gt;さらに、fbm関数をネストして（fbmのUV計算にfbmをつかって）、歪んだような不思議な雰囲気の地形も生成できるようにしました。&lt;/p&gt;

&lt;p&gt;左がfbmのネストよる歪みなしで、右がfbmのネストによる歪みありです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/fbm-shift.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/fbm-shift.jpg&#34; alt=&#34;fbm-shift&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;fbmの各種パラメーター（振幅や周波数、Y方向のスケール、歪み用のfbmの強度）は、乱数ではなく、配列で直接指定することで、イメージ通りの結果に調整できるようにしました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// fbmAmp, fbmFreq, fbmYScale, fbmShift
vec4[PLANETS_PAT_MAX * PLANETS_NUM_MAX] planetFbmParams = vec4[](
    // MIX_A
    vec4(0.3, 17.0, 1.0, 0.01), vec4(0.05, 10.0, 1.05, 0.0), vec4(0.05, 10.0, 1.05, 0.01),
    vec4(0.05, 10.0, 4.05, 0.02), vec4(0.05, 10.0, 2.05, 00.1), vec4(0.0),
    // MIX_B
    vec4(0.0, 10.0, 1.0, 0.2), vec4(0.0, 10.0, 1.0, 0.01), vec4(0.0, 10.0, 1.0, 0.03),
    vec4(0.05, 10.0, 1.0, 00.2), vec4(0.06, 10.0, 1.0, 0.03), vec4(0.05, 10.0, 1.0, 0.03));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このようなfbmをネストしたシンプルな関数で高さマップを生成しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// 惑星の高さマップ（height map）を生成する関数
// pは球体のUV, id は惑星のID
float hPlanetsMix(vec2 p, int id) {
    p.y *= planetFbmParams[id].z;
    return fbm(p + 
        planetFbmParams[id].w * fbm(p, 4.0 * planetFbmParams[id].y), planetFbmParams[id].y);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;テクスチャの色のグラデーションの自動生成&#34;&gt;テクスチャの色のグラデーションの自動生成&lt;/h4&gt;

&lt;p&gt;iqのColor Palettesを使いました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://iquilezles.org/www/articles/palettes/palettes.htm&#34;&gt;Color Palettes - Inigo Quilez :: fractals, computer graphics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec3 pal(in float t, in vec3 a, in vec3 b, in vec3 c, in vec3 d) {
    return a + b * cos(TAU * (c * t + d));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pal 関数の使い方は簡単で、&lt;code&gt;a, b, c, d&lt;/code&gt; を任意に指定すれば、&lt;code&gt;t&lt;/code&gt; を変化することでグラデーションを生成できます。&lt;/p&gt;

&lt;p&gt;今回は &lt;code&gt;a, b, c&lt;/code&gt; は定数、&lt;code&gt;d&lt;/code&gt; は惑星ごとに乱数で決定しました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;a, b, c&lt;/code&gt; や乱数のseed値はインスペクタで値を調整しながら、イメージ通りのグラデーションが生成されるまで試行錯誤しました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;t&lt;/code&gt; は地形の高さマップにマッピングしました。&lt;/p&gt;

&lt;h3 id=&#34;無数の小惑星のランダムな配置&#34;&gt;無数の小惑星のランダムな配置&lt;/h3&gt;

&lt;p&gt;宇宙空間がスカスカすぎて寂しかったので、無数の小惑星をランダムに配置しようとしたら、予想外に苦戦しました。&lt;/p&gt;

&lt;p&gt;レイマーチングだと空間をmodすることで物体を無限に複製することは簡単なのですが、それでは規則的な配置にしかならず、かなり不自然になってしまいます。&lt;/p&gt;

&lt;p&gt;gazさんのシェーダーを参考にして、空間をgridに分割して、gridごとに乱数を生成して、乱数で確率的に物体を間引く手法を採用しました。&lt;/p&gt;

&lt;p&gt;また、アーティファクトの回避するために、rayの長さを制限する工夫も必要でした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;もう忘れてるよ。自分で読み解いてしまったじゃないか。xy平面を通常のmod()で分割。z軸の奥行のみgridをseedに乱数を使い間引きしてる。z軸だけ空間移動のスピード、回転を変えてる。アーティファクト対策で、min(map(p), 1.0)を使いrayの長さを制限。effectにビルボードを使い発光を演出。&lt;/p&gt;&amp;mdash; gaz (@gaziya5) &lt;a href=&#34;https://twitter.com/gaziya5/status/1247671912521596928?ref_src=twsrc%5Etfw&#34;&gt;April 7, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;最終的に、ランダムな位置と大きさをもつ小惑星の距離関数はこうなりました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float dGomi(vec3 p) {
    // アーティファクト対策のための固定長の距離
    float d = 1.0;

    // グリット（4m四方の立方体）の計算
    vec3 g = vec3(floor(p / 4.0));

    // 座標の繰り返し
    p = mod(p, 4.0) - 2.0;

    // 確率 rate に応じて球体を配置
    vec3 rand = hash33(g);
    float rate = (gPlanetsId != PLANETS_EARTH) ? 0.08 : 0.01;
    if (rand.x &amp;lt; rate) {
        p -= (rand - 0.5);
        d = sdSphere(p, 0.1 * rand.y);
    }

    // fbmで表面の凹凸のディテールを加える
    // レイが接近したときだけに計算するのは、LODによる負荷対策
    // fbmの計算はかなり高負荷なので、LODをしないと激重になる
    if (d &amp;lt; 0.5) {
        vec2 uv = uvSphere(normalize(p));
        uv.x += dot(rand, vec3(1.0));
        d -= remapTo(rand.z, 0.01, 0.08) * fbm(uv, 5.0);
    }

    return d;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;音楽について&#34;&gt;音楽について&lt;/h2&gt;

&lt;p&gt;基盤となるGLSLサウンド用のシーケンサーの実装は私が、それ以外のオシレーターの関数やメロディの実装はさだきちさんが担当しました。&lt;/p&gt;

&lt;p&gt;音楽もやはり容量制約のためにGLSLで実装する必要があり、さだきちさんにはコーディングによる作曲をお願いしました。
さだきちさんはプログラミングもGLSLも未経験だったので、それらの習得から始まりました。
かなり無茶なお願いだったにも関わらず、かっこいいトランスミュージックを提供してくれたさだきちさんには感謝しかありません。ありがとうございます！&lt;/p&gt;

&lt;p&gt;私が担当したGLSLサウンド用のシーケンサーはGLSLサウンド上で実装されており、GLSLサウンドを鳴らす仕組みについては、AMAGIさん（&lt;a href=&#34;https://twitter.com/amagitakayosi&#34;&gt;@amagitakayosi&lt;/a&gt;）の記事を参考に、Shadertoy互換のGLSLサウンドの再生機能を実装しました。ありがとうございます！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.amagi.dev/entry/veda-sound&#34;&gt;VEDA 2.4: GLSLで音楽を演奏できるようになったぞ！！！ - マルシテイア&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;サウンド用のシーケンサーの利用例&#34;&gt;サウンド用のシーケンサーの利用例&lt;/h3&gt;

&lt;p&gt;これはベースのパートの波形を生成するGLSLの関数です。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec2 bass1(float beat, float time) {
// 1つのパターンのビート数
#define BASS1_BEAT_LEN 8

// パターンの種類
#define BASS1_DEV_PAT 10

// 楽曲全体の長さのパターン数
#define BASS1_DEV_LEN 32

    // パターンの定義
    int[BASS1_BEAT_LEN * NOTE_DIV * BASS1_DEV_PAT] notes = int[](
        // パターン0
        F(0), F(33), E(0, 33), S(0, 33, 0, 33),
        F(0), F(33), E(0, 33), S(0, 33, 0, 33),

        // パターン1
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),

        // パターン2
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(29, 29), S(0, 29, 29, 29), S(0, 31, 31, 31), S(48, 47, 43, 40),

        // パターン3
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 34, 34, 34),

        // パターン4
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 36, 36, 36),

        // パターン5
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 34, 34, 34), S(0, 36, 36, 36),

        // パターン6
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 43, 43, 43), S(0, 55, 57, 69),

        // パターン7
        E(29, 29), S(0, 29, 29, 29), S(0, 29, 29, 29), S(0, 31, 33, 45),
        E(29, 29), S(0, 29, 29, 29), S(0, 29, 29, 29), S(0, 31, 31, 31),

        // パターン8
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 43, 45, 57),

        // パターン9
        E(29, 29), S(0, 29, 29, 29), S(0, 29, 29, 29), S(0, 31, 33, 45),
        E(29, 29), S(0, 29, 29, 29), S(0, 31, 31, 31), S(0, 31, 31, 31));

    // パターンの進行
    int[BASS1_DEV_LEN / DEV_PACK] development = int[](
        D(0, 0, 0, 0, 0, 0, 0, 0), D(1, 1, 1, 2, 3, 4, 5, 6),
        D(7, 0, 7, 8, 7, 0, 9, 0), D(0, 0, 0, 0, 0, 0, 0, 0));

    SEQUENCER(beat, time, BASS1_BEAT_LEN, BASS1_DEV_PAT, BASS1_DEV_LEN,
        notes, development, bass)

    return ret;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パターン（2小節分のノートナンバーの並び）の定義と進行は、それぞれ配列で指定できるようにしています。&lt;/p&gt;

&lt;p&gt;音の長さは下記の4種類に対応しました。
ノートナンバーに0を指定すれば、同じ長さの休符になります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;O: 全音符&lt;/li&gt;
&lt;li&gt;F: 4分音符&lt;/li&gt;
&lt;li&gt;E: 8分音符&lt;/li&gt;
&lt;li&gt;S: 16分音符&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GLSLのコンスタントバッファのサイズには上限があり、サウンド用のシェーダー全体で要素数が4096個まででしか配列を宣言できません。&lt;/p&gt;

&lt;p&gt;そこで、&lt;code&gt;O, F, E, S&lt;/code&gt; を関数マクロとし、16分音符を最小単位として各音符を16bit（うち、ノートナンバーが8bit、音の長さが8bit）ずつパッキングしています。
GLSLのintは32bitなので、int配列の1要素に16分音符なら2つ、8分音符なら1つ入るような設計です。&lt;/p&gt;

&lt;p&gt;また、パターン進行の &lt;code&gt;D&lt;/code&gt; もマクロにしていて、要素数の節約のために4bitずつパッキングをしています。&lt;/p&gt;

&lt;p&gt;続いて、&lt;code&gt;bass&lt;/code&gt; は時間とノートナンバーを入力として、波形を出力するオシレーターのGLSL関数です。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;SEQUENCER&lt;/code&gt; は、時間、パターンの定義の配列、パターンの進行の配列、オシレーターの関数を指定することで、パートごとの波形を生成して &lt;code&gt;vec2 ret&lt;/code&gt; に代入する関数マクロです。
GLSLでは関数を引数とするような高階関数は実現できませんが、関数マクロで擬似的に実現しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define SEQUENCER(beat, time, beatLen, devPat, devLen, notes, development, toneFunc)  \
    int indexOffset = development[int(                                                \
        mod(beat / float(beatLen * DEV_PACK), float(devLen / DEV_PACK)))];            \
    indexOffset =                                                                     \
        (indexOffset &amp;gt;&amp;gt; (4 * int(mod(beat / float(beatLen), float(DEV_PACK))))) &amp;amp; 15; \
    indexOffset *= beatLen * NOTE_VDIV;                                               \
                                                                                      \
    for (int i = 0; i &amp;lt; beatLen * NOTE_VDIV;) {                                       \
        int index = i + indexOffset;                                                  \
        int shift = (index % 2 == 1) ? 16 : 0;                                        \
        int div = ((notes[index &amp;gt;&amp;gt; 1] &amp;gt;&amp;gt; shift) &amp;gt;&amp;gt; 8) &amp;amp; 255;                          \
        int len = NOTE_VDIV * NOTE_VDIV / div;                                        \
        for (int j = 0; j &amp;lt; len; j++) {                                               \
            tmpIndexes[i + j] = i;                                                    \
        }                                                                             \
        i += len;                                                                     \
    }                                                                                 \
                                                                                      \
    float indexFloat = mod(beat * float(NOTE_VDIV), float(beatLen * NOTE_VDIV));      \
    int index = int(indexFloat);                                                      \
    int shift = (index % 2 == 1) ? 16 : 0;                                            \
    int note = (notes[(index + indexOffset) &amp;gt;&amp;gt; 1] &amp;gt;&amp;gt; shift) &amp;amp; 255;                    \
    float localTime =                                                                 \
        beatToTime((indexFloat - float(tmpIndexes[index])) / float(NOTE_VDIV));       \
    float amp = (note == 0) ? 0.0 : 1.0;                                              \
    vec2 ret = vec2(toneFunc(float(note), localTime) * amp);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パターンの定義・進行のマクロはこちらです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// 1ビートを最大何分割するか。16分音符に対応するなら4
#define NOTE_VDIV 4

// 1ビートのpackingを考慮した分割数。32bitのintに16bitずつ詰めているので
// 4 / (32 / 16) = 2
#define NOTE_DIV 2

// 展開用の配列のpacking数。32bitのintに4bitずつ詰めているので
// 32 / 4 = 8
#define DEV_PACK 8

#define MAX_BEAT_LEN 8
int[MAX_BEAT_LEN * NOTE_VDIV] tmpIndexes;

#define O(a)                                                                      \
    (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16),     \
        (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), \
        (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), \
        (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define F(a) (a | 4 &amp;lt;&amp;lt; 8) | ((a | 4 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 4 &amp;lt;&amp;lt; 8) | ((a | 4 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define E(a, b) (a | 8 &amp;lt;&amp;lt; 8) | ((a | 8 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (b | 8 &amp;lt;&amp;lt; 8) | ((b | 8 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define S(a, b, c, d) \
    (a | 16 &amp;lt;&amp;lt; 8) | ((b | 16 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (c | 16 &amp;lt;&amp;lt; 8) | ((d | 16 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define D(a, b, c, d, e, f, g, h) \
    (a) | (b &amp;lt;&amp;lt; 4) | (c &amp;lt;&amp;lt; 8) | (d &amp;lt;&amp;lt; 12) | (e &amp;lt;&amp;lt; 16) | (f &amp;lt;&amp;lt; 20) | (g &amp;lt;&amp;lt; 24) | (h &amp;lt;&amp;lt; 28)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;re-simulated-の意味&#34;&gt;『RE: SIMULATED』の意味&lt;/h1&gt;

&lt;p&gt;タイトルの『RE: SIMULATED』には2つの意味を込めました。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;前作『WORMHOLE』の64K Introとしての「再現」&lt;/li&gt;
&lt;li&gt;SIMULATED REALITY&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;1-前作-wormhole-の64k-introとしての-再現&#34;&gt;1. 前作『WORMHOLE』の64K Introとしての「再現」&lt;/h2&gt;

&lt;p&gt;一昨年のTokyo Demo Fest 2018のCombined Demo Compoでも、さだきちさんとチームを組んで『WORMHOLE』という作品を制作しました（&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;記事&lt;/a&gt;）。&lt;/p&gt;

&lt;p&gt;前半のシーンが顕著ですが、『WORMHOLE』と表現や演出が酷似していると思います。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;フラクタルの形状変化&lt;/li&gt;
&lt;li&gt;光の色の変化&lt;/li&gt;
&lt;li&gt;シーン転換前の激しい点滅&lt;/li&gt;
&lt;li&gt;シーン転換後のホワイトイン&lt;/li&gt;
&lt;li&gt;パーティのロゴの登場&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;『WORMHOLE』はUnityで制作したので、60.7 MB（zip圧縮で 23.18MB）というファイルサイズでした。&lt;/p&gt;

&lt;p&gt;前作では、Unityを利用したことで賛否両論があったので、ツールに頼らなくても同様のビジュアルを再現できることを証明する意図がありました。&lt;/p&gt;

&lt;p&gt;また、64K Introなどの容量制限のある部門への参加が個人的にも憧れだったという理由もあります。&lt;/p&gt;

&lt;p&gt;今回は自作のシステムで作品を制作することでファイルサイズは26KBになりました。&lt;/p&gt;

&lt;p&gt;同じ表現を「再現」しつつも、容量を &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2334&lt;/sub&gt; まで圧縮する試みのコンセプトは達成できました。&lt;/p&gt;

&lt;p&gt;まさか、コンポで優勝するという結果まで「再現」してしまうのは予想外でした（笑）&lt;/p&gt;

&lt;h2 id=&#34;2-simulated-reality&#34;&gt;2. SIMULATED REALITY&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B7%E3%83%9F%E3%83%A5%E3%83%AC%E3%83%BC%E3%83%86%E3%83%83%E3%83%89%E3%83%BB%E3%83%AA%E3%82%A2%E3%83%AA%E3%83%86%E3%82%A3&#34;&gt;Simulated Reality&lt;/a&gt;という裏設定もありました。&lt;/p&gt;

&lt;p&gt;作品の最後に「RE: SIMULATED」の文字が&lt;/p&gt;

&lt;p&gt;&lt;code&gt;RE: SIMULATED&lt;/code&gt; → &lt;code&gt;RE&lt;/code&gt; → &lt;code&gt;REALITY&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;と変化して、REALITYに変化するタイミングで「地球」がフラッシュバックするのは、Simulated Realityの暗喩です。&lt;/p&gt;

&lt;p&gt;前半のサイバーなシーンは電子的な仮想空間という設定で、シーン転換時に球体を中心に空間が歪んで圧縮するのは、宇宙誕生の爆発であるビッグバンの暗喩です。&lt;/p&gt;

&lt;p&gt;この世界は上位存在によって電子的にシミュレーションされた仮想現実で、最後に自分たちが住む地球を見つけるというストーリーでした（あくまで裏設定だったので、見た人に通じなくても良い）。&lt;/p&gt;

&lt;p&gt;できれば現実と見分けがつかないようなリアルなグラフィックで表現できたら良かったのですが、力量不足でした……。&lt;/p&gt;

&lt;h1 id=&#34;おわりに&#34;&gt;おわりに&lt;/h1&gt;

&lt;p&gt;Webフロントエンドは久しぶりで、node.jsとwebpackは初めてだったので、新しい技術を学ぶ良い機会となりました。&lt;/p&gt;

&lt;p&gt;昔はjQueryが必要だったDOMのセレクターやHTTPアクセスが、標準のAPI（&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Document/querySelector&#34;&gt;querySelector&lt;/a&gt;や&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Fetch_API/Using_Fetch&#34;&gt;Fetch&lt;/a&gt;）になっていて驚きました。&lt;/p&gt;

&lt;p&gt;TypeScript（ECMascript）に苦手意識がありましたが、最近はかなり使いやすい言語になったなぁと認識を改めました。
演算子オーバーロードがないのだけは、3Dプログラミングには必須のベクトル計算の実装の可読性が落ちて苦しい気持ちになったので、早くサポートして欲しいと感じました。&lt;/p&gt;

&lt;p&gt;また、64K Introのエントリーは今回が初めてということで、どのくらいのコンテンツが詰め込めるか感覚がつかめず、容量を半分以上も余らせてしまいました。
次の機会には64KBギリギリまで使って、もっと映像としても洗練させて、さらにCoolな作品を発表したいです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;実は26KBしか使いきれなかったので、次回は64KBギリギリまで使えるように精進します💪 &lt;a href=&#34;https://t.co/uxF2M5DZmg&#34;&gt;pic.twitter.com/uxF2M5DZmg&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ / encoder killer (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1249677712815321088?ref_src=twsrc%5Etfw&#34;&gt;April 13, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;例年のRevisionの64K Introの作品と比較すると、かなり未熟なので、もっと精進して最高のデモを作りたいという気持ちです。&lt;/p&gt;

&lt;p&gt;ともあれ、このたびは優勝作品に選んでいただき、とても光栄に思います。&lt;/p&gt;

&lt;p&gt;世界中の尊敬するデモチームの方々からいただいたお祝いのコメントも嬉しかったです。わーい！&lt;/p&gt;

&lt;p&gt;最後に、世界的に大変な状況の中、オンラインでの開催のためにご尽力いただいた皆様に、心より感謝申し上げます。
とても楽しく充実した3日間を過ごせました。来年はドイツでお会いしましょう！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>近未来教育フォーラム2019でシェーダーライブコーディングをしました</title>
      <link>https://gam0022.net/blog/2019/11/29/dhw/</link>
      <pubDate>Fri, 29 Nov 2019 10:36:17 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/11/29/dhw/</guid>
      <description>&lt;p&gt;2019/11/28にデジタルハリウッド大学で開催された&lt;a href=&#34;https://www.dhw.co.jp/forum/program.html&#34;&gt;近未来教育フォーラム&lt;/a&gt;の
「The Real Time Live &amp;amp; Reception リアルタイムグラフィックスの世界とVTuberが牽引する新たな人類」というイベントに登壇しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/FL1NE&#34;&gt;@FL1NE&lt;/a&gt;さんと一緒にデモシーンについて話しました。
私は簡単なシェーダーライブコーディングをしながらプログラミングによる形状のモデリングについて解説しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/o_ob/status/1200067621799903238&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-11-29-dhw/live_coding_init.jpg&#34; alt=&#34;シェーダーライブコーディング（初期）&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/songofsaya_/status/1199999036964474886&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-11-29-dhw/live_coding.jpg&#34; alt=&#34;シェーダーライブコーディング（完成）&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;レポート-2020-05-09追記&#34;&gt;レポート（2020/05/09追記）&lt;/h2&gt;

&lt;p&gt;当日の様子のレポートが公開されました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dhw.co.jp/forum/report/report01.html&#34;&gt;近未来教育フォーラム2019 -In Real Time- 公演レポート&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;シェーダーライブコーディングによる作品&#34;&gt;シェーダーライブコーディングによる作品&lt;/h2&gt;

&lt;p&gt;WORMHOLEの前半に登場したフラクタルによる複雑な形状のトンネルのモデリングについてライブコーディングしながら解説しました。&lt;/p&gt;

&lt;p&gt;通常の3DCGでは、ツールでモデリングした3Dモデルを読み込んで表示すると思いますが、デモシーンの一部の部門には容量制限があるので、
WORMHOLEではシェーダーによるプログラミングによってプロシージャルにモデリングを行いました。&lt;/p&gt;

&lt;p&gt;発表時間が限られていたので、ハラハラ・ドキドキでしたが、なんとか意図通りの形になって良かったです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;WORMHOLEの前半に登場したフラクタルによる複雑な形状のトンネルのモデリングについてライブコーディングしながら解説しました。&lt;a href=&#34;https://twitter.com/hashtag/DHW?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DHW&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1200006025878749184?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Gam師のレイマーチング始まってる。 &lt;a href=&#34;https://t.co/MHLrFmbLpL&#34;&gt;pic.twitter.com/MHLrFmbLpL&lt;/a&gt;&lt;/p&gt;&amp;mdash; さやちゃんぐbot (@songofsaya_) &lt;a href=&#34;https://twitter.com/songofsaya__/status/1199999036964474886?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&#34;動画&#34;&gt;動画&lt;/h3&gt;

&lt;p&gt;YouTube配信のアーカイブが残っています。&lt;/p&gt;

&lt;p&gt;34:46〜が自分のシェーダーライブコーディングでした。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/j0yRASXFvlQ?start=2086&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;songofsaya-さんによる解説&#34;&gt;songofsaya_ さんによる解説&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/songofsaya_&#34;&gt;@songofsaya_&lt;/a&gt; さんがTwitterで解説をしてくださっていました。ありがとうございます！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;四角形のパイプと書いたけど、再帰性があるからおそらくメンガーだろうなーと思っていたらメンガーでした。&lt;br&gt;そしてGam師ならではのfoldRotateが登場します。これがKanetaaaaa神だとpmodと名前が変わります。 &lt;a href=&#34;https://t.co/VFqKT2jVoq&#34;&gt;pic.twitter.com/VFqKT2jVoq&lt;/a&gt;&lt;/p&gt;&amp;mdash; さやちゃんぐbot (@songofsaya_) &lt;a href=&#34;https://twitter.com/songofsaya__/status/1200008658916007938?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Gam師ならではのfoldRotateが登場します。これがKanetaaaaa神だとpmodと名前が変わります&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;正解です！&lt;/p&gt;

&lt;h2 id=&#34;発表資料&#34;&gt;発表資料&lt;/h2&gt;

&lt;p&gt;発表資料はFL1NEさんが作ってくれました。自分はライブコーディングのところを担当しました。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;b3019de333a449a481ff2df647d2d098&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;感想&#34;&gt;感想&lt;/h2&gt;

&lt;p&gt;当日は&lt;a href=&#34;https://www.sli.do/&#34;&gt;sli.do&lt;/a&gt;で来場者の声がリアルタイムに見えるようになっていました。&lt;/p&gt;

&lt;p&gt;sli.doや懇親会で、メガデモとシェーダーについて「楽しそう！」「自分でも作ってみたい」といった好意的な感想をいただけました！&lt;/p&gt;

&lt;p&gt;シェーダやレイマーチングや3DCGに少しでも興味を持っていただけたのなら嬉しい限りです。ありがとうございました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;メガデモとシェーダーについて&lt;br&gt;「楽しそう！」「自分でも作ってみたい」&lt;br&gt;といった好意的な感想をいただけて嬉しい限りです☺️&lt;a href=&#34;https://twitter.com/hashtag/DHW?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DHW&lt;/a&gt; &lt;a href=&#34;https://t.co/BCkGVOiAdv&#34;&gt;pic.twitter.com/BCkGVOiAdv&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1200068188043501568?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>レイトレ合宿7でレイマーチング対応のGPUパストレーサーを実装しました！</title>
      <link>https://gam0022.net/blog/2019/09/18/rtcamp7/</link>
      <pubDate>Wed, 18 Sep 2019 10:15:43 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/09/18/rtcamp7/</guid>
      <description>&lt;p&gt;9月7日(土)～9月8日(日)に猪苗代湖で開催された&lt;a href=&#34;https://sites.google.com/site/raytracingcamp7/&#34;&gt;レイトレ合宿7&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;自作のレンダラーでこんな画像を &lt;strong&gt;60秒の制限時間&lt;/strong&gt; でレンダリングして4位をいただきました！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/11.gam.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/11.gam.jpg&#34; alt=&#34;本番のレンダリング結果&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ちなみに4K解像度（3840x2160）です！&lt;/p&gt;

&lt;p&gt;事前に本番環境で動作確認できなかったこともあり、よく見ると意図しないアーティファクトが発生しているのですが、許容レベルに収まったのはラッキーでした。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;レイトレ合宿とは&#34;&gt;レイトレ合宿とは&lt;/h1&gt;

&lt;p&gt;レイトレ合宿は完全自作のレイトレーサーを走らせて画像の美しさを競うイベントです。&lt;/p&gt;

&lt;p&gt;参加者はレンダラーを自作する必要がある！というだけで面白いイベントなのですが、レンダリングの制限時間が毎年どんどん短縮されているのも注目ポイントです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://sites.google.com/site/rendering1h/&#34;&gt;第1回のレンダリング合宿&lt;/a&gt;では制限時間が1時間だったのですが、第7回となる今年は60秒制限でした。&lt;/p&gt;

&lt;p&gt;この制限時間はレンダラーを起動してから画像を保存するまでの時間なので、シーンの読み込みからレンダリングをすべて含めて60秒で完了させなくてはなりません。&lt;/p&gt;

&lt;p&gt;そのため、参加者はあらゆる手段をつかって、レンダラーの高速化に本気で取り組む必要があります。&lt;/p&gt;

&lt;p&gt;パストレーシングの高速化のアプローチとしては、サンプリングを効率化する、BVHなどの構造をつかってシーンとの交差判定を効率化する、ノイズを軽減するためにデノイズを行う、などが挙げられます。&lt;/p&gt;

&lt;p&gt;パストレーシングを使わないといけないルールは無いのですが、近年のレイトレ合宿ではパストレーシングが人気です。
今年のレイトレ合宿では、Stochastic Progressive Photon Mappingを実装した&lt;a href=&#34;https://github.com/tabochans&#34;&gt;tabochan&lt;/a&gt;さん以外は全員パストレーシングだったと記憶しています。&lt;/p&gt;

&lt;p&gt;また、複数コアのCPU・複数のGPUを利用したり、メモリのキャッシュ効率を上げてマシンスペックを最大限に活かし切るというのも、実はかなり難しい課題だったりします。私は今年は複数のGPUをうまく使えませんでした…&lt;/p&gt;

&lt;p&gt;参加者はプロダクションレンダラーの開発者やコンピュータグラフィック分野の研究者などのプロの人から、私のように趣味でレンダラーを開発している人まで様々です。&lt;/p&gt;

&lt;p&gt;レイトレ合宿の参加者のレベルが年々向上していて、特に今年は技術的にもアートセンスにも秀でた作品が多い中、4位と上位に食い込めて本当に嬉しかったです！&lt;/p&gt;

&lt;h1 id=&#34;前回までのレイトレ合宿の参加レポート&#34;&gt;前回までのレイトレ合宿の参加レポート&lt;/h1&gt;

&lt;p&gt;ちなみに私は今年で4回目の参加になります。過去の参加レポートはこちらです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/09/25/rtcamp6-part2/&#34;&gt;レイトレ合宿6 参加報告 Part2（当日編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/09/18/rtcamp6-part1/&#34;&gt;レイトレ合宿6 参加報告 前編（準備編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/10/02/rtcamp5/&#34;&gt;レイトレ合宿5‽に参加して、Rustでパストレーシングを実装しました！ | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gam0022.hatenablog.com/entry/raytracingcamp4&#34;&gt;レイトレ合宿4!? に参加しました！ - gam0022のブログ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;redflash-renderer&#34;&gt;Redflash Renderer&lt;/h1&gt;

&lt;p&gt;Redflash というGPUレンダラーを開発しました。&lt;/p&gt;

&lt;p&gt;Redflash は NVIDIA® OptiX 6.0 上で実装したパストレーシングによる物理ベースレンダラーで、ポリゴンと &lt;strong&gt;レイマーチング&lt;/strong&gt; が混在したシーンを一貫した描画ができます。&lt;/p&gt;

&lt;p&gt;GitHubにソースコードを公開しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/redflash&#34;&gt;https://github.com/gam0022/redflash&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こちらはアーティファクトなしの想定のレンダリング結果です。レンダリングは30分です。クリックすると非圧縮形式の画像になります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/pr33_v6_t3000_s1030.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/pr33_v6_t3000_s1030_1920x1080.jpg&#34; alt=&#34;想定したレンダリング結果&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;別視点からのレンダリング結果も紹介します。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle1.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle1.jpg&#34; alt=&#34;別視点からのレンダリング結果1&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle2.jpg&#34; alt=&#34;別視点からのレンダリング結果2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle3.jpg&#34; alt=&#34;別視点からのレンダリング結果3&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;発表資料&#34;&gt;発表資料&lt;/h2&gt;

&lt;p&gt;自作レンダラーの紹介スライドです。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;ba3966aad908467e8b21249e828c26d0&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;レイトレ合宿の参加者にとっては常識だと思われる箇所の説明を省略してしまったので、ここから簡単に補足解説をします。&lt;/p&gt;

&lt;h2 id=&#34;neeとmisによるサンプリングの効率化&#34;&gt;NEEとMISによるサンプリングの効率化&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.003.jpeg&#34; alt=&#34;実装機能&#34; /&gt;&lt;/p&gt;

&lt;p&gt;この2つは「パストレーシングのサンプリングを効率化する」ための非常に有名なテクニックです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Next Event Estimation (Direct Light Sampling)&lt;/li&gt;
&lt;li&gt;Multiple Importance Sampling&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next Event EstimationはよくNEEと省略されて呼ばれます。
光源が小さいシーンでは、BSDFによる重点的サンプリングだけではなかなか光源にヒットしません。
そのため、短い計算時間ではノイズだらけの結果になってしまいます。
また、BSDFの分布と光源の方向が異なる場合、むしろBSDFによる重点的サンプリングによって悪化するケースもありえます。
そこで、光源の表面上の点を明示的にサンプリングして光転送経路を生成することで、効率的なサンプリングを行うテクニックがNEEです。&lt;/p&gt;

&lt;p&gt;Multiple Importance SamplingはよくMISと省略されて呼ばれます。
MISは複数のサンプリング戦略を組み合わせることでサンプリングの効率を向上するテクニックです。
具体的には「BSDFによる重点的サンプリング」と「NEEによるライトのサンプリング」の2つの戦略の結果を適切なウェイトで組み合わせることで、サンプリングの効率を向上します。
それぞれのサンプリング戦略が得意な部分だけウェイトを大きくすることで、分散を抑えて効率的にサンプリングができるようになります。
例えば、光源が大きくてroughnessが大きいような「BSDFによる重点的サンプリング」が得意なケースなら「BSDFによる重点的サンプリング」の重みを大きくして、
逆に光源が小さくてroughnessが小さいような「NEEによるライトのサンプリング」が得意なケースなら「NEEによるライトのサンプリング」の重みを大きくします。&lt;/p&gt;

&lt;p&gt;NEEやMISについては、レイトレ合宿の参加者でもある &lt;a href=&#34;https://twitter.com/Shocker_0x15&#34;&gt;@Shocker_0x15&lt;/a&gt; さんが日本語で詳しく記事を書かれています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rayspace.xyz/CG/contents/path_tracing/&#34;&gt;パストレーシング - Computer Graphics - memoRANDOM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rayspace.xyz/CG/contents/MIS/&#34;&gt;多重重点的サンプリング - Computer Graphics - memoRANDOM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;optixとレイマーチングの統合&#34;&gt;OptiXとレイマーチングの統合&lt;/h2&gt;

&lt;p&gt;OptiXには独自のプリミティブを定義する仕組みがあるため、OptiXとレイマーチングの統合はそこまで苦労しませんでした。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;IntersectionProgram&lt;/code&gt; と &lt;code&gt;BoundingBoxProgram&lt;/code&gt; としてレイマーチングによる交差判定とAABBの定義をCUDAで実装するだけでできました。&lt;/p&gt;

&lt;p&gt;詳細はレイトレ合宿アドベントカレンダーの記事で既に紹介しているので、気になる方は読んでみてください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/&#34;&gt;NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを実装した | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;衝突判定の高速化&#34;&gt;衝突判定の高速化&lt;/h2&gt;

&lt;p&gt;BVHの構築はOptiXが自動でやってくれるので、ポリゴンの衝突判定は特に高速化しませんでした。
なんとOptiX 6.0ではRTXに対応しているので、RTX 2070ではハードウェアをつかって高速化な衝突判定ができました！（が、本番環境はRTX非対応でした…）&lt;/p&gt;

&lt;p&gt;一方でレイマーチングの衝突判定については自力で行う必要がありました。
シーン全体を1個の距離関数で表現したため、BVHなどの構造では衝突判定の高速化が難しいためです。&lt;/p&gt;

&lt;h3 id=&#34;距離関数の軽量化&#34;&gt;距離関数の軽量化&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.008.jpeg&#34; alt=&#34;実装機能&#34; /&gt;&lt;/p&gt;

&lt;p&gt;レイマーチングでは1本をレイを飛ばすごとに数百回も距離関数を評価する必要があります（今回のレンダリング結果は300回）。&lt;/p&gt;

&lt;p&gt;レイマーチングの負荷は距離関数の複雑さに比例するので、距離関数の軽量化は効果が大きい最適化でした。&lt;/p&gt;

&lt;p&gt;今回はMandelboxという伝統的なフラクタル図形を距離関数として用いたのですが、
メジャーなMandelboxの実装では &lt;code&gt;sphereFold&lt;/code&gt; という操作で分岐があったりとGPUには高負荷なものでした。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sphereFold&lt;/code&gt; のどちらの分岐に入るかはMandelboxのパラメータによって決まるので、
一部のパラメータを削除したり、パラメータの範囲を狭めることで分岐を削除して処理を簡略化しました。&lt;/p&gt;

&lt;h3 id=&#34;レイマーチングの衝突判定の精度のlod&#34;&gt;レイマーチングの衝突判定の精度のLOD&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.009.jpeg&#34; alt=&#34;レイマーチングの衝突判定の精度のLOD 1/2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;まず速度面では、カメラに近い部分は細部まで正確に衝突判定をする必要がありますが、遠い部分は大雑把でも問題にならないため、LODが有効でした。&lt;/p&gt;

&lt;p&gt;品質面でもLODが必要でした。
Mandelboxの距離関数は厳密には Distance Estimator（距離推定器）と呼ばれるものです。
通常の距離関数は表面までの距離をぴったりと計算できるのに対して、
Distance Estimatorは有限のイテレーション回数では表面に漸近しても、距離0になりません。&lt;/p&gt;

&lt;p&gt;そのため、適当な距離 eps で衝突とみなして計算を打ち切る必要があります。
また、eps を小さくすると、より細かい detail まで可視化できるのですが、
遠景まで同じ eps で処理すると高周波成分が現れて、まるでMipMap OFFのような汚い結果となります。&lt;/p&gt;

&lt;p&gt;このようにレイマーチングの高速化と品質向上の2つの目的ために、衝突判定の精度のLODが必要でした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.010.jpeg&#34; alt=&#34;レイマーチングの衝突判定の精度のLOD 2/2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LODはカメラからの距離に応じて動的に eps を決定することで実現しました。&lt;/p&gt;

&lt;p&gt;レイマーチングではレイを漸近的に進めるため、レイが進んだ距離を必ず計算する必要があります。
このとき &lt;code&gt;レイが進んだ距離 = カメラからの距離&lt;/code&gt; となるため、eps は簡単に決定できます。&lt;/p&gt;

&lt;p&gt;具体的にはレイが進んだ距離に定数を乗算したものを eps として扱うようにしました。&lt;/p&gt;

&lt;p&gt;今回の提出シーンのように同じレイマーチングのオブジェクトの近影〜遠景がひとつのカットで混在していても、綺麗に描画できるようになりました。&lt;/p&gt;

&lt;p&gt;また、カメラを近づけると実質無限に細部が現れるようになりました（フラクタル図形の特徴）。&lt;/p&gt;

&lt;h3 id=&#34;1回のlaunchでなるべくたくさんサンプリングする戦略&#34;&gt;1回のlaunchでなるべくたくさんサンプリングする戦略&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.011.jpeg&#34; alt=&#34;1回のlaunchでなるべくたくさんサンプリングする戦略&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OptiXでパストレーシングを実装する場合、通常は1回のlaunchでパストレーシングの1サンプリングを行うように実装するかと思います。&lt;/p&gt;

&lt;p&gt;ところが、launchにも多少のオーバーヘッドがあるため、手元のPCで実験した結果では、
&lt;code&gt;sample_per_launch&lt;/code&gt; （1回のlaunchごとのサンプリング回数）を大きくすれば大きくするほど60秒あたりのサンプリング回数を増やすことができました。&lt;/p&gt;

&lt;p&gt;そこで、最初の4サンプリングでマシンの性能をベンチマークして時間切れにならない最大の sample_per_launch を決定するような戦略をとりました。&lt;/p&gt;

&lt;h2 id=&#34;deep-learning-denoising&#34;&gt;Deep Learning Denoising&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.012.jpeg&#34; alt=&#34;Deep Learning Denoising&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディープラーニングをつかったデノイザーの性能が驚異的に良くて驚きました。&lt;/p&gt;

&lt;p&gt;左が10spp（sample per pixel）の結果で、右がデノイズした結果です。&lt;/p&gt;

&lt;p&gt;かなり少ないサンプリング数でも非常に綺麗にデノイズができました。
特にLucy像の拡散面の部分などは効果が絶大でした。&lt;/p&gt;

&lt;p&gt;Deep Learning DenoisingはOptiXの標準機能を利用しただけなので、詳細については私は理解していません。&lt;/p&gt;

&lt;p&gt;レンダリング結果とnormalとalbedoのバッファを与えてやると、綺麗にデノイズした結果を出力してくれました。&lt;/p&gt;

&lt;p&gt;速度面でも優秀で4K解像度でも&lt;a href=&#34;https://github.com/gam0022/redflash/pull/34&#34;&gt;1.4秒程度&lt;/a&gt;でデノイズが完了しました。&lt;/p&gt;

&lt;p&gt;まだリアルタイムレンダリングには速度的には使いづらいかもしれませんが、これまでの Bilateral Filter や Non-local Means Filter を遥かに凌駕する性能なので、改めてレンダリング技術とディープラーニングの親和性の高さを実感しました。&lt;/p&gt;

&lt;p&gt;これからの時代はグラフィックエンジニアもディープラーニングも勉強しなくては！と思いました。&lt;/p&gt;

&lt;h3 id=&#34;rt-buffer-gpu-local-による最適化&#34;&gt;RT_BUFFER_GPU_LOCAL による最適化&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.013.jpeg&#34; alt=&#34;RT_BUFFER_GPU_LOCAL による最適化&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Deep Learning Denoising用にalbedoとnormalのバッファを生成したところ、合計で5枚もバッファが必要になりました。
バッファの読み書きもそれなりに重たい処理なので、対策を行いました。
createBuffer の第1引数に &lt;code&gt;RT_BUFFER_INPUT_OUTPUT&lt;/code&gt; を指定したところ、なんと13.6%くらい高速化しました。&lt;/p&gt;

&lt;p&gt;ディスプレイにバッファを同期するかのオプションのようでした。
ウィンドウにバッファを表示する場合はこのオプションをつけると描画結果が同期されなくなってしまいますが、
CUIモードで起動するときには同期は不要なので、このオプションを有効にすることで大幅に性能向上できました。&lt;/p&gt;

&lt;h1 id=&#34;反省-スケジュール面が厳しすぎた&#34;&gt;反省：スケジュール面が厳しすぎた&lt;/h1&gt;

&lt;p&gt;ここまでがレンダラーの紹介でした。ここからは振り返りを書こうと思います。&lt;/p&gt;

&lt;p&gt;最大の反省点はスケジュール面が厳しすぎたことでした…&lt;/p&gt;

&lt;p&gt;OptiXのキャッチアップを含めて約一ヶ月で開発したのですが、流石に無理なスケジュールだったと思います。&lt;/p&gt;

&lt;p&gt;8月は仕事のプロジェクトの追い込み時期とCEDECの登壇準備が重なって、なかなかレンダラー開発の時間を捻出できず、
睡眠時間と生活を削りすぎたため、体力的にも精神的にもかなり限界でした…&lt;/p&gt;

&lt;p&gt;そろそろ若さで無茶をカバーできない年齢になってきたので、締め切り直前になって慌てて開発するのではなく、
日頃から継続的にレンダラーを開発することが大事だろうと思います。&lt;/p&gt;

&lt;h1 id=&#34;余談-シーン作成はunity&#34;&gt;余談：シーン作成はUnity&lt;/h1&gt;

&lt;p&gt;時間がなくてシーン編集機能を実装できなかったので、
Unityで事前に距離関数のパラメータ調整や光源の配置を行ってシーンのイメージを固めてから、後からパラメータを自作レンダラーに移植しました。&lt;/p&gt;

&lt;p&gt;結果的には納得できるシーンを作成できたので、作戦は成功だったと思います。&lt;/p&gt;

&lt;p&gt;UnityのHDRPでレイマーチングを行うのには&lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;@kanetaaaaa&lt;/a&gt;さんの&lt;a href=&#34;https://github.com/kaneta1992/RaymarchingInHDRP/&#34;&gt;RaymarchingInHDRP&lt;/a&gt;を利用させていただきました。&lt;/p&gt;

&lt;p&gt;カッコいいシーンを大量に作れたので、ついスクリーンショットをたくさん撮影してしまいました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Unity HDRP + Raymarching by &lt;a href=&#34;https://twitter.com/kanetaaaaa?ref_src=twsrc%5Etfw&#34;&gt;@kanetaaaaa&lt;/a&gt; を試してみました！&lt;br&gt;カッコいいシーンが無限に作れてしまう😍&lt;br&gt;これは凄いです🙏&lt;a href=&#34;https://twitter.com/hashtag/unity3d?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#unity3d&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/raymarching?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#raymarching&lt;/a&gt;&lt;a href=&#34;https://t.co/EK6JsHpTBZ&#34;&gt;https://t.co/EK6JsHpTBZ&lt;/a&gt; &lt;a href=&#34;https://t.co/ZueP2hfzet&#34;&gt;pic.twitter.com/ZueP2hfzet&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1163876089489285120?ref_src=twsrc%5Etfw&#34;&gt;August 20, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;今後やりたいこと&#34;&gt;今後やりたいこと&lt;/h1&gt;

&lt;h2 id=&#34;シーン編集機能がほしい&#34;&gt;シーン編集機能がほしい&lt;/h2&gt;

&lt;p&gt;現状はGUIでカメラ操作だけができます。&lt;/p&gt;

&lt;p&gt;シーン編集に関して、上で紹介したようなUnityからパラメータを移植する方法だと最終的なルックの確認のイテレーションの高速化がしずらいので、
Redflash自体にシーン編集機能を実装したいと思っています。&lt;/p&gt;

&lt;p&gt;距離関数を定義したCUDAファイルのホットリロード機能を実装したり、 CallableProgramをつかって距離関数を差し替え可能にしたいです。&lt;/p&gt;

&lt;p&gt;他にも距離関数やマテリアルのパラメータをインスペクタで編集するなどは最低限欲しいなと思っています。&lt;/p&gt;

&lt;p&gt;あとはオブジェクトの配置などをマニピュレーターでできるようにしたいですが、どうしても実装工数がかかるので、どういう感じが良いのか思案しているところです。
DCCツールから直接シーンを出力する形式だと、距離関数の扱いに困るため、なかなか難しい問題です。&lt;/p&gt;

&lt;h2 id=&#34;リファクタリング&#34;&gt;リファクタリング&lt;/h2&gt;

&lt;p&gt;CallableProgramでBSDFを入れ替えられるようにしたり、ファイルを適切に分割したりして、もう少しコードをリファクタリングしたいです。&lt;/p&gt;

&lt;h2 id=&#34;pngのエンコード時間の短縮&#34;&gt;PNGのエンコード時間の短縮&lt;/h2&gt;

&lt;p&gt;PNGの保存には &lt;a href=&#34;https://github.com/nothings/stb/blob/master/stb_image.h&#34;&gt;stb_image&lt;/a&gt; を使わせていただきました。&lt;/p&gt;

&lt;p&gt;ただし、4K解像度となるとPNGの保存に1.7秒前後の時間が必要でした。&lt;/p&gt;

&lt;p&gt;制限時間が短くなると、PNGの保存やGPUの初期化に要する時間が相対的に増えて、レンダリングに使える時間がどんどん短くなってしまいます。&lt;/p&gt;

&lt;p&gt;そのため、PNGの保存やGPU初期化の高速化は、来年以降のレイトレ合宿では重要な課題になるだろうと予想しています。&lt;/p&gt;

&lt;h2 id=&#34;複数gpu対応&#34;&gt;複数GPU対応&lt;/h2&gt;

&lt;p&gt;OptiXをつかっても複数のGPUをうまく使ってくれなかったので、独自の仕組みで対応が必要のようでした。&lt;/p&gt;

&lt;p&gt;単純な解決策として、プロセスを複数起動して最後にレンダリング結果をマージする方法が考えられますが、ちゃんと検証をしたいです。&lt;/p&gt;

&lt;h2 id=&#34;フルスクラッチgpuレンダラー&#34;&gt;フルスクラッチGPUレンダラー&lt;/h2&gt;

&lt;p&gt;去年まではGPUインスタンス勢は1人だけだったのですが、今年は7人（レンダラーが動かなかった人も含む）もいました。&lt;/p&gt;

&lt;p&gt;GPU勢にも、私のようにOptiXなどのレイトレーシング用のフレームワークを使う勢と、フルスクラッチ実装勢で別れていました。&lt;/p&gt;

&lt;p&gt;フルスクラッチ勢からは「OptiXでは作法がきっちり決められているのがなんとなく嫌だった」「GPU向けのBVH実装をしてみたかった」といった意見を聞きました。&lt;/p&gt;

&lt;p&gt;たしかにRTXなどの登場によって交差判定がハードウェアに移りつつある今だからこそ、勉強する価値はあるのかもしれません。&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;今年は忙しいからレイトレ合宿に参加できるか怪しいと思っていましたが、なんとかちゃんとレンダラーを提出できて良かったです。&lt;/p&gt;

&lt;p&gt;思えば「レイマーチングとポリゴンが混在したシーンをパストレーシングしたい」というのは3年前のレイトレ合宿4のときに本当は実現したいテーマでした。&lt;/p&gt;

&lt;p&gt;当時はレイトレ初心者だったので、ナイーブなパストレーシングで精一杯で高速化方法が分からず、
普通にレイマーチングを組み合わせたら激重になってしまい、5時間くらいかけないとまともな絵が出ない状態でした。
結局、パストレーシングを諦めて疑似手法でAOやシャドウを計算してなんとか見れる絵を提出しました…&lt;/p&gt;

&lt;p&gt;3年間で学んだ知識でようやくやりたいことを実現できて本当に良かったです。過去の自分に勝利できました。&lt;/p&gt;

&lt;p&gt;レイトレ合宿は自身の成長や糧となる機会を与えてくれる、とても良い合宿勉強会だなと改めて感じました。&lt;/p&gt;

&lt;p&gt;レイトレ合宿を毎年主催してくださっている&lt;a href=&#34;https://twitter.com/q_cinnamon&#34;&gt;q&lt;/a&gt;さんと&lt;a href=&#34;https://twitter.com/h013&#34;&gt;hole&lt;/a&gt;さん、その他の参加者のみなさん、本当にありがとうございました！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを実装した</title>
      <link>https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/</link>
      <pubDate>Mon, 05 Aug 2019 12:10:23 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;https://sites.google.com/site/raytracingcamp7/&#34;&gt;レイトレ合宿7&lt;/a&gt;アドベントカレンダーの記事です。&lt;/p&gt;

&lt;p&gt;NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを開発しました。&lt;/p&gt;

&lt;p&gt;レイとオブジェクトの交差判定をレイマーチングで行い、ライティングをパストレーシングをするという、レイマーチングとパストレーシングのハイブリッドなレンダリングを実現しました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;NVIDIA® OptiX上で&lt;br&gt;『レイマーチング×パストレーシング』&lt;br&gt;を実装できた😉 &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt; &lt;a href=&#34;https://t.co/FKbuHiXqmP&#34;&gt;pic.twitter.com/FKbuHiXqmP&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1155489034354843649?ref_src=twsrc%5Etfw&#34;&gt;July 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;実装の方針&#34;&gt;実装の方針&lt;/h1&gt;

&lt;p&gt;Optixは、CUDA基盤上で動作する、NVIDIA製のGPUレイトレーシング用フレームワークです。&lt;/p&gt;

&lt;p&gt;Optixではユーザ独自のプリミティブを定義できるため、この機能をつかってレイマーチングで衝突判定を行う距離関数のプリミティブを定義しました。&lt;/p&gt;

&lt;p&gt;独自のプリミティブの定義に必要なProgram（Optix用語でPTXアセンブリにコンパイルされたCUDA C関数を指す）は次の2つです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bounding Box&lt;/li&gt;
&lt;li&gt;Intersection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Optixの公式サンプルプロジェクトに optixPathtracing（パストレーシングの実装例）があったので、これにレイマーチングのプリミティブを追加する形で実装しました。&lt;/p&gt;

&lt;p&gt;パストレーシングの処理はサンプルコードの実装そのまま利用させていただきました。&lt;/p&gt;

&lt;h2 id=&#34;bounding-box&#34;&gt;Bounding Box&lt;/h2&gt;

&lt;p&gt;Bounding Boxを定義するProgramです。&lt;/p&gt;

&lt;p&gt;レイマーチングのオブジェクトのBounding BoxはC++側から値を渡すようにしました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;rtDeclareVariable&lt;/code&gt; でCPUからGPUへ送るバッファの宣言（GLSLのunifromと同じ）ができます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;optix_world.h&amp;gt;

rtDeclareVariable(float3, center, , );
rtDeclareVariable(float3, size, , );

RT_PROGRAM void bounds(int, float result[6])
{
    optix::Aabb* aabb = (optix::Aabb*)result;
    aabb-&amp;gt;m_min = center - size;
    aabb-&amp;gt;m_max = center + size;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;intersection&#34;&gt;Intersection&lt;/h2&gt;

&lt;p&gt;衝突判定をするProgramです。&lt;/p&gt;

&lt;p&gt;ごくごく普通のレイマーチングです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;rtDeclareVariable(int, lgt_instance, , ) = {0};
rtDeclareVariable(float3, texcoord, attribute texcoord, );
rtDeclareVariable(int, lgt_idx, attribute lgt_idx, );

RT_PROGRAM void intersect(int primIdx)
{
    const float EPS = 1e-2;
    float t = 0.0, d = 1e100;
    float3 p = ray.origin;

    for (int i = 0; i &amp;lt; 50; i++)
    {
        d = map(p);
        t += d;
        p = ray.origin + t * ray.direction;
        if (abs(d) &amp;lt; EPS)
        {
            break;
        }
    }

    if (abs(d) &amp;lt; EPS &amp;amp;&amp;amp; rtPotentialIntersection(t))
    {
        shading_normal = geometric_normal = calcNormal(p, map);
        texcoord = make_float3(p.x, p.y, 0);
        lgt_idx = lgt_instance;
        rtReportIntersection(0);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;法線計算&#34;&gt;法線計算&lt;/h3&gt;

&lt;p&gt;法線計算は四面体によるアプローチを用いました。&lt;/p&gt;

&lt;p&gt;通常は6回の距離関数の評価が必要なところ、4回の評価だけで法線を計算できます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://iquilezles.org/www/articles/normalsSDF/normalsSDF.htm&#34;&gt;normals for an SDF | http://iquilezles.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://setchi.hatenablog.com/entry/2018/12/17/095532&#34;&gt;#TokyoDemoFest 2018 の GLSL Graphics Compo で2位入賞しました - setchi’s blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;map関数を差し替え可能にするためにマクロをつかって実装しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;const float EPS_N = 1e-4;
#define calcNormal(p, dFunc) normalize(\
    make_float3( EPS_N, -EPS_N, -EPS_N) * dFunc(p + make_float3( EPS_N, -EPS_N, -EPS_N)) + \
    make_float3(-EPS_N, -EPS_N,  EPS_N) * dFunc(p + make_float3(-EPS_N, -EPS_N,  EPS_N)) + \
    make_float3(-EPS_N,  EPS_N, -EPS_N) * dFunc(p + make_float3(-EPS_N,  EPS_N, -EPS_N)) + \
    make_float3( EPS_N,  EPS_N,  EPS_N) * dFunc(p + make_float3( EPS_N,  EPS_N,  EPS_N)))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;距離関数&#34;&gt;距離関数&lt;/h3&gt;

&lt;p&gt;以前にブログで紹介したIFSによるMengerSpongeの距離関数をCUDA Cに移植しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/06/25/unity-raymarching/&#34;&gt;Unity×レイマーチングによる映像制作の実践手法 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Swizzle Operationを手動展開するのがしんどかったです…&lt;/p&gt;

&lt;p&gt;ベクトル版のabsやmaxは自分で定義すれば解決しますが、Swizzle OperationをCUDA C上で再現する方法は私には分かりませんでした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;CUDA C言語、absやmaxにベクトル型のオーバーロードが無いし、Swizzle Operationも無いからストレスで発狂して精神が崩壊した🤬🤪🤮 &lt;a href=&#34;https://t.co/mRPmQTTcsb&#34;&gt;pic.twitter.com/mRPmQTTcsb&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1155465784807657472?ref_src=twsrc%5Etfw&#34;&gt;July 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float dMenger(float3 z0, float3 offset, float scale) {
    float4 z = make_float4(z0, 1.0);
    for (int n = 0; n &amp;lt; 4; n++) {
        // z = abs(z);
        z.x = abs(z.x);
        z.y = abs(z.y);
        z.z = abs(z.z);
        z.w = abs(z.w);

        // if (z.x &amp;lt; z.y) z.xy = z.yx;
        if (z.x &amp;lt; z.y)
        {
            float x = z.x;
            z.x = z.y;
            z.y = x;
        }

        // if (z.x &amp;lt; z.z) z.xz = z.zx;
        if (z.x &amp;lt; z.z)
        {
            float x = z.x;
            z.x = z.z;
            z.z = x;
        }

        // if (z.y &amp;lt; z.z) z.yz = z.zy;
        if (z.y &amp;lt; z.z)
        {
            float y = z.y;
            z.y = z.z;
            z.z = y;
        }

        z *= scale;
        // z.xyz -= offset * (scale - 1.0);
        z.x -= offset.x * (scale - 1.0);
        z.y -= offset.y * (scale - 1.0);
        z.z -= offset.z * (scale - 1.0);

        if (z.z &amp;lt; -0.5 * offset.z * (scale - 1.0))
            z.z += offset.z * (scale - 1.0);
    }
    // return (length(max(abs(z.xyz) - make_float3(1.0, 1.0, 1.0), 0.0)) - 0.05) / z.w;
    return (length(make_float3(max(abs(z.x) - 1.0, 0.0), max(abs(z.y) - 1.0, 0.0), max(abs(z.z) - 1.0, 0.0))) - 0.05) / z.w;
}

float map(float3 p)
{
    float scale = 100;
    return dMenger((p - center) / scale, make_float3(1, 1, 1), 3.1) * scale;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;c-からprogramの利用&#34;&gt;C++からProgramの利用&lt;/h2&gt;

&lt;p&gt;Programを利用するには以下のようなC++のコードを書けばOKです。&lt;/p&gt;

&lt;p&gt;ProgramとGPUに送る情報のバッファを指定しているだけです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;Context        context = 0;
Program        pgram_raymarching_intersection = 0;
Program        pgram_raymarching_bounding_box = 0;

// レイマーチングのオブジェクトの GeometryInstance を生成します
GeometryInstance createRaymrachingObject(
    const float3&amp;amp; center,
    const float3&amp;amp; size)
{
    Geometry raymarching = context-&amp;gt;createGeometry();
    raymarching-&amp;gt;setPrimitiveCount(1u);
    raymarching-&amp;gt;setIntersectionProgram(pgram_raymarching_intersection);
    raymarching-&amp;gt;setBoundingBoxProgram(pgram_raymarching_bounding_box);

    raymarching[&amp;quot;center&amp;quot;]-&amp;gt;setFloat(center);
    raymarching[&amp;quot;size&amp;quot;]-&amp;gt;setFloat(size);

    GeometryInstance gi = context-&amp;gt;createGeometryInstance();
    gi-&amp;gt;setGeometry(raymarching);
    return gi;
}

// ジオメトリのセットアップをします
// ※レイマーチングに直接関係ないコードは省略しています
void loadGeometry()
{
    // Set up Raymarching programs
    const char *ptx = sutil::getPtxString( SAMPLE_NAME, &amp;quot;optixRaymarching.cu&amp;quot; );
    pgram_raymarching_bounding_box = context-&amp;gt;createProgramFromPTXString( ptx, &amp;quot;bounds&amp;quot; );
    pgram_raymarching_intersection = context-&amp;gt;createProgramFromPTXString( ptx, &amp;quot;intersect&amp;quot; );

    // create geometry instances
    std::vector&amp;lt;GeometryInstance&amp;gt; gis;

    // Raymarcing
    gis.push_back(createRaymrachingObject(
        make_float3(278.0f, 120.0f, 278.0f),
        make_float3(100.0f, 100.0f, 100.0f)));
    setMaterial(gis.back(), diffuse, &amp;quot;diffuse_color&amp;quot;, white);

    // Create geometry group
    GeometryGroup geometry_group = context-&amp;gt;createGeometryGroup(gis.begin(), gis.end());
    geometry_group-&amp;gt;setAcceleration( context-&amp;gt;createAcceleration( &amp;quot;Trbvh&amp;quot; ) );
    context[&amp;quot;top_object&amp;quot;]-&amp;gt;set( geometry_group );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;optixの環境構築-windows&#34;&gt;Optixの環境構築（Windows）&lt;/h1&gt;

&lt;p&gt;OptixのWindows用の環境構築の流れは&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;必要なツールを事前にインストール&lt;/li&gt;
&lt;li&gt;CamkeでVisualStudioのソリューションファイルを生成&lt;/li&gt;
&lt;li&gt;VisualStudioでビルド&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;という感じでした。&lt;/p&gt;

&lt;p&gt;morishigeさんのQiitaの記事が大変参考になりました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/morishige/items/d4a99c88b925ac31ff3d&#34;&gt;Nvidia OptiX 入門（環境構築編）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CmakeとOptixとCUDAのバージョンの組み合わせが肝のようで、Cmakeのバージョンを変えながら何回かトライしたところ、この組み合わせでCmakeビルドに成功しました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;✍️ &lt;br&gt;CUDA 10.1&lt;br&gt;OptiX SDK 6.0.0&lt;br&gt;Visual Studio 2017&lt;br&gt;Cmake 3.8.2&lt;br&gt;&lt;br&gt;freeglut / GLFW / GLEW は Nuget の最新版をインストール&lt;a href=&#34;https://t.co/OtsR6bnxmk&#34;&gt;https://t.co/OtsR6bnxmk&lt;/a&gt;&lt;br&gt;&lt;br&gt;Cmakeの設定はスクショ通り &lt;a href=&#34;https://t.co/cpBM4y2Vy1&#34;&gt;pic.twitter.com/cpBM4y2Vy1&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1150906026528391168?ref_src=twsrc%5Etfw&#34;&gt;July 15, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;CmakeでVisual Studioのバージョンを選択する際、誤って64bit版ではなく32bit版を選択してしまい、Cmake自体は成功するもののソリューションがビルドできないことがありました。&lt;/p&gt;

&lt;p&gt;Cmakeの過去のバージョンはGitHubからインストールできます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Kitware/CMake/releases&#34;&gt;Releases · Kitware/CMake&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;サンプルコードの改造&#34;&gt;サンプルコードの改造&lt;/h2&gt;

&lt;p&gt;サンプルコードの改造方法はNVIDIA Developer Forumsにあります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://devtalk.nvidia.com/default/topic/1049151/optix/how-can-i-modify-a-simple-example-/&#34;&gt;How can I modify a simple example? - NVIDIA Developer Forums&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Adding a new example is very simple:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Copy one of the optixIntro_01 (this is effectively optixHello) to optixIntro_10 folders,&lt;/li&gt;
&lt;li&gt;rename it,&lt;/li&gt;
&lt;li&gt;rename the project name in its copied CMakeLists.txt,&lt;/li&gt;
&lt;li&gt;add your new subdirectory in the CMakeLists.txt one folder above,&lt;/li&gt;
&lt;li&gt;rebuild the solution with CMake GUI. Done.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Your new project appears and would do the same thing as the example you copied it from.
Now change it as you like.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;参考資料&#34;&gt;参考資料&lt;/h1&gt;

&lt;p&gt;以下の記事が大変参考になりました。ありがとうございます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://memo.render.jp/optix&#34;&gt;optix - uimac実装メモ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/gameworks/content/gameworkslibrary/optix/optix_quickstart.htm&#34;&gt;OptiX QuickStart（公式チュートリアル）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>[Unity] Y軸ビルボードシェーダーの実装と解説</title>
      <link>https://gam0022.net/blog/2019/07/23/unity-y-axis-billboard-shader/</link>
      <pubDate>Tue, 23 Jul 2019 09:30:09 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/07/23/unity-y-axis-billboard-shader/</guid>
      <description>&lt;h1 id=&#34;改訂版の記事を書きました-2021-12-23&#34;&gt;改訂版の記事を書きました（2021-12-23）&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;この記事の方法は古いので、改訂版を参考にしてください。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2021/12/23/unity-urp-billboard-shader/&#34;&gt;[Unity][URP] Y軸ビルボードシェーダー | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;こんな感じのY軸のビルボードをC#スクリプトを使わずに、シェーダーだけで実装しました（Unity 2018.3.12f1）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-07-22-unity-y-axis-billboard-shader/billboard_y_axis.gif&#34; alt=&#34;Y軸ビルボード&#34; /&gt;&lt;/p&gt;

&lt;p&gt;GitHubリポジトリ: &lt;a href=&#34;https://github.com/gam0022/unity-legacy-render-pipeline-experiments/blob/master/Assets/Experiments/Billboard/Billboard.shader#L51-L82&#34;&gt;gam0022/unity-legacy-render-pipeline-experiments/blob/master/Assets/Experiments/Billboard&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;この記事の要約&#34;&gt;この記事の要約&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;頂点シェーダーでView行列の回転（カメラに応じた回転）をスキップすれば、ビルボードができる&lt;/li&gt;
&lt;li&gt;Unityは左手系座標だが、 &lt;strong&gt;View空間では右手系座標&lt;/strong&gt; なので、View変換をスキップするときには自前でZの符号を反転する必要がある&lt;/li&gt;
&lt;li&gt;Y軸のビルボードが必要なら、View行列から回転行列のY軸成分のみを抽出した行列を作れば良い&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;シェーダーで実装するメリット&#34;&gt;シェーダーで実装するメリット&lt;/h1&gt;

&lt;p&gt;シェーダーでビルボードを計算するメリットはたくさんあります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VRChatなどユーザのC#スクリプトが使えない環境でも動作する&lt;/li&gt;
&lt;li&gt;シーンビュー上でも動作する&lt;/li&gt;
&lt;li&gt;GPU（頂点シェーダー）でビルボード計算ができる

&lt;ul&gt;
&lt;li&gt;ビルボード計算のためのCPU負荷が全くかからない&lt;/li&gt;
&lt;li&gt;板ポリの頂点数は4なので、頂点シェーダーで多少重い処理をしても、GPU負荷への影響はわずか&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;シェーダーのコード-全体&#34;&gt;シェーダーのコード（全体）&lt;/h1&gt;

&lt;p&gt;最終的なシェーダーのコードはこちらです。&lt;/p&gt;

&lt;p&gt;単体で動作しますので、コピペしてお使いいただけます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Unity Y-Axis Billboard Shader by @gam0022
// https://gam0022.net/blog/2019/07/23/unity-y-axis-billboard-shader/
Shader &amp;quot;Unlit/Billboard&amp;quot;
{
    Properties
    {
        _MainTex (&amp;quot;Texture&amp;quot;, 2D) = &amp;quot;white&amp;quot; {}
        [KeywordEnum(OFF, ALL_AXIS, Y_AXIS)] _BILLBOARD(&amp;quot;Billboard Mode&amp;quot;, Float) = 2
        _Cutoff (&amp;quot;Alpha Cutoff&amp;quot;, Range(0, 1)) = 0.5
    }
    SubShader
    {
        Tags{ &amp;quot;Queue&amp;quot; = &amp;quot;AlphaTest&amp;quot; &amp;quot;RenderType&amp;quot; = &amp;quot;TransparentCutout&amp;quot;
                &amp;quot;IgnoreProjector&amp;quot; = &amp;quot;True&amp;quot; &amp;quot;DisableBatching&amp;quot; = &amp;quot;True&amp;quot; }

        Pass
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            // make fog work
            #pragma multi_compile_fog

            #include &amp;quot;UnityCG.cginc&amp;quot;
            #pragma multi_compile _BILLBOARD_OFF _BILLBOARD_ALL_AXIS _BILLBOARD_Y_AXIS

            struct appdata
            {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct v2f
            {
                float2 uv : TEXCOORD0;
                UNITY_FOG_COORDS(1)
                float4 vertex : SV_POSITION;
            };

            sampler2D _MainTex;
            float4 _MainTex_ST;
            
            float _Cutoff;

            v2f vert (appdata v)
            {
                v2f o;

                #if _BILLBOARD_OFF
                {
                    // ビルボードなしの通常の座標変換
                    o.vertex = UnityObjectToClipPos(v.vertex);
                }
                #elif _BILLBOARD_ALL_AXIS
                {                   
                    // Meshの原点をModelView変換
                    float3 viewPos = UnityObjectToViewPos(float3(0, 0, 0));
                    
                    // スケールと回転（平行移動なし）だけModel変換して、View変換はスキップ
                    float3 scaleRotatePos = mul((float3x3)unity_ObjectToWorld, v.vertex);
                    
                    // scaleRotatePosを右手系に変換して、viewPosに加算
                    // 本来はView変換で暗黙的にZが反転されているので、
                    // View変換をスキップする場合は明示的にZを反転する必要がある
                    viewPos += float3(scaleRotatePos.xy, -scaleRotatePos.z);
                    
                    o.vertex = mul(UNITY_MATRIX_P, float4(viewPos, 1));
                }
                #elif _BILLBOARD_Y_AXIS
                {
                    // Meshの原点をModelView変換
                    float3 viewPos = UnityObjectToViewPos(float3(0, 0, 0));
                    
                    // スケールと回転（平行移動なし）だけModel変換して、View変換はスキップ
                    float3 scaleRotatePos = mul((float3x3)unity_ObjectToWorld, v.vertex);                
                    
                    // View行列から回転行列のY軸成分のみを抽出
                    float3x3 ViewRotateY = float3x3(
                        1, UNITY_MATRIX_V._m01, 0,
                        0, UNITY_MATRIX_V._m11, 0,
                        0, UNITY_MATRIX_V._m21, -1// Zの符号を反転して右手系に変換
                    );
                    viewPos += mul(ViewRotateY, scaleRotatePos);
                    
                    o.vertex = mul(UNITY_MATRIX_P, float4(viewPos, 1));
                }
                #endif

                o.uv = TRANSFORM_TEX(v.uv, _MainTex);
                UNITY_TRANSFER_FOG(o,o.vertex);
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                // sample the texture
                fixed4 col = tex2D(_MainTex, i.uv);
                clip(col.a - _Cutoff);
                
                // apply fog
                UNITY_APPLY_FOG(i.fogCoord, col);
                return col;
            }
            ENDCG
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!--more--&gt;

&lt;h2 id=&#34;ビルボードのモードについて&#34;&gt;ビルボードのモードについて&lt;/h2&gt;

&lt;p&gt;このようにビルボードのモードをインスペクタで選択できます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-07-22-unity-y-axis-billboard-shader/shader_inspector.png&#34; alt=&#34;シェーダーのインスペクタ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;それぞれの結果を並べました。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;OFF: ビルボードなし&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;ALL_AXIS: 通常のビルボード&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Y_AXIS: Y軸のビルボード&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-07-22-unity-y-axis-billboard-shader/billboard_off.gif&#34; alt=&#34;ビルボードなし&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-07-22-unity-y-axis-billboard-shader/billboard_all_axis.gif&#34; alt=&#34;ビルボードあり&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-07-22-unity-y-axis-billboard-shader/billboard_y_axis.gif&#34; alt=&#34;Y軸ビルボード&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;通常の描画&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;上から見たときの違和感が大きい&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;上から見たときの違和感を緩和できる&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;コードの解説&#34;&gt;コードの解説&lt;/h1&gt;

&lt;p&gt;ここから、本題であるシェーダーの解説を行います。&lt;/p&gt;

&lt;h2 id=&#34;通常のビルボード&#34;&gt;通常のビルボード&lt;/h2&gt;

&lt;p&gt;通常のビルボードの頂点シェーダーの処理を抜粋しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#elif _BILLBOARD_ALL_AXIS
{                   
    // ①Meshの原点をModelView変換
    float3 viewPos = UnityObjectToViewPos(float3(0, 0, 0));
    
    // ②スケールと回転（平行移動なし）だけModel変換して、View変換はスキップ
    float3 scaleRotatePos = mul((float3x3)unity_ObjectToWorld, v.vertex);
    
    // ③scaleRotatePosを右手系に変換して、viewPosに加算
    // 本来はView変換で暗黙的にZが反転されているので、
    // View変換をスキップする場合は明示的にZを反転する必要がある
    viewPos += float3(scaleRotatePos.xy, -scaleRotatePos.z);
    
    // ④最後にプロジェクション変換
    o.vertex = mul(UNITY_MATRIX_P, float4(viewPos, 1));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;①について&#34;&gt;①について&lt;/h3&gt;

&lt;p&gt;記事の冒頭で&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;1.頂点シェーダーでView行列の回転（カメラに応じた回転）をスキップすれば、ビルボードができる&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;と書きましたが、厳密にはMeshの原点だけはView変換を行います。&lt;/p&gt;

&lt;p&gt;原点は回転の影響を受けないので、普通にModelView変換することで平行移動のみ適応できます。&lt;/p&gt;

&lt;h3 id=&#34;②について&#34;&gt;②について&lt;/h3&gt;

&lt;p&gt;Model行列よる平行移動は①で処理しているので、スケールと回転だけを各頂点に適応します。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;(float3x3)unity_ObjectToWorld&lt;/code&gt; のように &lt;code&gt;float3x3&lt;/code&gt; でキャストすることで、平行移動の行列の成分を捨てることができます。&lt;/p&gt;

&lt;p&gt;列ベクトルの場合は4行目に平行移動の情報が入っていますが、キャストによって4列目の成分が消えるため、平行移動の成分が消えます。&lt;/p&gt;

&lt;h3 id=&#34;③について&#34;&gt;③について&lt;/h3&gt;

&lt;p&gt;①で&lt;code&gt;viewPos&lt;/code&gt; には原点のView空間の座標を代入しましたが、これに②で生成した各頂点の座標を加算しています。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;float3(scaleRotatePos.xy, -scaleRotatePos.z)&lt;/code&gt; のようにZ成分だけ符号を反転しているのは、冒頭の&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2.Unityは左手系座標だが、 &lt;strong&gt;View空間では右手系座標&lt;/strong&gt; なので、View変換をスキップするときには自前でZの符号を反転する必要がある&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;という理由によるものです。&lt;/p&gt;

&lt;p&gt;左手系座標ではZ軸とカメラのforwardベクトルが同じ向きですが、右手系座標では反対向きになります。&lt;/p&gt;

&lt;p&gt;私はこのUnityの仕様を知らずに、かなり悩んでしまいました…&lt;/p&gt;

&lt;p&gt;私がネットで見つけたUnityのビルボードのシェーダーの実装のほとんどはZを反転する処理が抜けていました。
そのため、Box等の厚みのあるMeshに用いると、Cullingが反転して背面ポリゴンが描画される不具合がありました。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Z反転なし&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Z反転あり&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-07-22-unity-y-axis-billboard-shader/z_reverse_off.png&#34; alt=&#34;Z反転なし&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-07-22-unity-y-axis-billboard-shader/z_reverse_on.png&#34; alt=&#34;Z反転あり&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;NG: Cullingが反転して背面ポリゴンが描画されている&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;OK: 正常に表面ポリゴンが描画されている&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;④について&#34;&gt;④について&lt;/h3&gt;

&lt;p&gt;View座標にプロジェクション行列を乗算すると、最終的なクリッピング座標を計算できます（定形処理）。&lt;/p&gt;

&lt;h2 id=&#34;y軸のビルボード&#34;&gt;Y軸のビルボード&lt;/h2&gt;

&lt;p&gt;Y軸のビルボードの頂点シェーダーの処理を抜粋しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#elif _BILLBOARD_Y_AXIS
{
    // ①Meshの原点をModelView変換
    float3 viewPos = UnityObjectToViewPos(float3(0, 0, 0));
    
    // ②スケールと回転（平行移動なし）だけModel変換して、View変換はスキップ
    float3 scaleRotatePos = mul((float3x3)unity_ObjectToWorld, v.vertex);                
    
    // ③View行列からY軸の回転だけ抽出した行列を生成
    float3x3 ViewRotateY = float3x3(
        1, UNITY_MATRIX_V._m01, 0,
        0, UNITY_MATRIX_V._m11, 0,
        0, UNITY_MATRIX_V._m21, -1// Zの符号を反転して右手系に変換
    );
    viewPos += mul(ViewRotateY, scaleRotatePos);
    
    // ④最後にプロジェクション変換
    o.vertex = mul(UNITY_MATRIX_P, float4(viewPos, 1));
}
#endif
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;①②④について&#34;&gt;①②④について&lt;/h3&gt;

&lt;p&gt;①②④については、通常のビルボードと全く同じ処理なので、説明を割愛します。&lt;/p&gt;

&lt;h3 id=&#34;③について-1&#34;&gt;③について&lt;/h3&gt;

&lt;p&gt;③の &lt;code&gt;ViewRotateY&lt;/code&gt; は冒頭で説明したこの行列です。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;3.Y軸のビルボードが必要なら、View行列から回転行列のY軸成分のみを抽出した行列を作れば良い&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;View行列から回転行列のY軸成分だけ抽出して、X軸とZ軸は変換しないようにしています。&lt;/p&gt;

&lt;p&gt;通常のビルボードと同様に、View空間では右手系座標とするために、3行3列目には -1 を指定しています。&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;ビルボードくらいサクッと実装できると思いきや、View空間が右手系座標になっているとは夢にも思わず、すこし苦戦しました。&lt;/p&gt;

&lt;p&gt;そこで動作原理を解説した日本語の記事を探したものの、ほとんど見当たらなかったため、今回筆を執った次第です。&lt;/p&gt;

&lt;p&gt;なるべく丁寧に解説したつもりでしたが、分かりにくい点や間違いがあればコメントやTwitterで教えてください。&lt;/p&gt;

&lt;p&gt;ちなみに今回の方法だとドローコールバッチングができないため、次回はドローコールを減らす解決策を紹介するかもしれません。&lt;/p&gt;

&lt;h1 id=&#34;参考資料&#34;&gt;参考資料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Unity公式リファレンス

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual//SL-BuiltinFunctions.html&#34;&gt;ビルトインシェーダーヘルパー機能&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/SL-UnityShaderVariables.html&#34;&gt;ビルトインのシェーダー変数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/ScriptReference/Camera-worldToCameraMatrix.html&#34;&gt;Camera.worldToCameraMatrix&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;ポイント: Note that camera space matches OpenGL convention: camera&amp;rsquo;s forward is the negative Z axis. This is different from Unity&amp;rsquo;s convention, where forward is the positive Z axis.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://edom18.hateblo.jp/entry/2019/01/04/153205&#34;&gt;Unityの行列の扱いとベクトルのオーダー周りについてまとめておく&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;ポイント: UnityのC#は「列オーダー」。でもシェーダは「行オーダー」&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://logicalbeat.jp/blog/929/&#34;&gt;【Unity】【数学】Unityでのビュー＆プロジェクション行列とプラットフォームの関係&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;ポイント: UnityのScene上は左手座標系が原則だが、シェーダ内の行列（UNITY_MATRIX_V）では右手座標系になっているという情報がある。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://marupeke296.com/DXG_No72_ViewProjInfo.html&#34;&gt;その72 ビュー・射影変換行列が持つ情報を抜き出そう&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Model行列・View行列・Projection行列の各成分が何だったか忘れたときに参考になります&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;既存のビルボードのシェーダー実装

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/kaiware007/8ebad2d28638ff83b6b74970a4f70c9a#file-billboard-shader-L47-L50&#34;&gt;Simple Billboard shader for Unity&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;NOTE: Cullingの不具合あり&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/Unity3D/comments/ahqbod/a_billboard_sprite_shader_in_only_one_axis/eeieb6q/&#34;&gt;A billboard sprite shader in only one axis&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;NOTE: 逆行列（転置行列）でViewのXZの回転を打ち消すアプローチなので、計算に無駄がある&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;利用したテクスチャ素材

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pngall.com/tree-png/download/23754&#34;&gt;Tree PNG Clipart Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.deviantart.com/fabooguy/art/Dirt-Ground-Texture-Tileable-2048x2048-441212191&#34;&gt;Dirt/Ground Texture [Tileable | 2048x2048]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Unity×レイマーチングによる映像制作の実践手法</title>
      <link>https://gam0022.net/blog/2019/06/25/unity-raymarching/</link>
      <pubDate>Tue, 25 Jun 2019 09:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/06/25/unity-raymarching/</guid>
      <description>&lt;p&gt;6/19に開催された&lt;a href=&#34;https://techplay.jp/event/733454&#34;&gt;UnityエンジニアによるShader勉強会！&lt;/a&gt;で「Unity×レイマーチングによる映像制作の実践手法」という発表をしました。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;daf8218b7458460087137b6f23e938b3&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;はじめに&#34;&gt;はじめに&lt;/h1&gt;

&lt;p&gt;この記事は、発表内容をブログ向けに編集・要約したものになります。スライドだけでは伝わりにくい箇所を文章でフォローしました。&lt;/p&gt;

&lt;p&gt;発表当日の様子は前回の記事にまとめました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/06/20/klab-tech-meetup4/&#34;&gt;UnityエンジニアによるShader勉強会！に登壇しました | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;発表の題材-wormhole&#34;&gt;発表の題材『WORMHOLE』&lt;/h1&gt;

&lt;p&gt;TokyoDemoFest2018で発表した『WORMHOLE』という映像作品を題材とした発表です。&lt;/p&gt;

&lt;p&gt;WORMHOLEの映像はUnityと&lt;a href=&#34;https://www.slideshare.net/shohosoda9/threejs-58238484&#34;&gt;レイマーチング&lt;/a&gt;を組み合わせて制作しました。&lt;/p&gt;

&lt;p&gt;以下の記事で利用したテクニックは既に解説していましたが、今回は &lt;strong&gt;汎用的に役立ちそうなテクニック&lt;/strong&gt; に焦点を絞って、前回は説明しきれなかった部分を掘り下げて解説しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;Tokyo Demo Fest 2018のDemo Compo優勝作品の解説（グラフィック編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回の発表では &lt;strong&gt;「形状」「質感」「演出」&lt;/strong&gt; の3つをテーマとして、WORMHOLEに用いたテクニックの解説を行いました。&lt;/p&gt;

&lt;h1 id=&#34;形状-モデリング&#34;&gt;形状（モデリング）&lt;/h1&gt;

&lt;p&gt;1つ目のテーマは &lt;strong&gt;「形状」&lt;/strong&gt; です。&lt;/p&gt;

&lt;p&gt;CGの世界では、形状を決める作業をモデリングと呼びます。
複雑なトンネルの形状を40行ほどの距離関数でモデリングする方法を解説しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.011.jpeg&#34; alt=&#34;トンネルの距離関数の設計アプローチ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;トンネルは既存のフラクタル図形をアレンジして設計しました。
IFSと呼ばれる手法でMengerSpongeと呼ばれる有名なフラクタル図形を定義（図の左）して、IFSのパラメータを変化によって形状をアレンジ（図の中央）し、さらにfoldRotateという操作を加えるとトンネルの形状（図の右）が完成します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.012.jpeg&#34; alt=&#34;IFS（Iterated function system）とは&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IFS&lt;/strong&gt; は自身の縮小コピーを重ね合わせることでフラクタル図形を作るテクニックです。
IFSはIterated Function Systemの略で、その名前の通りforループの中で、fold、拡大や縮小、平行移動といった操作を繰り返して距離関数をつくります。
forループで空間を操作してから、最後にBoxの距離関数を return します。&lt;/p&gt;

&lt;p&gt;ループの中でスケールと位置を変化させながら空間を折りたたみをして、Boxが出現する座標空間を再帰的に繰り返すことで、Boxを再帰的に配置するイメージです。&lt;/p&gt;

&lt;p&gt;foldの部分はかなり難解なので、1行ずつコメントアウトしながら変化を確認すると理解が深まると思います。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.013.jpeg&#34; alt=&#34;IFS（Iterated function system）のアレンジ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;この関数では平行移動はOffset、拡大縮小はScaleという名前のパラメータにしました。&lt;/p&gt;

&lt;p&gt;このOffsetとScaleを変化させることで、フラクタル図形をアレンジできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.014.jpeg&#34; alt=&#34;foldRotateとは&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;foldRotate&lt;/strong&gt; （別名: &lt;strong&gt;polarMod&lt;/strong&gt; ）はある軸を中心として一定の角度で回転しながら空間を折りたたみする操作です。
この回転の角度を変化させると、任意の図形を多角形の柱のような形に変形できます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;三角柱を作りたいときは、360° を N = 3 で割った θ = 120° ずつ回転します。&lt;/li&gt;
&lt;li&gt;元の形が立方体なので、N = 4 のときは変化がありませんが、元の図形の4分の1が繰り返されています。&lt;/li&gt;
&lt;li&gt;N = 6 にすれば6角柱ができます。&lt;/li&gt;
&lt;li&gt;N = 8 にすれば8角柱になります。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WORMHOLEのトンネルには8角柱のfoldRotateを利用しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.018.jpeg&#34; alt=&#34;最終的なコード&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ここまで使ったIFSによるMengerSpongeの距離関数とfoldRotateを組み合わせた最終的な距離関数のコードがこちらです。
なんと、わずか40行のコードで複雑な形状を定義できました！
非常に短いコードだけで複雑なモデリングができるのが距離関数の強みです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float3 _MengerOffset;
float _MengerScale;
float _MengerFold;

// IFSによるMengerSpongeの距離関数
float dMenger(float3 z0, float3 offset, float scale) {
    float4 z = float4(z0, 1.0);
    for (int n = 0; n &amp;lt; 4; n++) {
        z = abs(z);

        if (z.x &amp;lt; z.y) z.xy = z.yx;
        if (z.x &amp;lt; z.z) z.xz = z.zx;
        if (z.y &amp;lt; z.z) z.yz = z.zy;

        z *= scale;
        z.xyz -= offset * (scale - 1.0);

        if (z.z &amp;lt; -0.5 * offset.z * (scale - 1.0))
            z.z += offset.z * (scale - 1.0);
    }
    return (length(max(abs(z.xyz) - float3(1.0, 1.0, 1.0), 0.0)) - 0.05) / z.w;
}

// 2Dの回転行列の生成
float2x2 rotate(in float a) {
    float s = sin(a), c = cos(a);
    return float2x2(c, s, -s, c);
}

// 回転のfold
// https://www.shadertoy.com/view/Mlf3Wj
float2 foldRotate(in float2 p, in float s) {
    float a = PI / s - atan2(p.x, p.y);
    float n = PI2 / s;
    a = floor(a / n) * n;
    p = mul(rotate(a), p);
    return p;
}

// 最終的な距離関数
inline float DistanceFunction(float3 pos) {
    // 回転foldの適用
    pos.yx = foldRotate(pos.yx, _MengerFold);

    return dMenger(pos, _MengerOffset, _MengerScale);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;シェーダー全体: &lt;a href=&#34;https://github.com/gam0022/unity-demoscene/blob/master/Assets/Demoscene/Projects/2019-06-02-KLabTechMeetup4/Tunel.shader&#34;&gt;Tunel.shader&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;距離関数のfoldについてブログ記事を書いたので、もっと詳しく知りたい方はご覧ください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/03/02/raymarching-fold/&#34;&gt;距離関数のfold（折りたたみ）による形状設計 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;質感-ライティング&#34;&gt;質感（ライティング）&lt;/h1&gt;

&lt;p&gt;2つ目のテーマは &lt;strong&gt;「質感」&lt;/strong&gt; です。&lt;/p&gt;

&lt;p&gt;CGの世界では、質感はライティング処理によって計算されます。
WORMHOLEではディファードレンダリングを採用しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.021.jpeg&#34; alt=&#34;ディファードレンダリングを採用&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディファードレンダリングは2つのパスでシーンを描画するレンダリング手法です。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;G-Bufferパス&lt;/strong&gt; でNormalやDepthなどのライティングに必要な情報を詰め込んだGバッファを生成します。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lightingパス&lt;/strong&gt; でGバッファの情報を元にライティングを計算して、最終的なレンダリング結果を生成します。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;これがディファードレンダリングの流れです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.022.jpeg&#34; alt=&#34;ディファードレンダリングを採用した3つの理由&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディファードレンダリングを採用した理由は3つあります。&lt;/p&gt;

&lt;p&gt;1つ目の理由は &lt;strong&gt;距離関数とポリゴンが混在したシーンであっても一貫したライティングができる&lt;/strong&gt; 点です。レイマーチングの結果をGバッファに書き込む &lt;strong&gt;G-Bufferパス&lt;/strong&gt; のシェーダーを実装すれば、Gバッファ上では距離関数もポリゴンもどちらもスクリーンスペースの2Dのデータとなり、両者を区別する必要がないので、一貫したライティングができます。
&lt;a href=&#34;https://twitter.com/hecomi&#34;&gt;@hecomi&lt;/a&gt;さんが開発している&lt;a href=&#34;https://github.com/hecomi/uRaymarching&#34;&gt;uRaymarching&lt;/a&gt;というレイマーチング用のシェーダーのテンプレートを用いると、このようなシェーダーを少ない手間で書くことができます。
WORMHOLEでもuRaymarchingを利用しています。&lt;/p&gt;

&lt;p&gt;2つ目の理由は、Unityが標準で用意している &lt;strong&gt;Lightingパス&lt;/strong&gt; を利用することで、自分でライティング処理を実装しなくてもUnityの全種類の光源やReflectionProbeに対応できる点です。
もしフォワードレンダリングでレイマーチングをする場合にはライティング処理を自力で実装する必要があるので、ライティング処理を実装しなくて済むのはディファードレンダリングの強みと言えると思います。&lt;/p&gt;

&lt;p&gt;3つ目の理由は、ディファードレンダリングの特性上、光源が数が多いシーンであっても現実的な処理負荷でライティングを計算できる点です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.023.jpeg&#34; alt=&#34;ディファードレンダリングのライティングをカスタマイズ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一方でディファードレンダリングにはデメリットもあります。
シーン全体を同じ &lt;strong&gt;Lightingパス&lt;/strong&gt; で処理するということは、
裏を返すとマテリアルごとのライティングのカスタマイズが難しくなります。&lt;/p&gt;

&lt;p&gt;このような場合、StencilやGバッファにマテリアルIDの情報を埋め込んで、
Lightingパスの中でマテリアルを判定してライティングを切り替えることが正攻法となりますが、Lightingパスの修正となると、プロジェクト全体への影響も大きいですし、手間もかかってしまいます。&lt;/p&gt;

&lt;p&gt;WORMHOLEではEmissiveを活用してこの問題を解決しました。
Emissiveは自発光（自分が放つ光の強さ）のパラメーターですが、Emissive以外のパラメータを0にすると、Emissiveの色がそのまま最終的なピクセルの色として画面に出力されます。
この性質を利用して、独自のライティング結果をEmissiveに書き込むことで、自由にライティングをカスタマイズできます。&lt;/p&gt;

&lt;h1 id=&#34;演出-テキストのアニメーション&#34;&gt;演出（テキストのアニメーション）&lt;/h1&gt;

&lt;p&gt;3つ目のテーマは &lt;strong&gt;「演出」&lt;/strong&gt; です。&lt;/p&gt;

&lt;p&gt;演出と言ってもたくさんの要素があると思いますが、今回の発表ではテキストのアニメーション演出をシェーダーで実装する話をします。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.028.jpeg&#34; alt=&#34;TextMeshProとは？&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProはSDFをつかって高品質にフォントをレンダリングするためのAssetです。&lt;/p&gt;

&lt;p&gt;SDFはSigned Distance Fieldのことで、左のように文字の輪郭までの距離を画素値にした画像です。
SDFを使うとフォントを拡大してもジャギが目立たないため、フォントのレンダリングに適しています。&lt;/p&gt;

&lt;p&gt;また、勘の良い方はお気づきかと思いますが、SDFはレイマーチングの距離関数と全く同じ概念です。
距離関数の入力が3Dなのか2Dなのかというのと、コードで表現されるか、テクスチャで表現されるかという違いはありますが、本質的には同じものです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p29.gif&#34; alt=&#34;TextMeshProの描画の仕組み&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProの描画の仕組みについて説明します。&lt;/p&gt;

&lt;p&gt;まずCPUで1文字ずつMeshを生成します。
オレンジ色で示されたTextMeshProの文字をワイヤーフレーム表示を見ると、1文字ずつMeshが存在することが分かります。&lt;/p&gt;

&lt;p&gt;SDFテクスチャのUV情報はMeshの頂点データとして埋め込まれています。
次にこのMeshを描画するフラグメントシェーダーをつかってSDFテクスチャをフェッチしてフォントの内外判定をしてフォントをレンダリングします。&lt;/p&gt;

&lt;p&gt;このように TextMeshProではシェーダーをつかってフォントをレンダリングしています。&lt;/p&gt;

&lt;p&gt;つまり、 &lt;strong&gt;シェーダーを書けば、TextMeshProのレンダリングを 自由にカスタマイズできます！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.031.jpeg&#34; alt=&#34;TextMeshProのシェーダーのカスタマイズ方法&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProのシェーダーのカスタマイズ方法を紹介します。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;TextMeshProのシェーダーをコピーします。どのシェーダーをコピーしても良いのですが、Mobileと書いてあるものは実装がシンプルなのでオススメです。&lt;/li&gt;
&lt;li&gt;好きなようにシェーダーをカスタマイズします。色を決定する部分や、SDFテクスチャをフェッチする部分を改造するのが良いかと思います。&lt;/li&gt;
&lt;li&gt;TextMeshProのインスペクタから改造したシェーダーを設定すれば、完了です。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p32.gif&#34; alt=&#34;TextMeshProのシェーダーのカスタマイズ例1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProのシェーダーのカスタマイズ例を2つ紹介します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;【左】色を決定する部分のシェーダーを書き換えて、sin関数で模様と動きをつけて、ブラウン管風のエフェクトと追加しました。&lt;/li&gt;
&lt;li&gt;【右】2種類のSDFテクスチャをブレンドすることで、平成と令和をモーフィングさせました。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p33.gif&#34; alt=&#34;TextMeshProのシェーダーのカスタマイズ例2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これはWORMHOLEのオープニング部分のエフェクトです。文字をパラパラと出現させたり消失させたりしています。&lt;/p&gt;

&lt;p&gt;これがシェーダーの差分のコードです。
SDFテクスチャをフェッチするUVをこのように時間でclampすることで、フォントを引き伸ばす効果を加えました。
わずか3行くらいの差分ですが、面白いエフェクトができたかなと思います。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;        // PIXEL SHADER
        fixed4 PixShader(pixel_t input) : SV_Target
        {
-           half d = tex2D(_MainTex, input.texcoord0.xy).a * input.param.x;
+           half2 uv = input.texcoord0.xy;
+           uv.y = clamp(uv.y, 0.0, 0.5 + 0.5 * sin(_Time.y));
+           half d = tex2D(_MainTex, uv).a * input.param.x;
            half4 c = input.faceColor * saturate(d - input.param.w);

        #ifdef OUTLINE_ON
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TextMeshProとカスタムシェーダーを組み合わせる方法についてはQiitaに記事を投稿しているので、詳しく知りたい方は、こちらをご覧ください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/gam0022/items/f3b7a3e9821a67a5b0f3&#34;&gt;[Unity] カスタムシェーダーでTextMeshProに独創的な演出を加える | Qiita&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;番外編-unity-timelineを活用した演出&#34;&gt;番外編: Unity Timelineを活用した演出&lt;/h2&gt;

&lt;p&gt;番外編のテキスト以外の演出の話として、Unity Timelineの活用についても紹介しました。&lt;/p&gt;

&lt;p&gt;シェーダーだけでなくUnity Timelineも利用することで、演出制作の効率を高めました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.037.jpeg&#34; alt=&#34;Unity Timelineの活用&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オレンジ色の枠で囲まれているのがTimeline Windowです。&lt;/p&gt;

&lt;p&gt;演出の品質を高めるためには、演出の試行錯誤のイテレーションが必要です。
このイテレーションを高速に回すために、リアルタイムに編集結果をプレビューできる点や、自由に再生時間をシークできる点が本当に良かったです。&lt;/p&gt;

&lt;p&gt;Timelineの主な利用箇所です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Animation Track

&lt;ul&gt;
&lt;li&gt;レイマーチング用のマテリアルのパラメータ制御&lt;/li&gt;
&lt;li&gt;ポストエフェクト用のマテリアルのパラメータ制御&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;TextMeshPro専用のCustom Track

&lt;ul&gt;
&lt;li&gt;TextMeshProのテキストを書き換えは標準のTrackでは実現できなかったので、Timelineのカスタムトラックを自作して実現しました。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Chinemachine Track

&lt;ul&gt;
&lt;li&gt;カメラワークにはChinemachineというAssetのトラックを利用しました。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.041.jpeg&#34; alt=&#34;演出のまとめ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;シェーダーが不得意な（数式で表現しにくい）演出はTimelineも活用することで、効率的に演出を制作しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;規則的な（数式で表現ができる）動きはシェーダーが得意

&lt;ul&gt;
&lt;li&gt;音楽のBPMに合わせてチカチカ点滅させるのは、シェーダーが適しています。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;不規則な（数式で表現しにくい）動きはTimelineが得意

&lt;ul&gt;
&lt;li&gt;カメラワークはTimelineを利用したほうが効率的に演出が作れると思います。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p35.gif&#34; alt=&#34;まとめ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;リアルな質感も、複雑な形状も、カッコいい演出も、どれもシェーダーで実現できます。&lt;/p&gt;

&lt;p&gt;短いコードだけで多彩な表現ができるため、映像作成においては &lt;strong&gt;シェーダーは最強の道具&lt;/strong&gt; だと言えるでしょう。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
